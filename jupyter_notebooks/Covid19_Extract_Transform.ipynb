{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook was used to develop the ETL pipeline for getting new COVID-19 data from Johns Hopkins via Github and to produce a clean dataframe.  In the process of producing the clean dataframe, it also loads cleaned dataframes for many regional populations so per capita calculations can be included in the final COVID dataframe.  It finally saves the clean dataframe as a pickle file on my local drive and uploads a copy to my Google Drive.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCv6HBqklIFL",
        "colab_type": "code",
        "outputId": "d0b12dc2-3487-44c1-ef32-08deeb76ff0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "import time\n",
        "t0 = time.time()\n",
        "from github.MainClass import Github\n",
        "\n",
        "# read my github access token from my secrets folder\n",
        "# a new token can be created here: https://github.com/settings/tokens\n",
        "with open(\"C:/Users/adiad/Anaconda3/envs/CovidApp36/covidapp/secret_credentials/github_token.txt\", \"r\") as file:\n",
        "    token = file.read()\n",
        "\n",
        "g = Github(token)\n",
        "repo = g.get_repo(\"CSSEGISandData/COVID-19\")\n",
        "file_list = repo.get_contents(\"csse_covid_19_data/csse_covid_19_daily_reports\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JJSam-wpLxj",
        "colab_type": "code",
        "outputId": "fe411a01-9014-494f-ad01-f55ad216543b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly, plotly.graph_objects as go\n",
        "import matplotlib, matplotlib.pyplot as plt, matplotlib.cm as cm\n",
        "\n",
        "github_dir_path = 'https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
        "file_path = github_dir_path  + str(file_list[1]).split('/')[-1].split(\".\")[0]+ '.csv'\n",
        "\n",
        "file_date = str(file_list[1]).split('/')[-1].split(\".\")[0]\n",
        "file_path = github_dir_path + file_date + '.csv'\n",
        "df = pd.read_csv(file_path, error_bad_lines=False)\n",
        "df[\"Date\"] = file_date\n",
        "\n",
        "for file in file_list[2:-1]:\n",
        "  file_date = str(file).split('/')[-1].split(\".\")[0]\n",
        "  file_path = github_dir_path  + file_date + '.csv'\n",
        "  file_df = pd.read_csv(file_path, error_bad_lines=False)\n",
        "  file_df[\"Date\"] = file_date\n",
        "\n",
        "  # rename columns which have changed from the orignal names in recent files\n",
        "  if any(file_df.columns.isin([\"Country_Region\"])):\n",
        "    file_df = file_df.rename(columns={\"Country_Region\": \"Country/Region\"})\n",
        "  if any(file_df.columns.isin([\"Province_State\"])):\n",
        "    file_df = file_df.rename(columns={\"Province_State\": \"Province/State\"})\n",
        "  if any(file_df.columns.isin([\"Last_Update\"])):\n",
        "    file_df = file_df.rename(columns={\"Last_Update\": \"Last Update\"})\n",
        "  if any(file_df.columns.isin([\"Long_\"])):\n",
        "    file_df = file_df.rename(columns={\"Long_\": \"Longitude\"})\n",
        "  if any(file_df.columns.isin([\"Lat\"])):\n",
        "    file_df = file_df.rename(columns={\"Lat\": \"Latitude\"})\n",
        "  if any(file_df.columns.isin([\"Admin2\"])):\n",
        "    file_df = file_df.rename(columns={\"Admin2\": \"County\"})\n",
        "  \n",
        "  df = df.append(file_df, ignore_index=True, sort=False)\n",
        "\n",
        "df.head(20)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "    Province/State  Country/Region      Last Update  Confirmed  Deaths  \\\n0            Anhui  Mainland China  1/22/2020 17:00        1.0     NaN   \n1          Beijing  Mainland China  1/22/2020 17:00       14.0     NaN   \n2        Chongqing  Mainland China  1/22/2020 17:00        6.0     NaN   \n3           Fujian  Mainland China  1/22/2020 17:00        1.0     NaN   \n4            Gansu  Mainland China  1/22/2020 17:00        NaN     NaN   \n5        Guangdong  Mainland China  1/22/2020 17:00       26.0     NaN   \n6          Guangxi  Mainland China  1/22/2020 17:00        2.0     NaN   \n7          Guizhou  Mainland China  1/22/2020 17:00        1.0     NaN   \n8           Hainan  Mainland China  1/22/2020 17:00        4.0     NaN   \n9            Hebei  Mainland China  1/22/2020 17:00        1.0     NaN   \n10    Heilongjiang  Mainland China  1/22/2020 17:00        NaN     NaN   \n11           Henan  Mainland China  1/22/2020 17:00        5.0     NaN   \n12       Hong Kong       Hong Kong  1/22/2020 17:00        NaN     NaN   \n13           Hubei  Mainland China  1/22/2020 17:00      444.0    17.0   \n14           Hunan  Mainland China  1/22/2020 17:00        4.0     NaN   \n15  Inner Mongolia  Mainland China  1/22/2020 17:00        NaN     NaN   \n16         Jiangsu  Mainland China  1/22/2020 17:00        1.0     NaN   \n17         Jiangxi  Mainland China  1/22/2020 17:00        2.0     NaN   \n18           Jilin  Mainland China  1/22/2020 17:00        NaN     NaN   \n19        Liaoning  Mainland China  1/22/2020 17:00        2.0     NaN   \n\n    Recovered        Date  Latitude  Longitude  FIPS County  Active  \\\n0         NaN  01-22-2020       NaN        NaN   NaN    NaN     NaN   \n1         NaN  01-22-2020       NaN        NaN   NaN    NaN     NaN   \n2         NaN  01-22-2020       NaN        NaN   NaN    NaN     NaN   \n3         NaN  01-22-2020       NaN        NaN   NaN    NaN     NaN   \n4         NaN  01-22-2020       NaN        NaN   NaN    NaN     NaN   \n5         NaN  01-22-2020       NaN        NaN   NaN    NaN     NaN   \n6         NaN  01-22-2020       NaN        NaN   NaN    NaN     NaN   \n7         NaN  01-22-2020       NaN        NaN   NaN    NaN     NaN   \n8         NaN  01-22-2020       NaN        NaN   NaN    NaN     NaN   \n9         NaN  01-22-2020       NaN        NaN   NaN    NaN     NaN   \n10        NaN  01-22-2020       NaN        NaN   NaN    NaN     NaN   \n11        NaN  01-22-2020       NaN        NaN   NaN    NaN     NaN   \n12        NaN  01-22-2020       NaN        NaN   NaN    NaN     NaN   \n13       28.0  01-22-2020       NaN        NaN   NaN    NaN     NaN   \n14        NaN  01-22-2020       NaN        NaN   NaN    NaN     NaN   \n15        NaN  01-22-2020       NaN        NaN   NaN    NaN     NaN   \n16        NaN  01-22-2020       NaN        NaN   NaN    NaN     NaN   \n17        NaN  01-22-2020       NaN        NaN   NaN    NaN     NaN   \n18        NaN  01-22-2020       NaN        NaN   NaN    NaN     NaN   \n19        NaN  01-22-2020       NaN        NaN   NaN    NaN     NaN   \n\n   Combined_Key  \n0           NaN  \n1           NaN  \n2           NaN  \n3           NaN  \n4           NaN  \n5           NaN  \n6           NaN  \n7           NaN  \n8           NaN  \n9           NaN  \n10          NaN  \n11          NaN  \n12          NaN  \n13          NaN  \n14          NaN  \n15          NaN  \n16          NaN  \n17          NaN  \n18          NaN  \n19          NaN  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>Last Update</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n      <th>Date</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>FIPS</th>\n      <th>County</th>\n      <th>Active</th>\n      <th>Combined_Key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Anhui</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>01-22-2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Beijing</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>14.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>01-22-2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Chongqing</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>01-22-2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Fujian</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>01-22-2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Gansu</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>01-22-2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Guangdong</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>26.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>01-22-2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Guangxi</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>01-22-2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Guizhou</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>01-22-2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Hainan</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>01-22-2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Hebei</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>01-22-2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Heilongjiang</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>01-22-2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Henan</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>01-22-2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Hong Kong</td>\n      <td>Hong Kong</td>\n      <td>1/22/2020 17:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>01-22-2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Hubei</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>444.0</td>\n      <td>17.0</td>\n      <td>28.0</td>\n      <td>01-22-2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Hunan</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>01-22-2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Inner Mongolia</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>01-22-2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Jiangsu</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>01-22-2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Jiangxi</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>01-22-2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Jilin</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>01-22-2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Liaoning</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>01-22-2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YICBncdW7L0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# format columns\n",
        "df[\"Country/Region\"] = df[\"Country/Region\"].astype(str)\n",
        "df[\"Province/State\"] = df[\"Province/State\"].astype(str)\n",
        "df[\"County\"] = df[\"County\"].astype(str)\n",
        "df.Date = pd.to_datetime(df.Date)\n",
        "df[\"Last Update\"] = pd.to_datetime(df[\"Last Update\"])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK4PxHnGhzzJ",
        "colab_type": "code",
        "outputId": "10cf8e05-d225-448b-9fd9-45234b05a320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        }
      },
      "source": [
        "# the following rows appear to give bogus duplicate data, so they will be deleted\n",
        "df[df[\"Country/Region\"].isin(['The Bahamas', 'Bahamas, The'])]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "     Province/State Country/Region         Last Update  Confirmed  Deaths  \\\n6152            nan    The Bahamas 2020-03-16 03:33:03        1.0     0.0   \n6427            nan    The Bahamas 2020-03-16 03:33:03        1.0     0.0   \n6705            nan    The Bahamas 2020-03-16 03:33:03        1.0     0.0   \n6953            nan   Bahamas, The 2020-03-19 11:33:39        3.0     0.0   \n7012            nan    The Bahamas 2020-03-19 12:13:38        0.0     0.0   \n7254            nan   Bahamas, The 2020-03-19 11:33:39        3.0     0.0   \n7311            nan    The Bahamas 2020-03-19 12:13:38        0.0     0.0   \n7551            nan   Bahamas, The 2020-03-21 02:43:03        4.0     0.0   \n7615            nan    The Bahamas 2020-03-19 12:13:38        0.0     0.0   \n\n      Recovered       Date  Latitude  Longitude  FIPS County  Active  \\\n6152        0.0 2020-03-16   24.2500   -76.0000   NaN    nan     NaN   \n6427        0.0 2020-03-17   24.2500   -76.0000   NaN    nan     NaN   \n6705        0.0 2020-03-18   24.2500   -76.0000   NaN    nan     NaN   \n6953        0.0 2020-03-19   25.0343   -77.3963   NaN    nan     NaN   \n7012        0.0 2020-03-19   24.2500   -76.0000   NaN    nan     NaN   \n7254        0.0 2020-03-20   25.0343   -77.3963   NaN    nan     NaN   \n7311        0.0 2020-03-20   24.2500   -76.0000   NaN    nan     NaN   \n7551        0.0 2020-03-21   25.0343   -77.3963   NaN    nan     NaN   \n7615        0.0 2020-03-21   24.2500   -76.0000   NaN    nan     NaN   \n\n     Combined_Key  \n6152          NaN  \n6427          NaN  \n6705          NaN  \n6953          NaN  \n7012          NaN  \n7254          NaN  \n7311          NaN  \n7551          NaN  \n7615          NaN  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>Last Update</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n      <th>Date</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>FIPS</th>\n      <th>County</th>\n      <th>Active</th>\n      <th>Combined_Key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6152</th>\n      <td>nan</td>\n      <td>The Bahamas</td>\n      <td>2020-03-16 03:33:03</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-16</td>\n      <td>24.2500</td>\n      <td>-76.0000</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6427</th>\n      <td>nan</td>\n      <td>The Bahamas</td>\n      <td>2020-03-16 03:33:03</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-17</td>\n      <td>24.2500</td>\n      <td>-76.0000</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6705</th>\n      <td>nan</td>\n      <td>The Bahamas</td>\n      <td>2020-03-16 03:33:03</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-18</td>\n      <td>24.2500</td>\n      <td>-76.0000</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6953</th>\n      <td>nan</td>\n      <td>Bahamas, The</td>\n      <td>2020-03-19 11:33:39</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-19</td>\n      <td>25.0343</td>\n      <td>-77.3963</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7012</th>\n      <td>nan</td>\n      <td>The Bahamas</td>\n      <td>2020-03-19 12:13:38</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-19</td>\n      <td>24.2500</td>\n      <td>-76.0000</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7254</th>\n      <td>nan</td>\n      <td>Bahamas, The</td>\n      <td>2020-03-19 11:33:39</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-20</td>\n      <td>25.0343</td>\n      <td>-77.3963</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7311</th>\n      <td>nan</td>\n      <td>The Bahamas</td>\n      <td>2020-03-19 12:13:38</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-20</td>\n      <td>24.2500</td>\n      <td>-76.0000</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7551</th>\n      <td>nan</td>\n      <td>Bahamas, The</td>\n      <td>2020-03-21 02:43:03</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-21</td>\n      <td>25.0343</td>\n      <td>-77.3963</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7615</th>\n      <td>nan</td>\n      <td>The Bahamas</td>\n      <td>2020-03-19 12:13:38</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-21</td>\n      <td>24.2500</td>\n      <td>-76.0000</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnCpE-lkjQyC",
        "colab_type": "code",
        "outputId": "d071bcb8-2a62-40ff-8629-80d6022d7a28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "df = df[df[\"Country/Region\"] != 'The Bahamas']\n",
        "\n",
        "# the mainland china rows shown below are bogus duplicates, so they will be dropped\n",
        "df[(df[\"Province/State\"].isin([\"Gansu\", \"Hebei\"]) ) & ((df.Date == pd.datetime(2020, 3, 11)) | (df.Date == pd.datetime(2020, 3, 12)))]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "     Province/State  Country/Region         Last Update  Confirmed  Deaths  \\\n4748          Hebei           China 2020-03-11 02:18:14      318.0     6.0   \n4765          Gansu           China 2020-03-11 14:33:03      127.0     2.0   \n4925          Gansu  Mainland China 2020-03-11 02:18:28        0.0     0.0   \n4926          Hebei  Mainland China 2020-03-11 02:18:29        0.0     0.0   \n4965          Hebei           China 2020-03-12 05:33:02      318.0     6.0   \n4983          Gansu           China 2020-03-11 14:33:03      127.0     2.0   \n5146          Gansu  Mainland China 2020-03-11 02:18:28        0.0     0.0   \n5147          Hebei  Mainland China 2020-03-11 02:18:29        0.0     0.0   \n\n      Recovered       Date  Latitude  Longitude  FIPS County  Active  \\\n4748      307.0 2020-03-11   39.5490   116.1306   NaN    nan     NaN   \n4765       88.0 2020-03-11   37.8099   101.0583   NaN    nan     NaN   \n4925        0.0 2020-03-11   36.0611   103.8343   NaN    nan     NaN   \n4926        0.0 2020-03-11   38.0428   114.5149   NaN    nan     NaN   \n4965      308.0 2020-03-12   39.5490   116.1306   NaN    nan     NaN   \n4983       88.0 2020-03-12   37.8099   101.0583   NaN    nan     NaN   \n5146        0.0 2020-03-12   36.0611   103.8343   NaN    nan     NaN   \n5147        0.0 2020-03-12   38.0428   114.5149   NaN    nan     NaN   \n\n     Combined_Key  \n4748          NaN  \n4765          NaN  \n4925          NaN  \n4926          NaN  \n4965          NaN  \n4983          NaN  \n5146          NaN  \n5147          NaN  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>Last Update</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n      <th>Date</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>FIPS</th>\n      <th>County</th>\n      <th>Active</th>\n      <th>Combined_Key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4748</th>\n      <td>Hebei</td>\n      <td>China</td>\n      <td>2020-03-11 02:18:14</td>\n      <td>318.0</td>\n      <td>6.0</td>\n      <td>307.0</td>\n      <td>2020-03-11</td>\n      <td>39.5490</td>\n      <td>116.1306</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4765</th>\n      <td>Gansu</td>\n      <td>China</td>\n      <td>2020-03-11 14:33:03</td>\n      <td>127.0</td>\n      <td>2.0</td>\n      <td>88.0</td>\n      <td>2020-03-11</td>\n      <td>37.8099</td>\n      <td>101.0583</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4925</th>\n      <td>Gansu</td>\n      <td>Mainland China</td>\n      <td>2020-03-11 02:18:28</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-11</td>\n      <td>36.0611</td>\n      <td>103.8343</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4926</th>\n      <td>Hebei</td>\n      <td>Mainland China</td>\n      <td>2020-03-11 02:18:29</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-11</td>\n      <td>38.0428</td>\n      <td>114.5149</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4965</th>\n      <td>Hebei</td>\n      <td>China</td>\n      <td>2020-03-12 05:33:02</td>\n      <td>318.0</td>\n      <td>6.0</td>\n      <td>308.0</td>\n      <td>2020-03-12</td>\n      <td>39.5490</td>\n      <td>116.1306</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4983</th>\n      <td>Gansu</td>\n      <td>China</td>\n      <td>2020-03-11 14:33:03</td>\n      <td>127.0</td>\n      <td>2.0</td>\n      <td>88.0</td>\n      <td>2020-03-12</td>\n      <td>37.8099</td>\n      <td>101.0583</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5146</th>\n      <td>Gansu</td>\n      <td>Mainland China</td>\n      <td>2020-03-11 02:18:28</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-12</td>\n      <td>36.0611</td>\n      <td>103.8343</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5147</th>\n      <td>Hebei</td>\n      <td>Mainland China</td>\n      <td>2020-03-11 02:18:29</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-12</td>\n      <td>38.0428</td>\n      <td>114.5149</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzeCQadUq7a5",
        "colab_type": "code",
        "outputId": "0505701b-307f-440a-fe0c-bb604aef42e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        }
      },
      "source": [
        "df = df[~((df[\"Province/State\"].isin([\"Gansu\", \"Hebei\"])) & \\\n",
        "           (df[\"Country/Region\"] == \"Mainland China\") & \\\n",
        "           (df.Date.isin([pd.datetime(2020, 3, 11), pd.datetime(2020, 3, 12)])))]\n",
        "\n",
        "# The country \"The Gambia\" is a bogus duplicate of \"Gambia, The\", so it will be deleted\n",
        "df[df[\"Country/Region\"].isin([\"Gambia\", \"Gambia, The\", \"The Gambia\"]) & \\\n",
        "   (df.Date.isin([pd.datetime(2020, 3, 18), pd.datetime(2020, 3, 19), \\\n",
        "                  pd.datetime(2020, 3, 20), pd.datetime(2020, 3, 21)]))]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "     Province/State Country/Region         Last Update  Confirmed  Deaths  \\\n6695            nan    Gambia, The 2020-03-18 14:13:56        1.0     0.0   \n6721            nan     The Gambia 2020-03-18 14:13:56        0.0     0.0   \n6990            nan    Gambia, The 2020-03-18 14:13:56        1.0     0.0   \n7013            nan     The Gambia 2020-03-18 14:13:56        0.0     0.0   \n7286            nan    Gambia, The 2020-03-18 14:13:56        1.0     0.0   \n7312            nan     The Gambia 2020-03-18 14:13:56        0.0     0.0   \n7592            nan    Gambia, The 2020-03-18 14:13:56        1.0     0.0   \n7616            nan     The Gambia 2020-03-18 14:13:56        0.0     0.0   \n\n      Recovered       Date  Latitude  Longitude  FIPS County  Active  \\\n6695        0.0 2020-03-18   13.4432   -15.3101   NaN    nan     NaN   \n6721        0.0 2020-03-18   13.4667   -16.6000   NaN    nan     NaN   \n6990        0.0 2020-03-19   13.4432   -15.3101   NaN    nan     NaN   \n7013        0.0 2020-03-19   13.4667   -16.6000   NaN    nan     NaN   \n7286        0.0 2020-03-20   13.4432   -15.3101   NaN    nan     NaN   \n7312        0.0 2020-03-20   13.4667   -16.6000   NaN    nan     NaN   \n7592        0.0 2020-03-21   13.4432   -15.3101   NaN    nan     NaN   \n7616        0.0 2020-03-21   13.4667   -16.6000   NaN    nan     NaN   \n\n     Combined_Key  \n6695          NaN  \n6721          NaN  \n6990          NaN  \n7013          NaN  \n7286          NaN  \n7312          NaN  \n7592          NaN  \n7616          NaN  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>Last Update</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n      <th>Date</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>FIPS</th>\n      <th>County</th>\n      <th>Active</th>\n      <th>Combined_Key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6695</th>\n      <td>nan</td>\n      <td>Gambia, The</td>\n      <td>2020-03-18 14:13:56</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-18</td>\n      <td>13.4432</td>\n      <td>-15.3101</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6721</th>\n      <td>nan</td>\n      <td>The Gambia</td>\n      <td>2020-03-18 14:13:56</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-18</td>\n      <td>13.4667</td>\n      <td>-16.6000</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6990</th>\n      <td>nan</td>\n      <td>Gambia, The</td>\n      <td>2020-03-18 14:13:56</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-19</td>\n      <td>13.4432</td>\n      <td>-15.3101</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7013</th>\n      <td>nan</td>\n      <td>The Gambia</td>\n      <td>2020-03-18 14:13:56</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-19</td>\n      <td>13.4667</td>\n      <td>-16.6000</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7286</th>\n      <td>nan</td>\n      <td>Gambia, The</td>\n      <td>2020-03-18 14:13:56</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-20</td>\n      <td>13.4432</td>\n      <td>-15.3101</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7312</th>\n      <td>nan</td>\n      <td>The Gambia</td>\n      <td>2020-03-18 14:13:56</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-20</td>\n      <td>13.4667</td>\n      <td>-16.6000</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7592</th>\n      <td>nan</td>\n      <td>Gambia, The</td>\n      <td>2020-03-18 14:13:56</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-21</td>\n      <td>13.4432</td>\n      <td>-15.3101</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7616</th>\n      <td>nan</td>\n      <td>The Gambia</td>\n      <td>2020-03-18 14:13:56</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-21</td>\n      <td>13.4667</td>\n      <td>-16.6000</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6HZuBQ2iywI",
        "colab_type": "code",
        "outputId": "c25d412e-e3d6-4db2-b6f1-422d14afe3bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "df = df[df[\"Country/Region\"] != \"The Gambia\"]\n",
        "\n",
        "# the single row with the country \"Republic of Ireland\" is a bogus duplicate, so it will be deleted\n",
        "df[df[\"Country/Region\"].isin([\"Ireland\", \"Republic of Ireland\"]) & \\\n",
        "   (df.Date.isin([pd.datetime(2020, 3, 7), pd.datetime(2020, 3, 8), pd.datetime(2020, 3, 9)]))]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "     Province/State       Country/Region         Last Update  Confirmed  \\\n3839            nan              Ireland 2020-03-06 20:43:03       18.0   \n4066            nan  Republic of Ireland 2020-03-08 21:03:03       21.0   \n4070            nan              Ireland 2020-03-08 21:03:03       19.0   \n4322            nan              Ireland 2020-03-09 09:53:06       21.0   \n\n      Deaths  Recovered       Date  Latitude  Longitude  FIPS County  Active  \\\n3839     0.0        0.0 2020-03-07   53.1424    -7.6921   NaN    nan     NaN   \n4066     0.0        0.0 2020-03-08   53.1424    -7.6921   NaN    nan     NaN   \n4070     0.0        0.0 2020-03-08   53.4167    -8.0000   NaN    nan     NaN   \n4322     0.0        0.0 2020-03-09   53.1424    -7.6921   NaN    nan     NaN   \n\n     Combined_Key  \n3839          NaN  \n4066          NaN  \n4070          NaN  \n4322          NaN  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>Last Update</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n      <th>Date</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>FIPS</th>\n      <th>County</th>\n      <th>Active</th>\n      <th>Combined_Key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3839</th>\n      <td>nan</td>\n      <td>Ireland</td>\n      <td>2020-03-06 20:43:03</td>\n      <td>18.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-07</td>\n      <td>53.1424</td>\n      <td>-7.6921</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4066</th>\n      <td>nan</td>\n      <td>Republic of Ireland</td>\n      <td>2020-03-08 21:03:03</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-08</td>\n      <td>53.1424</td>\n      <td>-7.6921</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4070</th>\n      <td>nan</td>\n      <td>Ireland</td>\n      <td>2020-03-08 21:03:03</td>\n      <td>19.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-08</td>\n      <td>53.4167</td>\n      <td>-8.0000</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4322</th>\n      <td>nan</td>\n      <td>Ireland</td>\n      <td>2020-03-09 09:53:06</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-09</td>\n      <td>53.1424</td>\n      <td>-7.6921</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0xpsA9h6Ucc",
        "colab_type": "code",
        "outputId": "16eb9391-45d1-45fb-d7c4-c2a881096fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "df = df[df[\"Country/Region\"] != \"Republic of Ireland\"]\n",
        "\n",
        "# The District of Columbia has a duplicate on 3/22/2020, delete the row with Confirmed == 0\n",
        "df[(df[\"Province/State\"].str.contains(\"District of Columbia\")) & (df.Date == pd.datetime(2020, 3, 22))]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "             Province/State Country/Region         Last Update  Confirmed  \\\n8954   District of Columbia             US 2020-03-22 23:45:00      102.0   \n11032  District of Columbia             US 2020-03-22 23:45:00      102.0   \n\n       Deaths  Recovered       Date   Latitude  Longitude     FIPS  \\\n8954      0.0        0.0 2020-03-22  38.904178  -77.01656  11001.0   \n11032     2.0        0.0 2020-03-22  38.904178  -77.01656  11001.0   \n\n                     County  Active  \\\n8954   District of Columbia     0.0   \n11032  District of Columbia     0.0   \n\n                                         Combined_Key  \n8954   District of Columbia, District of Columbia, US  \n11032    District of Columbia,District of Columbia,US  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>Last Update</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n      <th>Date</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>FIPS</th>\n      <th>County</th>\n      <th>Active</th>\n      <th>Combined_Key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8954</th>\n      <td>District of Columbia</td>\n      <td>US</td>\n      <td>2020-03-22 23:45:00</td>\n      <td>102.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-22</td>\n      <td>38.904178</td>\n      <td>-77.01656</td>\n      <td>11001.0</td>\n      <td>District of Columbia</td>\n      <td>0.0</td>\n      <td>District of Columbia, District of Columbia, US</td>\n    </tr>\n    <tr>\n      <th>11032</th>\n      <td>District of Columbia</td>\n      <td>US</td>\n      <td>2020-03-22 23:45:00</td>\n      <td>102.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2020-03-22</td>\n      <td>38.904178</td>\n      <td>-77.01656</td>\n      <td>11001.0</td>\n      <td>District of Columbia</td>\n      <td>0.0</td>\n      <td>District of Columbia,District of Columbia,US</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dplFwnG_ETUx",
        "colab_type": "code",
        "outputId": "7bf5a642-9e3e-4569-aac7-90a540735112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df = df[~((df[\"Province/State\"].str.contains(\"District of Columbia\")) & \\\n",
        "        (df.Date == pd.datetime(2020, 3, 22)) & \\\n",
        "        (df.Confirmed == 0))]\n",
        "\n",
        "# check if country names have evolved in combined dataset\n",
        "sorted(df[\"Country/Region\"].unique().tolist())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "[' Azerbaijan',\n 'Afghanistan',\n 'Albania',\n 'Algeria',\n 'Andorra',\n 'Angola',\n 'Antigua and Barbuda',\n 'Argentina',\n 'Armenia',\n 'Aruba',\n 'Australia',\n 'Austria',\n 'Azerbaijan',\n 'Bahamas',\n 'Bahamas, The',\n 'Bahrain',\n 'Bangladesh',\n 'Barbados',\n 'Belarus',\n 'Belgium',\n 'Belize',\n 'Benin',\n 'Bhutan',\n 'Bolivia',\n 'Bosnia and Herzegovina',\n 'Botswana',\n 'Brazil',\n 'Brunei',\n 'Bulgaria',\n 'Burkina Faso',\n 'Burma',\n 'Burundi',\n 'Cabo Verde',\n 'Cambodia',\n 'Cameroon',\n 'Canada',\n 'Cape Verde',\n 'Cayman Islands',\n 'Central African Republic',\n 'Chad',\n 'Channel Islands',\n 'Chile',\n 'China',\n 'Colombia',\n 'Comoros',\n 'Congo (Brazzaville)',\n 'Congo (Kinshasa)',\n 'Costa Rica',\n \"Cote d'Ivoire\",\n 'Croatia',\n 'Cruise Ship',\n 'Cuba',\n 'Curacao',\n 'Cyprus',\n 'Czech Republic',\n 'Czechia',\n 'Denmark',\n 'Diamond Princess',\n 'Djibouti',\n 'Dominica',\n 'Dominican Republic',\n 'East Timor',\n 'Ecuador',\n 'Egypt',\n 'El Salvador',\n 'Equatorial Guinea',\n 'Eritrea',\n 'Estonia',\n 'Eswatini',\n 'Ethiopia',\n 'Faroe Islands',\n 'Fiji',\n 'Finland',\n 'France',\n 'French Guiana',\n 'Gabon',\n 'Gambia',\n 'Gambia, The',\n 'Georgia',\n 'Germany',\n 'Ghana',\n 'Gibraltar',\n 'Greece',\n 'Greenland',\n 'Grenada',\n 'Guadeloupe',\n 'Guam',\n 'Guatemala',\n 'Guernsey',\n 'Guinea',\n 'Guinea-Bissau',\n 'Guyana',\n 'Haiti',\n 'Holy See',\n 'Honduras',\n 'Hong Kong',\n 'Hong Kong SAR',\n 'Hungary',\n 'Iceland',\n 'India',\n 'Indonesia',\n 'Iran',\n 'Iran (Islamic Republic of)',\n 'Iraq',\n 'Ireland',\n 'Israel',\n 'Italy',\n 'Ivory Coast',\n 'Jamaica',\n 'Japan',\n 'Jersey',\n 'Jordan',\n 'Kazakhstan',\n 'Kenya',\n 'Korea, South',\n 'Kosovo',\n 'Kuwait',\n 'Kyrgyzstan',\n 'Laos',\n 'Latvia',\n 'Lebanon',\n 'Lesotho',\n 'Liberia',\n 'Libya',\n 'Liechtenstein',\n 'Lithuania',\n 'Luxembourg',\n 'MS Zaandam',\n 'Macao SAR',\n 'Macau',\n 'Madagascar',\n 'Mainland China',\n 'Malawi',\n 'Malaysia',\n 'Maldives',\n 'Mali',\n 'Malta',\n 'Martinique',\n 'Mauritania',\n 'Mauritius',\n 'Mayotte',\n 'Mexico',\n 'Moldova',\n 'Monaco',\n 'Mongolia',\n 'Montenegro',\n 'Morocco',\n 'Mozambique',\n 'Namibia',\n 'Nepal',\n 'Netherlands',\n 'New Zealand',\n 'Nicaragua',\n 'Niger',\n 'Nigeria',\n 'North Ireland',\n 'North Macedonia',\n 'Norway',\n 'Oman',\n 'Others',\n 'Pakistan',\n 'Palestine',\n 'Panama',\n 'Papua New Guinea',\n 'Paraguay',\n 'Peru',\n 'Philippines',\n 'Poland',\n 'Portugal',\n 'Puerto Rico',\n 'Qatar',\n 'Republic of Korea',\n 'Republic of Moldova',\n 'Republic of the Congo',\n 'Reunion',\n 'Romania',\n 'Russia',\n 'Russian Federation',\n 'Rwanda',\n 'Saint Barthelemy',\n 'Saint Kitts and Nevis',\n 'Saint Lucia',\n 'Saint Martin',\n 'Saint Vincent and the Grenadines',\n 'San Marino',\n 'Sao Tome and Principe',\n 'Saudi Arabia',\n 'Senegal',\n 'Serbia',\n 'Seychelles',\n 'Sierra Leone',\n 'Singapore',\n 'Slovakia',\n 'Slovenia',\n 'Somalia',\n 'South Africa',\n 'South Korea',\n 'South Sudan',\n 'Spain',\n 'Sri Lanka',\n 'St. Martin',\n 'Sudan',\n 'Suriname',\n 'Sweden',\n 'Switzerland',\n 'Syria',\n 'Taipei and environs',\n 'Taiwan',\n 'Taiwan*',\n 'Tajikistan',\n 'Tanzania',\n 'Thailand',\n 'Timor-Leste',\n 'Togo',\n 'Trinidad and Tobago',\n 'Tunisia',\n 'Turkey',\n 'UK',\n 'US',\n 'Uganda',\n 'Ukraine',\n 'United Arab Emirates',\n 'United Kingdom',\n 'Uruguay',\n 'Uzbekistan',\n 'Vatican City',\n 'Venezuela',\n 'Viet Nam',\n 'Vietnam',\n 'West Bank and Gaza',\n 'Western Sahara',\n 'Yemen',\n 'Zambia',\n 'Zimbabwe',\n 'occupied Palestinian territory']"
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf63IAAZ-5dT",
        "colab_type": "code",
        "outputId": "2972388b-625a-4ebd-955b-0437138795d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ]
      },
      "source": [
        "# The following alternate names were found by visual inspection of the list\n",
        "df.replace('Mainland China', 'China', inplace=True)\n",
        "df.replace('Bahamas, The', 'The Bahamas', inplace=True)\n",
        "df.replace('Bahamas', 'The Bahamas', inplace=True)\n",
        "df.replace('Gambia, The', 'Gambia', inplace=True)\n",
        "df.replace('Hong Kong', 'Hong Kong S.A.R.', inplace=True)\n",
        "df.replace('Hong Kong SAR', 'Hong Kong S.A.R.', inplace=True)\n",
        "df.replace('Iran (Islamic Republic of)', 'Iran', inplace=True)\n",
        "df.replace('Republic of Ireland', 'Ireland', inplace=True)\n",
        "df.replace('Republic of Korea', 'South Korea', inplace=True)\n",
        "df.replace('Korea, South', 'South Korea', inplace=True)\n",
        "df.replace('Republic of Moldova', 'Moldova', inplace=True)\n",
        "df.replace('Russian Federation', 'Russia', inplace=True)\n",
        "df.replace('St. Martin', 'Saint Martin', inplace=True)\n",
        "df.replace('Taiwan*', 'Taiwan', inplace=True)\n",
        "df.replace('UK', 'United Kingdom', inplace=True)\n",
        "df.replace('Viet Nam', 'Vietnam', inplace=True)\n",
        "df.replace(\"Cote d'Ivoire\", 'Ivory Coast', inplace=True)\n",
        "df.replace(' Azerbaijan', 'Azerbaijan', inplace=True)\n",
        "df.replace('US', 'United States of America', inplace=True)\n",
        "\n",
        "# Look for evolving state/province names\n",
        "for country in sorted(df[\"Country/Region\"].unique().tolist()):\n",
        "  print(country)\n",
        "\n",
        "  for state in sorted(df.loc[df[\"Country/Region\"] == country, \"Province/State\"].unique().tolist()):\n",
        "    if state != \"nan\":\n",
        "      print(\"|-\", state)\n",
        "\n",
        "    for county in sorted(df.loc[(df[\"Country/Region\"] == country) & (df[\"Province/State\"] == state), \"County\"].unique().tolist()):\n",
        "      if county != \"nan\":\n",
        "        print(\"  |-\", county)\n",
        "\n",
        "        #for city in sorted(df.loc[(df[\"Country/Region\"] == country) & \\\n",
        "        #                          (df[\"Province/State\"] == state) & \\\n",
        "        #                          df[\"County\"] == county, \"City\"].unique().tolist()):\n",
        "        #  if city != \"nan\":\n",
        "        #    print(\"    |- City:\", city)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "  |- Lea\n  |- Lincoln\n  |- Los Alamos\n  |- Luna\n  |- McKinley\n  |- Mora\n  |- Otero\n  |- Quay\n  |- Rio Arriba\n  |- Roosevelt\n  |- San Juan\n  |- San Miguel\n  |- Sandoval\n  |- Santa Fe\n  |- Sierra\n  |- Socorro\n  |- Taos\n  |- Torrance\n  |- Unassigned\n  |- Union\n  |- Valencia\n|- New York\n  |- Albany\n  |- Allegany\n  |- Bronx\n  |- Broome\n  |- Cattaraugus\n  |- Cayuga\n  |- Chautauqua\n  |- Chemung\n  |- Chenango\n  |- Clinton\n  |- Columbia\n  |- Cortland\n  |- Delaware\n  |- Dutchess\n  |- Erie\n  |- Essex\n  |- Franklin\n  |- Fulton\n  |- Genesee\n  |- Greene\n  |- Hamilton\n  |- Herkimer\n  |- Jefferson\n  |- Kings\n  |- Lewis\n  |- Livingston\n  |- Madison\n  |- Monroe\n  |- Montgomery\n  |- Nassau\n  |- New York City\n  |- Niagara\n  |- Oneida\n  |- Onondaga\n  |- Ontario\n  |- Orange\n  |- Orleans\n  |- Oswego\n  |- Otsego\n  |- Putnam\n  |- Queens\n  |- Rensselaer\n  |- Richmond\n  |- Rockland\n  |- Saratoga\n  |- Schenectady\n  |- Schoharie\n  |- Schuyler\n  |- Seneca\n  |- St. Lawrence\n  |- Steuben\n  |- Suffolk\n  |- Sullivan\n  |- Tioga\n  |- Tompkins\n  |- Ulster\n  |- Unassigned\n  |- Warren\n  |- Washington\n  |- Wayne\n  |- Westchester\n  |- Wyoming\n  |- Yates\n|- New York City, NY\n|- New York County, NY\n|- Norfolk County, MA\n|- North Carolina\n  |- Alamance\n  |- Alexander\n  |- Alleghany\n  |- Anson\n  |- Ashe\n  |- Avery\n  |- Beaufort\n  |- Bertie\n  |- Bladen\n  |- Brunswick\n  |- Buncombe\n  |- Burke\n  |- Cabarrus\n  |- Caldwell\n  |- Camden\n  |- Carteret\n  |- Caswell\n  |- Catawba\n  |- Chatham\n  |- Cherokee\n  |- Chowan\n  |- Clay\n  |- Cleveland\n  |- Columbus\n  |- Craven\n  |- Cumberland\n  |- Currituck\n  |- Dare\n  |- Davidson\n  |- Davie\n  |- Duplin\n  |- Durham\n  |- Edgecombe\n  |- Forsyth\n  |- Franklin\n  |- Gaston\n  |- Gates\n  |- Graham\n  |- Granville\n  |- Greene\n  |- Guilford\n  |- Halifax\n  |- Harnett\n  |- Haywood\n  |- Henderson\n  |- Hertford\n  |- Hoke\n  |- Hyde\n  |- Iredell\n  |- Jackson\n  |- Johnston\n  |- Jones\n  |- Lee\n  |- Lenoir\n  |- Lincoln\n  |- Macon\n  |- Madison\n  |- Martin\n  |- McDowell\n  |- Mecklenburg\n  |- Mitchell\n  |- Montgomery\n  |- Moore\n  |- Nash\n  |- New Hanover\n  |- Northampton\n  |- Onslow\n  |- Orange\n  |- Pamlico\n  |- Pasquotank\n  |- Pender\n  |- Perquimans\n  |- Person\n  |- Pitt\n  |- Polk\n  |- Randolph\n  |- Richmond\n  |- Robeson\n  |- Rockingham\n  |- Rowan\n  |- Rutherford\n  |- Sampson\n  |- Scotland\n  |- Stanly\n  |- Stokes\n  |- Surry\n  |- Swain\n  |- Transylvania\n  |- Tyrrell\n  |- Unassigned\n  |- Union\n  |- Vance\n  |- Wake\n  |- Warren\n  |- Washington\n  |- Watauga\n  |- Wayne\n  |- Wilkes\n  |- Wilson\n  |- Yadkin\n  |- Yancey\n|- North Dakota\n  |- Adams\n  |- Barnes\n  |- Benson\n  |- Billings\n  |- Bottineau\n  |- Bowman\n  |- Burke\n  |- Burleigh\n  |- Cass\n  |- Cavalier\n  |- Dickey\n  |- Divide\n  |- Dunn\n  |- Eddy\n  |- Emmons\n  |- Foster\n  |- Golden Valley\n  |- Grand Forks\n  |- Grant\n  |- Griggs\n  |- Hettinger\n  |- Kidder\n  |- LaMoure\n  |- Logan\n  |- McHenry\n  |- McIntosh\n  |- McKenzie\n  |-McLean\n  |- Mercer\n  |- Morton\n  |- Mountrail\n  |- Nelson\n  |- Oliver\n  |- Pembina\n  |- Pierce\n  |- Ramsey\n  |- Ransom\n  |- Renville\n  |- Richland\n  |- Rolette\n  |- Sargent\n  |- Sheridan\n  |- Sioux\n  |- Slope\n  |- Stark\n  |- Steele\n  |- Stutsman\n  |- Towner\n  |- Traill\n  |- Unassigned\n  |- Walsh\n  |- Ward\n  |- Wells\n  |- Williams\n|- Northern Mariana Islands\n|- Norwell County, MA\n|- Ohio\n  |- Adams\n  |- Allen\n  |- Ashland\n  |- Ashtabula\n  |- Athens\n  |- Auglaize\n  |- Belmont\n  |- Brown\n  |- Butler\n  |- Carroll\n  |- Champaign\n  |- Clark\n  |- Clermont\n  |- Clinton\n  |- Columbiana\n  |- Coshocton\n  |- Crawford\n  |- Cuyahoga\n  |- Darke\n  |- Defiance\n  |- Delaware\n  |- Erie\n  |- Fairfield\n  |- Fayette\n  |- Franklin\n  |- Fulton\n  |- Gallia\n  |- Geauga\n  |- Greene\n  |- Guernsey\n  |- Hamilton\n  |- Hancock\n  |- Hardin\n  |- Harrison\n  |- Henry\n  |- Highland\n  |- Hocking\n  |- Holmes\n  |- Huron\n  |- Jackson\n  |- Jefferson\n  |- Knox\n  |- Lake\n  |- Lawrence\n  |- Licking\n  |- Logan\n  |- Lorain\n  |- Lucas\n  |- Madison\n  |- Mahoning\n  |- Marion\n  |- Medina\n  |- Meigs\n  |- Mercer\n  |- Miami\n  |- Monroe\n  |- Montgomery\n  |- Morgan\n  |- Morrow\n  |- Muskingum\n  |- Noble\n  |- Ottawa\n  |- Paulding\n  |- Perry\n  |- Pickaway\n  |- Pike\n  |- Portage\n  |- Preble\n  |- Putnam\n  |- Richland\n  |- Ross\n  |- Sandusky\n  |- Scioto\n  |- Seneca\n  |- Shelby\n  |- Stark\n  |- Summit\n  |- Trumbull\n  |- Tuscarawas\n  |- Unassigned\n  |- Union\n  |- Van Wert\n  |- Vinton\n  |- Warren\n  |- Washington\n  |- Wayne\n  |- Williams\n  |- Wood\n  |- Wyandot\n|- Okaloosa County, FL\n|- Oklahoma\n  |- Adair\n  |- Alfalfa\n  |- Atoka\n  |- Beaver\n  |- Beckham\n  |- Blaine\n  |- Bryan\n  |- Caddo\n  |- Canadian\n  |- Carter\n  |- Cherokee\n  |- Choctaw\n  |- Cimarron\n  |- Cleveland\n  |- Coal\n  |- Comanche\n  |- Cotton\n  |- Craig\n  |- Creek\n  |- Custer\n  |- Delaware\n  |- Dewey\n  |- Ellis\n  |- Garfield\n  |- Garvin\n  |- Grady\n  |- Grant\n  |- Greer\n  |- Harmon\n  |- Harper\n  |- Haskell\n  |- Hughes\n  |- Jackson\n  |- Jefferson\n  |- Johnston\n  |- Kay\n  |- Kingfisher\n  |- Kiowa\n  |- Latimer\n  |- Le Flore\n  |- Lincoln\n  |- Logan\n  |- Love\n  |- Major\n  |- Marshall\n  |- Mayes\n  |- McClain\n  |- McCurtain\n  |- McIntosh\n  |- Murray\n  |- Muskogee\n  |- Noble\n  |- Nowata\n  |- Okfuskee\n  |- Oklahoma\n  |- Okmulgee\n  |- Osage\n  |- Ottawa\n  |- Out of OK\n  |- Pawnee\n  |- Payne\n  |- Pittsburg\n  |- Pontotoc\n  |- Pottawatomie\n  |- Pushmataha\n  |- Roger Mills\n  |- Rogers\n  |- Seminole\n  |- Sequoyah\n  |- Stephens\n  |- Texas\n  |- Tillman\n  |- Tulsa\n  |- Unassigned\n  |- Wagoner\n  |- Washington\n  |- Washita\n  |- Woods\n  |- Woodward\n|- Omaha, NE (From Diamond Princess)\n|- Orange County, CA\n|- Orange, CA\n|- Oregon\n  |- Baker\n  |- Benton\n  |- Clackamas\n  |- Clatsop\n  |- Columbia\n  |- Coos\n  |- Crook\n  |- Curry\n  |- Deschutes\n  |- Douglas\n  |- Gilliam\n  |- Grant\n  |- Harney\n  |- Hood River\n  |- Jackson\n  |- Jefferson\n  |- Josephine\n  |- Klamath\n  |- Lake\n  |- Lane\n  |- Lincoln\n  |- Linn\n  |- Malheur\n  |- Marion\n  |- Morrow\n  |- Multnomah\n  |- Polk\n  |- Sherman\n  |- Tillamook\n  |- Umatilla\n  |- Unassigned\n  |- Union\n  |- Wallowa\n  |- Wasco\n  |- Washington\n  |- Wheeler\n  |- Yamhill\n|- Pennsylvania\n  |- Adams\n  |- Allegheny\n  |- Armstrong\n  |- Beaver\n  |- Bedford\n  |- Berks\n  |- Blair\n  |- Bradford\n  |- Bucks\n  |- Butler\n  |- Cambria\n  |- Cameron\n  |- Carbon\n  |- Centre\n  |- Chester\n  |- Clarion\n  |- Clearfield\n  |- Clinton\n  |- Columbia\n  |- Crawford\n  |- Cumberland\n  |- Dauphin\n  |- Delaware\n  |- Elk\n  |- Erie\n  |- Fayette\n  |- Forest\n  |- Franklin\n  |- Fulton\n  |- Greene\n  |- Huntingdon\n  |- Indiana\n  |- Jefferson\n  |- Juniata\n  |- Lackawanna\n  |- Lancaster\n  |- Lawrence\n  |- Lebanon\n  |- Lehigh\n  |- Luzerne\n  |- Lycoming\n  |- McKean\n  |- Mercer\n  |- Mifflin\n  |- Monroe\n  |- Montgomery\n  |- Montour\n  |- Northampton\n  |- Northumberland\n  |- Perry\n  |- Philadelphia\n  |- Pike\n  |- Potter\n  |- Schuylkill\n  |- Snyder\n  |- Somerset\n  |- Sullivan\n  |- Susquehanna\n  |- Tioga\n  |- Unassigned\n  |- Union\n  |- Venango\n  |- Warren\n  |- Washington\n  |- Wayne\n  |- Westmoreland\n  |- Wyoming\n  |- York\n|- Pierce County, WA\n|- Pinal County, AZ\n|- Placer County, CA\n|- Plymouth County, MA\n|- Polk County, GA\n|- Portland, OR\n|- Providence County, RI\n|- Providence, RI\n|- Puerto Rico\n|- Queens County, NY\n|- Ramsey County, MN\n|- Recovered\n|- Rhode Island\n  |- Bristol\n  |- Kent\n  |- Newport\n  |- Providence\n  |- Unassigned\n  |- Washington\n|- Riverside County, CA\n|- Rockingham County, NH\n|- Rockland County, NY\n|- Sacramento County, CA\n|- San Antonio, TX\n|- San Benito, CA\n|- San Diego County, CA\n|- San Francisco County, CA\n|- San Mateo, CA\n|- Santa Clara County, CA\n|- Santa Clara, CA\n|- Santa Cruz County, CA\n|- Santa Rosa County, FL\n|- Sarasota, FL\n|- Saratoga County, NY\n|- Seattle, WA\n|- Shasta County, CA\n|- Shelby County, TN\n|- Snohomish County, WA\n|- Sonoma County, CA\n|- South Carolina\n  |- Abbeville\n  |- Aiken\n  |- Allendale\n  |- Anderson\n  |- Bamberg\n  |- Barnwell\n  |- Beaufort\n  |- Berkeley\n  |- Calhoun\n  |- Charleston\n  |- Cherokee\n  |- Chester\n  |- Chesterfield\n  |- Clarendon\n  |- Colleton\n  |- Darlington\n  |- Dillon\n  |- Dorchester\n  |- Edgefield\n  |- Fairfield\n  |- Florence\n  |- Georgetown\n  |- Greenville\n  |- Greenwood\n  |- Hampton\n  |- Horry\n  |- Jasper\n  |- Kershaw\n  |- Lancaster\n  |- Laurens\n  |- Lee\n  |- Lexington\n  |- Marion\n  |- Marlboro\n  |- McCormick\n  |- Newberry\n  |- Oconee\n  |- Orangeburg\n  |- Pickens\n  |- Richland\n  |- Saluda\n  |- Spartanburg\n  |- Sumter\n  |- Unassigned\n  |- Union\n  |- Williamsburg\n  |- York\n|- South Dakota\n  |- Aurora\n  |- Beadle\n  |- Bennett\n  |- Bon Homme\n  |- Brookings\n  |- Brown\n  |- Brule\n  |- Buffalo\n  |- Butte\n  |- Campbell\n  |- Charles Mix\n  |- Clark\n  |- Clay\n  |- Codington\n  |- Corson\n  |- Custer\n  |- Davison\n  |- Day\n  |- Deuel\n  |- Dewey\n  |- Douglas\n  |- Edmunds\n  |- Fall River\n  |- Faulk\n  |- Grant\n  |- Gregory\n  |- Haakon\n  |- Hamlin\n  |- Hand\n  |- Hanson\n  |- Harding\n  |- Hughes\n  |- Hutchinson\n  |- Hyde\n  |- Jackson\n  |- Jerauld\n  |- Jones\n  |- Kingsbury\n  |- Lake\n  |- Lawrence\n  |- Lincoln\n  |- Lyman\n  |- Marshall\n  |- McCook\n  |- McPherson\n  |- Meade\n  |- Mellette\n  |- Miner\n  |- Minnehaha\n  |- Moody\n  |- Oglala Lakota\n  |- Pennington\n  |- Perkins\n  |- Potter\n  |- Roberts\n  |- Sanborn\n  |- Spink\n  |- Stanley\n  |- Sully\n  |- Todd\n  |- Tripp\n  |- Turner\n  |- Unassigned\n  |- Union\n  |- Walworth\n  |- Yankton\n  |- Ziebach\n|- Spartanburg County, SC\n|- Spokane County, WA\n|- St. Louis County, MO\n|- Suffolk County, MA\n|- Suffolk County, NY\n|- Summit County, CO\n|- Tempe, AZ\n|- Tennessee\n  |- Anderson\n  |- Bedford\n  |- Benton\n  |- Bledsoe\n  |- Blount\n  |- Bradley\n  |- Campbell\n  |- Cannon\n  |- Carroll\n  |- Carter\n  |- Cheatham\n  |- Chester\n  |- Claiborne\n  |- Clay\n  |- Cocke\n  |- Coffee\n  |- Crockett\n  |- Cumberland\n  |- Davidson\n  |- DeKalb\n  |- Decatur\n  |- Dickson\n  |- Dyer\n  |- Fayette\n  |- Fentress\n  |- Franklin\n  |- Gibson\n  |- Giles\n  |- Grainger\n  |- Greene\n  |- Grundy\n  |- Hamblen\n  |- Hamilton\n  |- Hancock\n  |- Hardeman\n  |- Hardin\n  |- Hawkins\n  |- Haywood\n  |- Henderson\n  |- Henry\n  |- Hickman\n  |- Houston\n  |- Humphreys\n  |- Jackson\n  |- Jefferson\n  |- Johnson\n  |- Knox\n  |- Lake\n  |- Lauderdale\n  |- Lawrence\n  |- Lewis\n  |- Lincoln\n  |- Loudon\n  |- Macon\n  |- Madison\n  |- Marion\n  |- Marshall\n  |- Maury\n  |- McMinn\n  |- McNairy\n  |- Meigs\n  |- Monroe\n  |- Montgomery\n  |- Moore\n  |- Morgan\n  |- Obion\n  |- Out of TN\n  |- Out-of-state\n  |- Overton\n  |- Perry\n  |- Pickett\n  |- Polk\n  |- Putnam\n  |- Rhea\n  |- Roane\n  |- Robertson\n  |- Rutherford\n  |- Scott\n  |- Sequatchie\n  |- Sevier\n  |- Shelby\n  |- Smith\n  |- Stewart\n  |- Sullivan\n  |- Sumner\n  |- Tipton\n  |- Trousdale\n  |- Unassigned\n  |- Unicoi\n  |- Union\n  |- Unknown\n  |- Van Buren\n  |- Warren\n  |- Washington\n  |- Wayne\n  |- Weakley\n  |- White\n  |- Williamson\n  |- Wilson\n|- Texas\n  |- Anderson\n  |- Andrews\n  |- Angelina\n  |- Aransas\n  |- Archer\n  |- Armstrong\n  |- Atascosa\n  |- Austin\n  |- Bailey\n  |- Bandera\n  |- Bastrop\n  |- Baylor\n  |- Bee\n  |- Bell\n  |- Bexar\n  |- Blanco\n  |- Borden\n  |- Bosque\n  |- Bowie\n  |- Brazoria\n  |- Brazos\n  |- Brewster\n  |- Briscoe\n  |- Brooks\n  |- Brown\n  |- Burleson\n  |- Burnet\n  |- Caldwell\n  |- Calhoun\n  |- Callahan\n  |- Cameron\n  |- Camp\n  |- Carson\n  |- Cass\n  |- Castro\n  |- Chambers\n  |- Cherokee\n  |- Childress\n  |- Clay\n  |- Cochran\n  |- Coke\n  |- Coleman\n  |- Collin\n  |- Collingsworth\n  |- Colorado\n  |- Comal\n  |- Comanche\n  |- Concho\n  |- Cooke\n  |- Coryell\n  |- Cottle\n  |- Crane\n  |- Crockett\n  |- Crosby\n  |- Culberson\n  |- Dallam\n  |- Dallas\n  |- Dawson\n  |- DeWitt\n  |- Deaf Smith\n  |- Delta\n  |- Denton\n  |- Dickens\n  |- Dimmit\n  |- Donley\n  |- Duval\n  |- Eastland\n  |- Ector\n  |- Edwards\n  |- El Paso\n  |- Ellis\n  |- Erath\n  |- Falls\n  |- Fannin\n  |- Fayette\n  |- Fisher\n  |- Floyd\n  |- Foard\n  |- Fort Bend\n  |- Franklin\n  |- Freestone\n  |- Frio\n  |- Gaines\n  |- Galveston\n  |- Garza\n  |- Gillespie\n  |- Glasscock\n  |- Goliad\n  |- Gonzales\n  |- Gray\n  |- Grayson\n  |- Gregg\n  |- Grimes\n  |- Guadalupe\n  |- Hale\n  |- Hall\n  |- Hamilton\n  |- Hansford\n  |- Hardeman\n  |- Hardin\n  |- Harris\n  |- Harrison\n  |- Hartley\n  |- Haskell\n  |- Hays\n  |- Hemphill\n  |- Henderson\n  |- Hidalgo\n  |- Hill\n  |- Hockley\n  |- Hood\n  |- Hopkins\n  |- Houston\n  |- Howard\n  |- Hudspeth\n  |- Hunt\n  |- Hutchinson\n  |- Irion\n  |- Jack\n  |- Jackson\n  |- Jasper\n  |- Jeff Davis\n  |- Jefferson\n  |- Jim Hogg\n  |- Jim Wells\n  |- Johnson\n  |- Jones\n  |- Karnes\n  |- Kaufman\n  |- Kendall\n  |- Kenedy\n  |- Kent\n  |- Kerr\n  |- Kimble\n  |- King\n  |- Kinney\n  |- Kleberg\n  |- Knox\n  |- La Salle\n  |- Lamar\n  |- Lamb\n  |- Lampasas\n  |- Lavaca\n  |- Lee\n  |- Leon\n  |- Liberty\n  |- Limestone\n  |- Lipscomb\n  |- Live Oak\n  |- Llano\n  |- Loving\n  |- Lubbock\n  |- Lynn\n  |- Madison\n  |- Marion\n  |- Martin\n  |- Mason\n  |- Matagorda\n  |- Maverick\n  |- McCulloch\n  |- McLennan\n  |- McMullen\n  |- Medina\n  |- Menard\n  |- Midland\n  |- Milam\n  |- Mills\n  |- Mitchell\n  |- Montague\n  |- Montgomery\n  |- Moore\n  |- Morris\n  |- Motley\n  |- Nacogdoches\n  |- Navarro\n  |- Newton\n  |- Nolan\n  |- Nueces\n  |- Ochiltree\n  |- Oldham\n  |- Orange\n  |- Palo Pinto\n  |- Panola\n  |- Parker\n  |- Parmer\n  |- Pecos\n  |- Polk\n  |- Potter\n  |- Presidio\n  |- Rains\n  |- Randall\n  |- Reagan\n  |- Real\n  |- Red River\n  |- Reeves\n  |- Refugio\n  |- Roberts\n  |- Robertson\n  |- Rockwall\n  |- Runnels\n  |- Rusk\n  |- Sabine\n  |- San Augustine\n  |- San Jacinto\n  |- San Patricio\n  |- San Saba\n  |- Schleicher\n  |- Scurry\n  |- Shackelford\n  |- Shelby\n  |- Sherman\n  |- Smith\n  |- Somervell\n  |- Starr\n  |- Stephens\n  |- Sterling\n  |- Stonewall\n  |- Sutton\n  |- Swisher\n  |- Tarrant\n  |- Taylor\n  |- Terrell\n  |- Terry\n  |- Throckmorton\n  |- Titus\n  |- Tom Green\n  |- Travis\n  |- Trinity\n  |- Tyler\n  |- Unassigned\n  |- Upshur\n  |- Upton\n  |- Uvalde\n  |- Val Verde\n  |- Van Zandt\n  |- Victoria\n  |- Walker\n  |- Waller\n  |- Ward\n  |- Washington\n  |- Webb\n  |- Wharton\n  |- Wheeler\n  |- Wichita\n  |- Wilbarger\n  |- Willacy\n  |- Williamson\n  |- Wilson\n  |- Winkler\n  |- Wise\n  |- Wood\n  |- Yoakum\n  |- Young\n  |- Zapata\n  |- Zavala\n|- Travis, CA\n|- Travis, CA (From Diamond Princess)\n|- Tulsa County, OK\n|- Ulster County, NY\n|- Umatilla, OR\n|- Unassigned Location (From Diamond Princess)\n|- Unassigned Location, VT\n|- Unassigned Location, WA\n|- United States Virgin Islands\n|- United States of America\n|- Unknown Location, MA\n|- Utah\n  |- Bear River\n  |- Beaver\n  |- Box Elder\n  |- Cache\n  |- Carbon\n  |- Central Utah\n  |- Daggett\n  |- Davis\n  |- Duchesne\n  |- Emery\n  |- Garfield\n  |- Grand\n  |- Iron\n  |- Juab\n  |- Kane\n  |- Millard\n  |- Morgan\n  |- Out of UT\n  |- Piute\n  |- Rich\n  |- Salt Lake\n  |- San Juan\n  |- Sanpete\n  |- Sevier\n  |- Southeast Utah\n  |- Southwest\n  |- Southwest Utah\n  |- Summit\n  |- Tooele\n  |- TriCounty\n  |- Uintah\n  |- Unassigned\n  |- Utah\n  |- Wasatch\n  |- Washington\n  |- Washington County\n  |- Wayne\n  |- Weber\n  |- Weber-Morgan\n  |- unassigned\n|- Vermont\n  |- Addison\n  |- Bennington\n  |- Caledonia\n  |- Chittenden\n  |- Essex\n  |- Franklin\n  |- Grand Isle\n  |- Lamoille\n  |- Orange\n  |- Orleans\n  |- Rutland\n  |- Unassigned\n  |- Washington\n  |- Windham\n  |- Windsor\n|- Virgin Islands\n|- Virgin Islands, U.S.\n|- Virginia\n  |- Accomack\n  |- Albemarle\n  |- Alexandria\n  |- Alleghany\n  |- Amelia\n  |- Amherst\n  |- Appomattox\n  |- Arlington\n  |- Augusta\n  |- Bath\n  |- Bedford\n  |- Bland\n  |- Botetourt\n  |- Bristol\n  |- Brunswick\n  |- Buchanan\n  |- Buckingham\n  |- Buena Vista\n  |- Campbell\n  |- Caroline\n  |- Carroll\n  |- Charles City\n  |- Charlotte\n  |- Charlottesville\n  |- Chesapeake\n  |- Chesterfield\n  |- Clarke\n  |- Colonial Heights\n  |- Covington\n  |- Craig\n  |- Culpeper\n  |- Cumberland\n  |- Danville\n  |- Dickenson\n  |- Dinwiddie\n  |- Emporia\n  |- Essex\n  |- Fairfax\n  |- Fairfax City\n  |- Falls Church\n  |- Fauquier\n  |- Floyd\n  |- Fluvanna\n  |- Franklin\n  |- Franklin City\n  |- Frederick\n  |- Fredericksburg\n  |- Galax\n  |- Giles\n  |- Gloucester\n  |- Goochland\n  |- Grayson\n  |- Greene\n  |- Greensville\n  |- Halifax\n  |- Hampton\n  |- Hanover\n  |- Harrisonburg\n  |- Henrico\n  |- Henry\n  |- Highland\n  |- Hopewell\n  |- Isle of Wight\n  |- James City\n  |- King George\n  |- King William\n  |- King and Queen\n  |- Lancaster\n  |- Lee\n  |- Lexington\n  |- Loudoun\n  |- Louisa\n  |- Lunenburg\n  |- Lynchburg\n  |- Madison\n  |- Manassas\n  |- Manassas Park\n  |- Martinsville\n  |- Mathews\n  |- Mecklenburg\n  |- Middlesex\n  |- Montgomery\n  |- Nelson\n  |- New Kent\n  |- Newport News\n  |- Norfolk\n  |- Northampton\n  |- Northumberland\n  |- Norton\n  |- Nottoway\n  |- Orange\n  |- Page\n  |- Patrick\n  |- Petersburg\n  |- Pittsylvania\n  |- Poquoson\n  |- Portsmouth\n  |- Powhatan\n  |- Prince Edward\n  |- Prince George\n  |- Prince William\n  |- Pulaski\n  |- Radford\n  |- Rappahannock\n  |- Richmond\n  |- Richmond City\n  |- Roanoke\n  |- Roanoke City\n  |- Rockbridge\n  |- Rockingham\n  |- Russell\n  |- Salem\n  |- Scott\n  |- Shenandoah\n  |- Smyth\n  |- Southampton\n  |- Spotsylvania\n  |- Stafford\n  |- Staunton\n  |- Suffolk\n  |- Surry\n  |- Sussex\n  |- Tazewell\n  |- Unassigned\n  |- Virginia Beach\n  |- Warren\n  |- Washington\n  |- Waynesboro\n  |- Westmoreland\n  |- Williamsburg\n  |- Winchester\n  |- Wise\n  |- Wythe\n  |- York\n|- Volusia County, FL\n|- Wake County, NC\n|- Washington\n  |- Adams\n  |- Asotin\n  |- Benton\n  |- Chelan\n  |- Clallam\n  |- Clark\n  |- Columbia\n  |- Cowlitz\n  |- Douglas\n  |- Ferry\n  |- Franklin\n  |- Garfield\n  |- Garfield County\n  |- Grant\n  |- Grays Harbor\n  |- Island\n  |- Jefferson\n  |- King\n  |- Kitsap\n  |- Kittitas\n  |- Klickitat\n  |- Lewis\n  |- Lincoln\n  |- Mason\n  |- Okanogan\n  |- Pacific\n  |- Pend Oreille\n  |- Pierce\n  |- San Juan\n  |- Skagit\n  |- Skamania\n  |- Snohomish\n  |- Spokane\n  |- Stevens\n  |- Thurston\n  |- Unassigned\n  |- Wahkiakum\n  |- Walla Walla\n  |- Walla Walla County\n  |- Whatcom\n  |- Whitman\n  |- Yakima\n|- Washington County, OR\n|- Washington, D.C.\n|- Washoe County, NV\n|- Wayne County, PA\n|- West Virginia\n  |- Barbour\n  |- Berkeley\n  |- Boone\n  |- Braxton\n  |- Brooke\n  |- Cabell\n  |- Calhoun\n  |- Clay\n  |- Doddridge\n  |- Fayette\n  |- Gilmer\n  |- Grant\n  |- Greenbrier\n  |- Hampshire\n  |- Hancock\n  |- Hardy\n  |- Harrison\n  |- Jackson\n  |- Jefferson\n  |- Kanawha\n  |- Lewis\n  |- Lincoln\n  |- Logan\n  |- Marion\n  |- Marshall\n  |- Mason\n  |- McDowell\n  |- Mercer\n  |- Mineral\n  |- Mingo\n  |- Monongalia\n  |- Monroe\n  |- Morgan\n  |- Nicholas\n  |- Ohio\n  |- Pendleton\n  |- Pleasants\n  |- Pocahontas\n  |- Preston\n  |- Putnam\n  |- Raleigh\n  |- Randolph\n  |- Ritchie\n  |- Roane\n  |- Summers\n  |- Taylor\n  |- Tucker\n  |- Tyler\n  |- Unassigned\n  |- Upshur\n  |- Wayne\n  |- Webster\n  |- Wetzel\n  |- Wirt\n  |- Wood\n  |- Wyoming\n|- Westchester County, NY\n|- Williamson County, TN\n|- Wisconsin\n  |- Adams\n  |- Ashland\n  |- Barron\n  |- Bayfield\n  |- Brown\n  |- Buffalo\n  |- Burnett\n  |- Calumet\n  |- Chippewa\n  |- Clark\n  |- Columbia\n  |- Crawford\n  |- Dane\n  |- Dodge\n  |- Door\n  |- Douglas\n  |- Dunn\n  |- Eau Claire\n  |- Florence\n  |- Fond du Lac\n  |- Forest\n  |- Grant\n  |- Green\n  |- Green Lake\n  |- Iowa\n  |- Iron\n  |- Jackson\n  |- Jefferson\n  |- Juneau\n  |- Kenosha\n  |- Kewaunee\n  |- La Crosse\n  |- Lafayette\n  |- Langlade\n  |- Lincoln\n  |- Manitowoc\n  |- Marathon\n  |- Marinette\n  |- Marquette\n  |- Menominee\n  |- Milwaukee\n  |- Monroe\n  |- Oconto\n  |- Oneida\n  |- Outagamie\n  |- Ozaukee\n  |- Pepin\n  |- Pierce\n  |- Polk\n  |- Portage\n  |- Price\n  |- Racine\n  |- Richland\n  |- Rock\n  |- Rusk\n  |- Sauk\n  |- Sawyer\n  |- Shawano\n  |- Sheboygan\n  |- St. Croix\n  |- Taylor\n  |- Trempealeau\n  |- Unassigned\n  |- Vernon\n  |- Vilas\n  |- Walworth\n  |- Washburn\n  |- Washington\n  |- Waukesha\n  |- Waupaca\n  |- Waushara\n  |- Winnebago\n  |- Wood\n|- Wuhan Evacuee\n  |- Unassigned\n|- Wyoming\n  |- Albany\n  |- Big Horn\n  |- Campbell\n  |- Carbon\n  |- Converse\n  |- Crook\n  |- Fremont\n  |- Goshen\n  |- Hot Springs\n  |- Johnson\n  |- Laramie\n  |- Lincoln\n  |- Natrona\n  |- Niobrara\n  |- Park\n  |- Platte\n  |- Sheridan\n  |- Sublette\n  |- Sweetwater\n  |- Teton\n  |- Uinta\n  |- Unassigned\n  |- Washakie\n  |- Weston\n  |- unassigned\n|- Yolo County, CA\nUruguay\nUzbekistan\nVatican City\nVenezuela\nVietnam\nWest Bank and Gaza\nWestern Sahara\nYemen\nZambia\nZimbabwe\noccupied Palestinian territory\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxckblDFlpU-",
        "colab_type": "code",
        "outputId": "66f7a5db-e20e-470d-8cb2-ad0ec9691c6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        }
      },
      "source": [
        "# clean the province/state column after visually inspecting output above\n",
        "df[\"Province/State\"].replace('None', np.nan, inplace=True)\n",
        "df[df[\"Province/State\"] == \"Recovered\"].head(10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "      Province/State            Country/Region         Last Update  Confirmed  \\\n17676      Recovered                    Canada 2020-03-24 23:41:36        0.0   \n17677      Recovered  United States of America 2020-03-24 23:37:31        0.0   \n21092      Recovered                    Canada 2020-03-25 23:37:36        0.0   \n21093      Recovered  United States of America 2020-03-25 23:33:19        0.0   \n24510      Recovered                    Canada 2020-03-26 23:53:11        0.0   \n24511      Recovered  United States of America 2020-03-26 23:48:35        0.0   \n27938      Recovered                    Canada 2020-03-27 23:27:32        0.0   \n27939      Recovered  United States of America 2020-03-27 22:14:55        0.0   \n31366      Recovered                    Canada 2020-03-28 23:10:00        0.0   \n31367      Recovered  United States of America 2020-03-28 23:05:00        0.0   \n\n       Deaths  Recovered       Date  Latitude  Longitude  FIPS County  Active  \\\n17676     0.0      110.0 2020-03-24       0.0        0.0   NaN    nan     0.0   \n17677     0.0      348.0 2020-03-24       0.0        0.0   NaN    nan     0.0   \n21092     0.0      183.0 2020-03-25       0.0        0.0   NaN    nan     0.0   \n21093     0.0      361.0 2020-03-25       0.0        0.0   NaN    nan     0.0   \n24510     0.0      184.0 2020-03-26       0.0        0.0   NaN    nan     0.0   \n24511     0.0      681.0 2020-03-26       0.0        0.0   NaN    nan     0.0   \n27938     0.0      256.0 2020-03-27       0.0        0.0   NaN    nan     0.0   \n27939     0.0      869.0 2020-03-27       0.0        0.0   NaN    nan     0.0   \n31366     0.0      466.0 2020-03-28       0.0        0.0   NaN    nan     0.0   \n31367     0.0     1072.0 2020-03-28       0.0        0.0   NaN    nan     0.0   \n\n            Combined_Key  \n17676  Recovered, Canada  \n17677      Recovered, US  \n21092  Recovered, Canada  \n21093      Recovered, US  \n24510  Recovered, Canada  \n24511      Recovered, US  \n27938  Recovered, Canada  \n27939      Recovered, US  \n31366  Recovered, Canada  \n31367      Recovered, US  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>Last Update</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n      <th>Date</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>FIPS</th>\n      <th>County</th>\n      <th>Active</th>\n      <th>Combined_Key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17676</th>\n      <td>Recovered</td>\n      <td>Canada</td>\n      <td>2020-03-24 23:41:36</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>110.0</td>\n      <td>2020-03-24</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>0.0</td>\n      <td>Recovered, Canada</td>\n    </tr>\n    <tr>\n      <th>17677</th>\n      <td>Recovered</td>\n      <td>United States of America</td>\n      <td>2020-03-24 23:37:31</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>348.0</td>\n      <td>2020-03-24</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>0.0</td>\n      <td>Recovered, US</td>\n    </tr>\n    <tr>\n      <th>21092</th>\n      <td>Recovered</td>\n      <td>Canada</td>\n      <td>2020-03-25 23:37:36</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>183.0</td>\n      <td>2020-03-25</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>0.0</td>\n      <td>Recovered, Canada</td>\n    </tr>\n    <tr>\n      <th>21093</th>\n      <td>Recovered</td>\n      <td>United States of America</td>\n      <td>2020-03-25 23:33:19</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>361.0</td>\n      <td>2020-03-25</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>0.0</td>\n      <td>Recovered, US</td>\n    </tr>\n    <tr>\n      <th>24510</th>\n      <td>Recovered</td>\n      <td>Canada</td>\n      <td>2020-03-26 23:53:11</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>184.0</td>\n      <td>2020-03-26</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>0.0</td>\n      <td>Recovered, Canada</td>\n    </tr>\n    <tr>\n      <th>24511</th>\n      <td>Recovered</td>\n      <td>United States of America</td>\n      <td>2020-03-26 23:48:35</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>681.0</td>\n      <td>2020-03-26</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>0.0</td>\n      <td>Recovered, US</td>\n    </tr>\n    <tr>\n      <th>27938</th>\n      <td>Recovered</td>\n      <td>Canada</td>\n      <td>2020-03-27 23:27:32</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>256.0</td>\n      <td>2020-03-27</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>0.0</td>\n      <td>Recovered, Canada</td>\n    </tr>\n    <tr>\n      <th>27939</th>\n      <td>Recovered</td>\n      <td>United States of America</td>\n      <td>2020-03-27 22:14:55</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>869.0</td>\n      <td>2020-03-27</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>0.0</td>\n      <td>Recovered, US</td>\n    </tr>\n    <tr>\n      <th>31366</th>\n      <td>Recovered</td>\n      <td>Canada</td>\n      <td>2020-03-28 23:10:00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>466.0</td>\n      <td>2020-03-28</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>0.0</td>\n      <td>Recovered, Canada</td>\n    </tr>\n    <tr>\n      <th>31367</th>\n      <td>Recovered</td>\n      <td>United States of America</td>\n      <td>2020-03-28 23:05:00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1072.0</td>\n      <td>2020-03-28</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>0.0</td>\n      <td>Recovered, US</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0KJRuyOuvv3",
        "colab_type": "code",
        "outputId": "c4707756-9c1c-40c3-a6c9-8fdb3d8213ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "df.loc[(df[\"Country/Region\"] == \"Canada\") & (df.Date == pd.datetime(2020, 3, 24)), :].Recovered.agg(\"sum\")\n",
        "# the following result demonstrates that the rows where column \n",
        "# Province/State == \"Recovered\" is an aggregate which can be derived\n",
        "# there these rows are duplicates and will be deleted"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "110.0"
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDzmANCz0sV2",
        "colab_type": "code",
        "outputId": "e486134e-a718-4651-9f93-91f4b9af21fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "df.loc[(df[\"Country/Region\"] == \"Others\") & (df[\"Province/State\"] == \"Diamond Princess cruise ship\"), \"Province/State\"] = \"Diamond Princess\"\n",
        "df.loc[df[\"Country/Region\"] == \"Others\", \"Country/Region\"] = \"Cruise Ship\"\n",
        "\n",
        "#Combine US states: Grand Princess and Grand Princess cruise ship\n",
        "df[df[\"Province/State\"] == \"Grand Princess Cruise Ship\"].head(10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "                  Province/State            Country/Region  \\\n3836  Grand Princess Cruise Ship  United States of America   \n4067  Grand Princess Cruise Ship  United States of America   \n4323  Grand Princess Cruise Ship  United States of America   \n\n             Last Update  Confirmed  Deaths  Recovered       Date  Latitude  \\\n3836 2020-03-07 01:33:02       21.0     0.0        0.0 2020-03-07   37.6489   \n4067 2020-03-07 01:33:02       21.0     0.0        0.0 2020-03-08   37.6489   \n4323 2020-03-07 01:33:02       21.0     0.0        0.0 2020-03-09   37.6489   \n\n      Longitude  FIPS County  Active Combined_Key  \n3836  -122.6655   NaN    nan     NaN          NaN  \n4067  -122.6655   NaN    nan     NaN          NaN  \n4323  -122.6655   NaN    nan     NaN          NaN  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>Last Update</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n      <th>Date</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>FIPS</th>\n      <th>County</th>\n      <th>Active</th>\n      <th>Combined_Key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3836</th>\n      <td>Grand Princess Cruise Ship</td>\n      <td>United States of America</td>\n      <td>2020-03-07 01:33:02</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-07</td>\n      <td>37.6489</td>\n      <td>-122.6655</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4067</th>\n      <td>Grand Princess Cruise Ship</td>\n      <td>United States of America</td>\n      <td>2020-03-07 01:33:02</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-08</td>\n      <td>37.6489</td>\n      <td>-122.6655</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4323</th>\n      <td>Grand Princess Cruise Ship</td>\n      <td>United States of America</td>\n      <td>2020-03-07 01:33:02</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-09</td>\n      <td>37.6489</td>\n      <td>-122.6655</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDsxOWYlxLfD",
        "colab_type": "code",
        "outputId": "db5480e5-c097-4f9a-ec6c-3ccf99bb57fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        }
      },
      "source": [
        "df = df[df[\"Province/State\"] != \"Recovered\"]\n",
        "\n",
        "#Diamond Princess country move to Cruise ship country\n",
        "df[df[\"Country/Region\"] == \"Diamond Princess\"].head(10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "      Province/State    Country/Region         Last Update  Confirmed  Deaths  \\\n21155            nan  Diamond Princess 2020-03-25 23:33:04      712.0    10.0   \n24574            nan  Diamond Princess 2020-03-26 23:48:18      712.0    10.0   \n28003            nan  Diamond Princess 2020-03-27 23:23:03      712.0    10.0   \n31432            nan  Diamond Princess 2020-03-28 23:05:00      712.0    10.0   \n34866            nan  Diamond Princess 2020-03-29 23:08:00      712.0    10.0   \n38305            nan  Diamond Princess 2020-03-30 22:52:00      712.0    10.0   \n40738            nan  Diamond Princess 2020-03-31 23:43:43      712.0    10.0   \n43221            nan  Diamond Princess 2020-04-01 21:58:34      712.0    11.0   \n45788            nan  Diamond Princess 2020-04-02 23:25:00      712.0    11.0   \n48412            nan  Diamond Princess 2020-04-03 22:46:20      712.0    11.0   \n\n       Recovered       Date  Latitude  Longitude  FIPS County  Active  \\\n21155      587.0 2020-03-25       0.0        0.0   NaN    nan   115.0   \n24574      597.0 2020-03-26       0.0        0.0   NaN    nan   105.0   \n28003      597.0 2020-03-27       0.0        0.0   NaN    nan   105.0   \n31432      597.0 2020-03-28       0.0        0.0   NaN    nan   105.0   \n34866      603.0 2020-03-29       0.0        0.0   NaN    nan    99.0   \n38305      603.0 2020-03-30       0.0        0.0   NaN    nan    99.0   \n40738      603.0 2020-03-31       0.0        0.0   NaN    nan    99.0   \n43221      603.0 2020-04-01       0.0        0.0   NaN    nan    98.0   \n45788      619.0 2020-04-02       NaN        NaN   NaN    nan    82.0   \n48412      619.0 2020-04-03       NaN        NaN   NaN    nan    82.0   \n\n           Combined_Key  \n21155  Diamond Princess  \n24574  Diamond Princess  \n28003  Diamond Princess  \n31432  Diamond Princess  \n34866  Diamond Princess  \n38305  Diamond Princess  \n40738  Diamond Princess  \n43221  Diamond Princess  \n45788  Diamond Princess  \n48412  Diamond Princess  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>Last Update</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n      <th>Date</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>FIPS</th>\n      <th>County</th>\n      <th>Active</th>\n      <th>Combined_Key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21155</th>\n      <td>nan</td>\n      <td>Diamond Princess</td>\n      <td>2020-03-25 23:33:04</td>\n      <td>712.0</td>\n      <td>10.0</td>\n      <td>587.0</td>\n      <td>2020-03-25</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>115.0</td>\n      <td>Diamond Princess</td>\n    </tr>\n    <tr>\n      <th>24574</th>\n      <td>nan</td>\n      <td>Diamond Princess</td>\n      <td>2020-03-26 23:48:18</td>\n      <td>712.0</td>\n      <td>10.0</td>\n      <td>597.0</td>\n      <td>2020-03-26</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>105.0</td>\n      <td>Diamond Princess</td>\n    </tr>\n    <tr>\n      <th>28003</th>\n      <td>nan</td>\n      <td>Diamond Princess</td>\n      <td>2020-03-27 23:23:03</td>\n      <td>712.0</td>\n      <td>10.0</td>\n      <td>597.0</td>\n      <td>2020-03-27</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>105.0</td>\n      <td>Diamond Princess</td>\n    </tr>\n    <tr>\n      <th>31432</th>\n      <td>nan</td>\n      <td>Diamond Princess</td>\n      <td>2020-03-28 23:05:00</td>\n      <td>712.0</td>\n      <td>10.0</td>\n      <td>597.0</td>\n      <td>2020-03-28</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>105.0</td>\n      <td>Diamond Princess</td>\n    </tr>\n    <tr>\n      <th>34866</th>\n      <td>nan</td>\n      <td>Diamond Princess</td>\n      <td>2020-03-29 23:08:00</td>\n      <td>712.0</td>\n      <td>10.0</td>\n      <td>603.0</td>\n      <td>2020-03-29</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>99.0</td>\n      <td>Diamond Princess</td>\n    </tr>\n    <tr>\n      <th>38305</th>\n      <td>nan</td>\n      <td>Diamond Princess</td>\n      <td>2020-03-30 22:52:00</td>\n      <td>712.0</td>\n      <td>10.0</td>\n      <td>603.0</td>\n      <td>2020-03-30</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>99.0</td>\n      <td>Diamond Princess</td>\n    </tr>\n    <tr>\n      <th>40738</th>\n      <td>nan</td>\n      <td>Diamond Princess</td>\n      <td>2020-03-31 23:43:43</td>\n      <td>712.0</td>\n      <td>10.0</td>\n      <td>603.0</td>\n      <td>2020-03-31</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>99.0</td>\n      <td>Diamond Princess</td>\n    </tr>\n    <tr>\n      <th>43221</th>\n      <td>nan</td>\n      <td>Diamond Princess</td>\n      <td>2020-04-01 21:58:34</td>\n      <td>712.0</td>\n      <td>11.0</td>\n      <td>603.0</td>\n      <td>2020-04-01</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>98.0</td>\n      <td>Diamond Princess</td>\n    </tr>\n    <tr>\n      <th>45788</th>\n      <td>nan</td>\n      <td>Diamond Princess</td>\n      <td>2020-04-02 23:25:00</td>\n      <td>712.0</td>\n      <td>11.0</td>\n      <td>619.0</td>\n      <td>2020-04-02</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>82.0</td>\n      <td>Diamond Princess</td>\n    </tr>\n    <tr>\n      <th>48412</th>\n      <td>nan</td>\n      <td>Diamond Princess</td>\n      <td>2020-04-03 22:46:20</td>\n      <td>712.0</td>\n      <td>11.0</td>\n      <td>619.0</td>\n      <td>2020-04-03</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>82.0</td>\n      <td>Diamond Princess</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4cHSNZXyuRs",
        "colab_type": "code",
        "outputId": "af6e3c44-70bf-4e7d-9c9d-c47a6369ccca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df.loc[df[\"Country/Region\"] == \"Diamond Princess\", \"Province/State\"] = \"Diamond Princess\"\n",
        "df.loc[df[\"Country/Region\"] == \"Diamond Princess\", \"Country/Region\"] = \"Cruise Ship\"\n",
        "df.loc[df[\"Province/State\"] == \"Diamond Princess\", \"Country/Region\"] = \"Cruise Ship\"\n",
        "\n",
        "#Others country move to Cruise ship country\n",
        "df.loc[df[\"Country/Region\"] == \"Others\", \"Province/State\"].unique()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([], dtype=object)"
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dkOEFXq2MzN",
        "colab_type": "code",
        "outputId": "c5ef3441-3a53-4a03-e477-e753220b569e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# the Grand Princess cruise ship is listed under the US & Canada\n",
        "df.loc[df[\"Province/State\"] == \"Grand Princess\", \"Country/Region\"].unique()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array(['United States of America', 'Canada'], dtype=object)"
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6ZPSSLXzrnh",
        "colab_type": "code",
        "outputId": "32cdd08c-629a-4fdb-f575-91d638c77d70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "# combine these rows and move them under the cruise ship country\n",
        "for date in df.loc[df[\"Province/State\"] == \"Grand Princess\", \"Date\"].unique():\n",
        "  confirmed_on_date = df.loc[(df[\"Province/State\"] == \"Grand Princess\") & (df.Date == date), \"Confirmed\"].agg(\"sum\")\n",
        "  \n",
        "  # delete Canadian row\n",
        "  df = df[~((df[\"Country/Region\"] == \"Canada\") & (df[\"Province/State\"] == \"Grand Princess\") & (df.Date == date))]\n",
        "\n",
        "  # re-assign the remaining US row under the Cruise Ship country\n",
        "  df.loc[(df[\"Country/Region\"] == \"United States of America\") & \\\n",
        "         (df[\"Province/State\"] == \"Grand Princess\") & \\\n",
        "         (df.Date == date), \"Confirmed\"] = confirmed_on_date\n",
        "  df.loc[(df[\"Country/Region\"] == \"United States of America\") & \\\n",
        "         (df[\"Province/State\"] == \"Grand Princess\") & \\\n",
        "         (df.Date == date), \"Country/Region\"] = \"Cruise Ship\"\n",
        "\n",
        "# three rows have the Grand Princess ship mislabelled\n",
        "df[df[\"Province/State\"] == \"Grand Princess Cruise Ship\"]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "                  Province/State            Country/Region  \\\n3836  Grand Princess Cruise Ship  United States of America   \n4067  Grand Princess Cruise Ship  United States of America   \n4323  Grand Princess Cruise Ship  United States of America   \n\n             Last Update  Confirmed  Deaths  Recovered       Date  Latitude  \\\n3836 2020-03-07 01:33:02       21.0     0.0        0.0 2020-03-07   37.6489   \n4067 2020-03-07 01:33:02       21.0     0.0        0.0 2020-03-08   37.6489   \n4323 2020-03-07 01:33:02       21.0     0.0        0.0 2020-03-09   37.6489   \n\n      Longitude  FIPS County  Active Combined_Key  \n3836  -122.6655   NaN    nan     NaN          NaN  \n4067  -122.6655   NaN    nan     NaN          NaN  \n4323  -122.6655   NaN    nan     NaN          NaN  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>Last Update</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n      <th>Date</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>FIPS</th>\n      <th>County</th>\n      <th>Active</th>\n      <th>Combined_Key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3836</th>\n      <td>Grand Princess Cruise Ship</td>\n      <td>United States of America</td>\n      <td>2020-03-07 01:33:02</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-07</td>\n      <td>37.6489</td>\n      <td>-122.6655</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4067</th>\n      <td>Grand Princess Cruise Ship</td>\n      <td>United States of America</td>\n      <td>2020-03-07 01:33:02</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-08</td>\n      <td>37.6489</td>\n      <td>-122.6655</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4323</th>\n      <td>Grand Princess Cruise Ship</td>\n      <td>United States of America</td>\n      <td>2020-03-07 01:33:02</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-03-09</td>\n      <td>37.6489</td>\n      <td>-122.6655</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viuNhA2b0Pjk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.loc[df[\"Province/State\"] == \"Grand Princess Cruise Ship\", \"Province/State\"] = \"Grand Princess\"\n",
        "df.loc[df[\"Province/State\"] == \"Grand Princess\", \"Country/Region\"] = \"Cruise Ship\""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z47iOAc1sjGP",
        "colab_type": "code",
        "outputId": "071656c5-3b6a-4faa-f541-eb29d02cb413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# Move Hong Kong from China to Hong Kong\n",
        "df[(df[\"Province/State\"] == \"Hong Kong S.A.R.\") & (df[\"Country/Region\"] == \"China\")].head(5)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "        Province/State Country/Region         Last Update  Confirmed  Deaths  \\\n4766  Hong Kong S.A.R.          China 2020-03-11 18:52:03      126.0     3.0   \n4982  Hong Kong S.A.R.          China 2020-03-12 01:53:02      129.0     3.0   \n5175  Hong Kong S.A.R.          China 2020-03-13 13:33:03      134.0     4.0   \n5435  Hong Kong S.A.R.          China 2020-03-14 12:53:06      140.0     4.0   \n5684  Hong Kong S.A.R.          China 2020-03-15 18:20:18      145.0     4.0   \n\n      Recovered       Date  Latitude  Longitude  FIPS County  Active  \\\n4766       65.0 2020-03-11      22.3      114.2   NaN    nan     NaN   \n4982       67.0 2020-03-12      22.3      114.2   NaN    nan     NaN   \n5175       77.0 2020-03-13      22.3      114.2   NaN    nan     NaN   \n5435       78.0 2020-03-14      22.3      114.2   NaN    nan     NaN   \n5684       81.0 2020-03-15      22.3      114.2   NaN    nan     NaN   \n\n     Combined_Key  \n4766          NaN  \n4982          NaN  \n5175          NaN  \n5435          NaN  \n5684          NaN  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>Last Update</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n      <th>Date</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>FIPS</th>\n      <th>County</th>\n      <th>Active</th>\n      <th>Combined_Key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4766</th>\n      <td>Hong Kong S.A.R.</td>\n      <td>China</td>\n      <td>2020-03-11 18:52:03</td>\n      <td>126.0</td>\n      <td>3.0</td>\n      <td>65.0</td>\n      <td>2020-03-11</td>\n      <td>22.3</td>\n      <td>114.2</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4982</th>\n      <td>Hong Kong S.A.R.</td>\n      <td>China</td>\n      <td>2020-03-12 01:53:02</td>\n      <td>129.0</td>\n      <td>3.0</td>\n      <td>67.0</td>\n      <td>2020-03-12</td>\n      <td>22.3</td>\n      <td>114.2</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5175</th>\n      <td>Hong Kong S.A.R.</td>\n      <td>China</td>\n      <td>2020-03-13 13:33:03</td>\n      <td>134.0</td>\n      <td>4.0</td>\n      <td>77.0</td>\n      <td>2020-03-13</td>\n      <td>22.3</td>\n      <td>114.2</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5435</th>\n      <td>Hong Kong S.A.R.</td>\n      <td>China</td>\n      <td>2020-03-14 12:53:06</td>\n      <td>140.0</td>\n      <td>4.0</td>\n      <td>78.0</td>\n      <td>2020-03-14</td>\n      <td>22.3</td>\n      <td>114.2</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5684</th>\n      <td>Hong Kong S.A.R.</td>\n      <td>China</td>\n      <td>2020-03-15 18:20:18</td>\n      <td>145.0</td>\n      <td>4.0</td>\n      <td>81.0</td>\n      <td>2020-03-15</td>\n      <td>22.3</td>\n      <td>114.2</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aThwlkzG30HD",
        "colab_type": "code",
        "outputId": "6659a6b5-c612-4450-e87e-6787ed756056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        }
      },
      "source": [
        "df.loc[(df[\"Province/State\"] == \"Hong Kong S.A.R.\") & \\\n",
        "       (df[\"Country/Region\"] == \"China\"), \"Country/Region\"] = \"Hong Kong S.A.R.\"\n",
        "df.loc[(df[\"Country/Region\"] == \"Hong Kong S.A.R.\"), \"Province/State\"] = \"nan\"\n",
        "df.loc[df[\"Country/Region\"] == \"Taipei and environs\", \"Country/Region\"] = \"Taiwan\"\n",
        "df.loc[df[\"Country/Region\"] == \"Taiwan\", \"Province/State\"] = \"nan\"\n",
        "df.loc[df[\"Country/Region\"] == \"Macau SAR\", \"Country/Region\"] = \"China\"\n",
        "df.loc[df[\"Country/Region\"] == \"Macao SAR\", \"Country/Region\"] = \"China\"\n",
        "df.loc[df[\"Country/Region\"] == \"Macau\", \"Country/Region\"] = \"China\"\n",
        "df.loc[df[\"Province/State\"] == \"Bavaria\", \"Province/State\"] = \"nan\"\n",
        "df.loc[df[\"Country/Region\"] == \"Israel\", \"Province/State\"] = \"nan\"\n",
        "df.loc[df[\"Country/Region\"] == \"France\", \"Province/State\"] = \"nan\"\n",
        "df.loc[df[\"Country/Region\"] == \"United Kingdom\", \"Province/State\"] = \"nan\"\n",
        "df.loc[df[\"Country/Region\"] == \"Denmark\", \"Province/State\"] = \"nan\"\n",
        "df.loc[df[\"Country/Region\"] == \"Netherlands\", \"Province/State\"] = \"nan\"\n",
        "df.loc[(df[\"Country/Region\"] == \"Canada\") & \\\n",
        "       (df[\"Province/State\"] == \"Diamond Princess\"), \"Province/State\"] = \"nan\"\n",
        "df.loc[(df[\"Country/Region\"] == \"Canada\") & \\\n",
        "       (df[\"Province/State\"] == \"Nunavut\"), \"Province/State\"] = \"nan\"\n",
        "df.loc[(df[\"Province/State\"] == \"Wuhan Evacuee\"), \"Province/State\"] = \"nan\"\n",
        "df.loc[(df[\"Province/State\"] == \"Chicago\"), \"Province/State\"] = \"Illinois\"\n",
        "df.loc[(df[\"Province/State\"] == \"D.C.\"), \"Province/State\"] = \"District of Columbia\"\n",
        "df.loc[(df[\"Province/State\"] == \"United States Virgin Islands\"), \"Province/State\"] = \"Virgin Islands\"\n",
        "df.loc[(df[\"Country/Region\"] == \"North Macedonia\"), \"Country/Region\"] = \"Macedonia\"\n",
        "df.loc[(df[\"Country/Region\"] == \"North Ireland\"), \"Country/Region\"] = \"Ireland\"\n",
        "df.loc[(df[\"Country/Region\"] == \"Serbia\"), \"Country/Region\"] = \"Republic of Serbia\"\n",
        "df.loc[(df[\"Country/Region\"] == \"Vatican City\"), \"Country/Region\"] = \"Vatican\"\n",
        "df.loc[(df[\"Country/Region\"] == \"Holy See\"), \"Country/Region\"] = \"Vatican\"\n",
        "df.loc[(df[\"Country/Region\"] == \"French Guiana\"), \"Country/Region\"] = \"France\"\n",
        "df.loc[(df[\"Country/Region\"] == \"Martinique\"), \"Country/Region\"] = \"France\"\n",
        "df.loc[(df[\"Country/Region\"] == \"Guadeloupe\"), \"Country/Region\"] = \"France\"\n",
        "df.loc[(df[\"Country/Region\"] == \"Mayotte\"), \"Country/Region\"] = \"France\"\n",
        "df.loc[(df[\"Country/Region\"] == \"occupied Palestinian territory\"), \"Country/Region\"] = \"Palestine\"\n",
        "df.loc[(df[\"Country/Region\"] == \"West Bank and Gaza\"), \"Country/Region\"] = \"Palestine\"\n",
        "df.loc[(df[\"Country/Region\"] == \"Czechia\"), \"Country/Region\"] = \"Czech Republic\"\n",
        "df.loc[(df[\"Country/Region\"] == \"Curacao\"), \"Country/Region\"] = \"Netherlands\"\n",
        "df.loc[(df[\"Country/Region\"] == \"Republic of the Congo\"), \"Country/Region\"] = \"Republic of Congo\"\n",
        "df.loc[(df[\"Country/Region\"] == \"Tanzania\"), \"Country/Region\"] = \"United Republic of Tanzania\"\n",
        "df.loc[(df[\"Country/Region\"] == \"Cabo Verde\"), \"Country/Region\"] = \"Cape Verde\"\n",
        "df.loc[(df[\"Country/Region\"] == \"Timor-Leste\"), \"Country/Region\"] = \"East Timor\"\n",
        "df.loc[(df[\"Country/Region\"] == \"Guinea-Bissau\"), \"Country/Region\"] = \"Guinea Bissau\"\n",
        "df.loc[(df[\"Country/Region\"] == \"Burma\"), \"Country/Region\"] = \"Myanmar\"\n",
        "df.loc[(df[\"Country/Region\"] == \"MS Zaandam\"), \"Country/Region\"] = \"Cruise Ship\"\n",
        "df.loc[(df.County == \"Unassigned\"), \"County\"] = \"nan\"\n",
        "df.loc[(df[\"County\"] == \"New York City\"), \"County\"] = \"New York\""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array(['Ontario', 'British Columbia', 'Toronto, ON', 'London, ON',\n       ' Montreal, QC', 'Calgary, Alberta', 'Edmonton, Alberta',\n       'Alberta', 'Quebec', 'New Brunswick', 'Manitoba', 'Saskatchewan',\n       'Newfoundland and Labrador', 'Prince Edward Island', 'Nova Scotia',\n       'Northwest Territories', 'Yukon'], dtype=object)"
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "df.loc[df[\"Country/Region\"] == \"Canada\", \"Province/State\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   Country/Region Province/State County       Date  Confirmed  Deaths  \\\n0     Afghanistan            nan    nan 2020-02-24        1.0     0.0   \n1     Afghanistan            nan    nan 2020-02-25        1.0     0.0   \n2     Afghanistan            nan    nan 2020-02-26        1.0     0.0   \n3     Afghanistan            nan    nan 2020-02-27        1.0     0.0   \n4     Afghanistan            nan    nan 2020-02-28        1.0     0.0   \n5     Afghanistan            nan    nan 2020-02-29        1.0     0.0   \n6     Afghanistan            nan    nan 2020-03-01        1.0     0.0   \n7     Afghanistan            nan    nan 2020-03-02        1.0     0.0   \n8     Afghanistan            nan    nan 2020-03-03        1.0     0.0   \n9     Afghanistan            nan    nan 2020-03-04        1.0     0.0   \n10    Afghanistan            nan    nan 2020-03-05        1.0     0.0   \n11    Afghanistan            nan    nan 2020-03-06        1.0     0.0   \n12    Afghanistan            nan    nan 2020-03-07        1.0     0.0   \n13    Afghanistan            nan    nan 2020-03-08        4.0     0.0   \n14    Afghanistan            nan    nan 2020-03-09        4.0     0.0   \n15    Afghanistan            nan    nan 2020-03-10        5.0     0.0   \n16    Afghanistan            nan    nan 2020-03-11        7.0     0.0   \n17    Afghanistan            nan    nan 2020-03-12        7.0     0.0   \n18    Afghanistan            nan    nan 2020-03-13        7.0     0.0   \n19    Afghanistan            nan    nan 2020-03-14       11.0     0.0   \n\n    Recovered  Latitude  Longitude  FIPS  Active  \n0         0.0    0.0000       0.00   0.0     0.0  \n1         0.0    0.0000       0.00   0.0     0.0  \n2         0.0    0.0000       0.00   0.0     0.0  \n3         0.0    0.0000       0.00   0.0     0.0  \n4         0.0    0.0000       0.00   0.0     0.0  \n5         0.0    0.0000       0.00   0.0     0.0  \n6         0.0   33.0000      65.00   0.0     0.0  \n7         0.0   33.0000      65.00   0.0     0.0  \n8         0.0   33.0000      65.00   0.0     0.0  \n9         0.0   33.0000      65.00   0.0     0.0  \n10        0.0   33.0000      65.00   0.0     0.0  \n11        0.0   33.0000      65.00   0.0     0.0  \n12        0.0   33.0000      65.00   0.0     0.0  \n13        0.0   33.0000      65.00   0.0     0.0  \n14        0.0   33.0000      65.00   0.0     0.0  \n15        0.0   33.0000      65.00   0.0     0.0  \n16        0.0   33.0000      65.00   0.0     0.0  \n17        0.0   33.0000      65.00   0.0     0.0  \n18        0.0   33.0000      65.00   0.0     0.0  \n19        0.0   33.9391      67.71   0.0     0.0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country/Region</th>\n      <th>Province/State</th>\n      <th>County</th>\n      <th>Date</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>FIPS</th>\n      <th>Active</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-02-24</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-02-25</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-02-26</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-02-27</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-02-28</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-02-29</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-03-01</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>33.0000</td>\n      <td>65.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-03-02</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>33.0000</td>\n      <td>65.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-03-03</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>33.0000</td>\n      <td>65.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-03-04</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>33.0000</td>\n      <td>65.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-03-05</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>33.0000</td>\n      <td>65.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-03-06</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>33.0000</td>\n      <td>65.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-03-07</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>33.0000</td>\n      <td>65.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-03-08</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>33.0000</td>\n      <td>65.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-03-09</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>33.0000</td>\n      <td>65.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-03-10</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>33.0000</td>\n      <td>65.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-03-11</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>33.0000</td>\n      <td>65.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-03-12</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>33.0000</td>\n      <td>65.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-03-13</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>33.0000</td>\n      <td>65.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-03-14</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>33.9391</td>\n      <td>67.71</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Beginning on Feb 1, 2020 through Mar 9, 2020 the data for the US & Canada were reported using\n",
        "# <city>, <state> in the Province/State field.  Before and after this date range, data was reported\n",
        "# using only the state name in this field.  The field values within this data range will be modified\n",
        "# to only specify the state name.\n",
        "\n",
        "# determine which rows have \"<city>, <state>\" format\n",
        "has_city_mask = df[\"Province/State\"].str.find(\", \") > -1\n",
        "\n",
        "# replace the field values with the word following the comma\n",
        "df.loc[has_city_mask, \"Province/State\"] = df.loc[has_city_mask, \"Province/State\"].apply(lambda x: x.split(\", \")[1])\n",
        "\n",
        "# make a dict to replace state/province abbreviations with their full name\n",
        "# this dict is from https://code.activestate.com/recipes/577305-python-dictionary-of-us-states-and-territories/\n",
        "states = {\n",
        "        'AK': 'Alaska',\n",
        "        'AL': 'Alabama',\n",
        "        'AR': 'Arkansas',\n",
        "        'AS': 'American Samoa',\n",
        "        'AZ': 'Arizona',\n",
        "        'CA': 'California',\n",
        "        'CO': 'Colorado',\n",
        "        'CT': 'Connecticut',\n",
        "        'DC': 'District of Columbia',\n",
        "        'DE': 'Delaware',\n",
        "        'FL': 'Florida',\n",
        "        'GA': 'Georgia',\n",
        "        'GU': 'Guam',\n",
        "        'HI': 'Hawaii',\n",
        "        'IA': 'Iowa',\n",
        "        'ID': 'Idaho',\n",
        "        'IL': 'Illinois',\n",
        "        'IN': 'Indiana',\n",
        "        'KS': 'Kansas',\n",
        "        'KY': 'Kentucky',\n",
        "        'LA': 'Louisiana',\n",
        "        'MA': 'Massachusetts',\n",
        "        'MD': 'Maryland',\n",
        "        'ME': 'Maine',\n",
        "        'MI': 'Michigan',\n",
        "        'MN': 'Minnesota',\n",
        "        'MO': 'Missouri',\n",
        "        'MP': 'Northern Mariana Islands',\n",
        "        'MS': 'Mississippi',\n",
        "        'MT': 'Montana',\n",
        "        'NA': 'National',\n",
        "        'NC': 'North Carolina',\n",
        "        'ND': 'North Dakota',\n",
        "        'NE': 'Nebraska',\n",
        "        'NH': 'New Hampshire',\n",
        "        'NJ': 'New Jersey',\n",
        "        'NM': 'New Mexico',\n",
        "        'NV': 'Nevada',\n",
        "        'NY': 'New York',\n",
        "        'OH': 'Ohio',\n",
        "        'OK': 'Oklahoma',\n",
        "        'OR': 'Oregon',\n",
        "        'PA': 'Pennsylvania',\n",
        "        'PR': 'Puerto Rico',\n",
        "        'RI': 'Rhode Island',\n",
        "        'SC': 'South Carolina',\n",
        "        'SD': 'South Dakota',\n",
        "        'TN': 'Tennessee',\n",
        "        'TX': 'Texas',\n",
        "        'UT': 'Utah',\n",
        "        'VA': 'Virginia',\n",
        "        'VI': 'Virgin Islands',\n",
        "        'VT': 'Vermont',\n",
        "        'WA': 'Washington',\n",
        "        'WI': 'Wisconsin',\n",
        "        'WV': 'West Virginia',\n",
        "        'WY': 'Wyoming',\n",
        "        'OR ': 'Oregon',\n",
        "        'NE (From Diamond Princess)': 'Nebraska',\n",
        "        'CA (From Diamond Princess)': 'California',\n",
        "        'TX (From Diamond Princess)': 'Texas',\n",
        "        'Unassigned Location (From Diamond Princess)': 'nan',\n",
        "        'U.S.': 'nan',\n",
        "        'United States of America': 'nan',\n",
        "        'ON': 'Ontario',\n",
        "        'QC': 'Quebec'\n",
        "}\n",
        "df[\"Province/State\"].replace(states, inplace=True)\n",
        "\n",
        "# whenever more than one city in the same state/province was recorded on the same date,\n",
        "# the state will now appear more than once.  These rows need to be aggregated.\n",
        "df[\"Country/Region\"] = df[\"Country/Region\"].astype(str)\n",
        "df[\"Province/State\"] = df[\"Province/State\"].astype(str)\n",
        "df[\"County\"] = df[\"County\"].astype(str)\n",
        "df2 = df\n",
        "\n",
        "df2 = df2.groupby([\"Country/Region\", \"Province/State\", \"County\", \"Date\"]).sum().reset_index()\n",
        "df2.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "3.344525376955668"
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "t1 = time.time()\n",
        "(t1 - t0)/60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array(['Afghanistan', 'Albania', 'Algeria', 'Andorra', 'Angola',\n       'Antigua and Barbuda', 'Argentina', 'Armenia', 'Aruba',\n       'Australia', 'Austria', 'Azerbaijan', 'Bahrain', 'Bangladesh',\n       'Barbados', 'Belarus', 'Belgium', 'Belize', 'Benin', 'Bhutan',\n       'Bolivia', 'Bosnia and Herzegovina', 'Botswana', 'Brazil',\n       'Brunei', 'Bulgaria', 'Burkina Faso', 'Burundi', 'Cambodia',\n       'Cameroon', 'Canada', 'Cape Verde', 'Cayman Islands',\n       'Central African Republic', 'Chad', 'Channel Islands', 'Chile',\n       'China', 'Colombia', 'Comoros', 'Congo (Brazzaville)',\n       'Congo (Kinshasa)', 'Costa Rica', 'Croatia', 'Cruise Ship', 'Cuba',\n       'Cyprus', 'Czech Republic', 'Denmark', 'Djibouti', 'Dominica',\n       'Dominican Republic', 'East Timor', 'Ecuador', 'Egypt',\n       'El Salvador', 'Equatorial Guinea', 'Eritrea', 'Estonia',\n       'Eswatini', 'Ethiopia', 'Faroe Islands', 'Fiji', 'Finland',\n       'France', 'Gabon', 'Gambia', 'Georgia', 'Germany', 'Ghana',\n       'Gibraltar', 'Greece', 'Greenland', 'Grenada', 'Guam', 'Guatemala',\n       'Guernsey', 'Guinea', 'Guinea Bissau', 'Guyana', 'Haiti',\n       'Honduras', 'Hong Kong S.A.R.', 'Hungary', 'Iceland', 'India',\n       'Indonesia', 'Iran', 'Iraq', 'Ireland', 'Israel', 'Italy',\n       'Ivory Coast', 'Jamaica', 'Japan', 'Jersey', 'Jordan',\n       'Kazakhstan', 'Kenya', 'Kosovo', 'Kuwait', 'Kyrgyzstan', 'Laos',\n       'Latvia', 'Lebanon', 'Lesotho', 'Liberia', 'Libya',\n       'Liechtenstein', 'Lithuania', 'Luxembourg', 'Macedonia',\n       'Madagascar', 'Malawi', 'Malaysia', 'Maldives', 'Mali', 'Malta',\n       'Mauritania', 'Mauritius', 'Mexico', 'Moldova', 'Monaco',\n       'Mongolia', 'Montenegro', 'Morocco', 'Mozambique', 'Myanmar',\n       'Namibia', 'Nepal', 'Netherlands', 'New Zealand', 'Nicaragua',\n       'Niger', 'Nigeria', 'Norway', 'Oman', 'Pakistan', 'Palestine',\n       'Panama', 'Papua New Guinea', 'Paraguay', 'Peru', 'Philippines',\n       'Poland', 'Portugal', 'Puerto Rico', 'Qatar', 'Republic of Congo',\n       'Republic of Serbia', 'Reunion', 'Romania', 'Russia', 'Rwanda',\n       'Saint Barthelemy', 'Saint Kitts and Nevis', 'Saint Lucia',\n       'Saint Martin', 'Saint Vincent and the Grenadines', 'San Marino',\n       'Sao Tome and Principe', 'Saudi Arabia', 'Senegal', 'Seychelles',\n       'Sierra Leone', 'Singapore', 'Slovakia', 'Slovenia', 'Somalia',\n       'South Africa', 'South Korea', 'South Sudan', 'Spain', 'Sri Lanka',\n       'Sudan', 'Suriname', 'Sweden', 'Switzerland', 'Syria', 'Taiwan',\n       'Tajikistan', 'Thailand', 'The Bahamas', 'Togo',\n       'Trinidad and Tobago', 'Tunisia', 'Turkey', 'Uganda', 'Ukraine',\n       'United Arab Emirates', 'United Kingdom',\n       'United Republic of Tanzania', 'United States of America',\n       'Uruguay', 'Uzbekistan', 'Vatican', 'Venezuela', 'Vietnam',\n       'Western Sahara', 'Yemen', 'Zambia', 'Zimbabwe'], dtype='<U32')"
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "np.sort(df2[\"Country/Region\"].unique().tolist())"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnvm6ds-nQnV",
        "colab_type": "code",
        "outputId": "1a0b4322-1457-4cac-b5f4-173912274771",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# calculate new cases for each region on each date\n",
        "df = df2\n",
        "df[\"Country/Region\"] = df[\"Country/Region\"].astype(str)\n",
        "df[\"Province/State\"] = df[\"Province/State\"].astype(str)\n",
        "df[\"County\"] = df[\"County\"].astype(str)\n",
        "all_csc_per_date_df = pd.DataFrame(columns=[\"Country/Region\", \"Province/State\", \"County\"])\n",
        "for country in sorted(df[\"Country/Region\"].unique().tolist()):\n",
        "  for state in sorted(df.loc[df[\"Country/Region\"] == country, \"Province/State\"].unique().tolist()):\n",
        "    for county in sorted(df.loc[(df[\"Country/Region\"] == country) & \\\n",
        "                                (df[\"Province/State\"] == state), \"County\"].unique().tolist()):\n",
        "      \n",
        "      # isolate corresponding country-state-county combination\n",
        "      csc_df = df.loc[(df[\"Country/Region\"] == country) & \\\n",
        "                           (df[\"Province/State\"] == state) & \\\n",
        "                           (df[\"County\"] == county), [\"Date\", \"Confirmed\", \"Recovered\", \"Deaths\"]]\n",
        "      csc_df.Date = csc_df.Date.dt.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "      # pivot into time series array (each column is a date)\n",
        "      csc_conf_arr = csc_df.drop(labels=[\"Recovered\", \"Deaths\"], axis=1).values.transpose()\n",
        "      csc_recv_arr = csc_df.drop(labels=[\"Confirmed\", \"Deaths\"], axis=1).values.transpose()\n",
        "      csc_death_arr = csc_df.drop(labels=[\"Confirmed\", \"Recovered\"], axis=1).values.transpose()\n",
        "\n",
        "      # calcuate new confirmations for each date\n",
        "      all_arrs = np.zeros([3, csc_conf_arr.shape[0],  csc_conf_arr.shape[1]])\n",
        "      for i, arr in enumerate([csc_conf_arr, csc_recv_arr, csc_death_arr]):\n",
        "        yesterday = arr[:, 0:-1]\n",
        "        today = arr[:, 1:]\n",
        "        arr_per_date = arr[0,:]\n",
        "        arr_per_date = np.vstack([arr_per_date, np.hstack([np.nan, today[1,:] - yesterday[1,:]])])\n",
        "\n",
        "        # return array back to dataframe\n",
        "        arr_per_date_df = pd.DataFrame(columns=arr_per_date[0,:].astype(str))\n",
        "        arr_per_date_df = arr_per_date_df.append(pd.Series(dict(zip(arr_per_date_df.columns, arr_per_date[1,:]))), ignore_index=True)\n",
        "        arr_per_date_df[\"Country/Region\"] = country\n",
        "        arr_per_date_df[\"Province/State\"] = state\n",
        "        arr_per_date_df[\"County\"] = county\n",
        "\n",
        "        if i == 0:\n",
        "          arr_per_date_df[\"Var\"] = \"ConfirmedPerDate\"\n",
        "        if i == 1:\n",
        "          arr_per_date_df[\"Var\"] = \"RecoveredPerDate\"\n",
        "        if i == 2:\n",
        "          arr_per_date_df[\"Var\"] = \"DeathsPerDate\"\n",
        "\n",
        "        # add this combo to collection\n",
        "        #print(arr_per_date_df.head(1))\n",
        "        #print(\"---------------------------\")\n",
        "        all_csc_per_date_df = all_csc_per_date_df.append(arr_per_date_df, ignore_index=True)\n",
        "\n",
        "    # Beginning on Mar 22 the US had data broken down at the county level.\n",
        "    # This will cause a problem on the 22 & 23 because there is no prior county\n",
        "    # data to reference, causing the standard calculation to fail.  Each state will\n",
        "    # be corrected here.\n",
        "    if (country == \"United States of America\"):\n",
        "        \n",
        "      # get the df row for the entire state to get total state cases on Mar 21\n",
        "      state_21_df = df.loc[(df[\"Country/Region\"] == country) & (df[\"Province/State\"] == state) & \\\n",
        "                           (df.Date == pd.datetime(2020, 3, 21)), [\"Confirmed\", \"Recovered\", \"Deaths\"]]\n",
        "      #print(state)\n",
        "      if state_21_df.size > 0:\n",
        "        state_21_arr = state_21_df.values[0,:]\n",
        "      else:\n",
        "        state_21_arr =np.array([0, 0, 0])\n",
        "      #print(state_21_arr)\n",
        "      # get the df rows for all the state's counties to get total cases on Mar 22\n",
        "      counties_df = df.loc[(df[\"Country/Region\"] == country) & (df[\"Province/State\"] == state) & \\\n",
        "                           (df.Date == pd.datetime(2020, 3, 22)), [\"Confirmed\", \"Recovered\", \"Deaths\"]]\n",
        "      counties_22_arr = np.array([counties_df[\"Confirmed\"].sum(), counties_df[\"Recovered\"].sum(),\n",
        "                                     counties_df[\"Deaths\"].sum()])\n",
        "      #print(counties_22_arr)\n",
        "      # calculate the increase in cases ocurring on Mar 22\n",
        "      state_per_date_22_arr = counties_22_arr - state_21_arr\n",
        "      #print(state_per_date_22_arr)\n",
        "      \n",
        "      # correct the value on Mar 22\n",
        "      all_csc_per_date_df.loc[(all_csc_per_date_df[\"Country/Region\"] == \"United States of America\") & \\\n",
        "                              (all_csc_per_date_df[\"Province/State\"] == state) & \\\n",
        "                              (all_csc_per_date_df.County == \"nan\") & \\\n",
        "                              (all_csc_per_date_df.Var == \"ConfirmedPerDate\"), \"2020-03-22\"] = state_per_date_22_arr[0]\n",
        "      all_csc_per_date_df.loc[(all_csc_per_date_df[\"Country/Region\"] == \"United States of America\") & \\\n",
        "                              (all_csc_per_date_df[\"Province/State\"] == state) & \\\n",
        "                              (all_csc_per_date_df.County == \"nan\") & \\\n",
        "                              (all_csc_per_date_df.Var == \"RecoveredPerDate\"), \"2020-03-22\"] = state_per_date_22_arr[1]\n",
        "      all_csc_per_date_df.loc[(all_csc_per_date_df[\"Country/Region\"] == \"United States of America\") & \\\n",
        "                              (all_csc_per_date_df[\"Province/State\"] == state) & \\\n",
        "                              (all_csc_per_date_df.County == \"nan\") & \\\n",
        "                              (all_csc_per_date_df.Var == \"DeathsPerDate\"), \"2020-03-22\"] = state_per_date_22_arr[2]\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "      2020-03-21 2020-03-22  2020-03-23  2020-03-24\n7479        75.0        108         NaN         NaN\n7480         0.0          0         NaN         NaN\n7481         1.0          0         NaN         NaN",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>2020-03-21</th>\n      <th>2020-03-22</th>\n      <th>2020-03-23</th>\n      <th>2020-03-24</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7479</th>\n      <td>75.0</td>\n      <td>108</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7480</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7481</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "all_csc_per_date_df.loc[(all_csc_per_date_df[\"Province/State\"] == \"Ohio\") & (all_csc_per_date_df.County == \"nan\"), [\"2020-03-21\", \"2020-03-22\", \"2020-03-23\", \"2020-03-24\"]].head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Index(['2020-03-20', '2020-03-21', '2020-03-22', '2020-03-23', '2020-03-24',\n       '2020-03-25', '2020-03-26', '2020-03-27', '2020-03-28', '2020-03-29',\n       '2020-03-30', '2020-03-31', '2020-04-01', '2020-04-02', '2020-04-03',\n       '2020-04-04', '2020-04-05', '2020-04-06', '2020-04-07', '2020-04-08',\n       '2020-04-09', '2020-04-10', '2020-04-11', '2020-04-12', '2020-04-13',\n       '2020-04-14', '2020-04-15', '2020-04-16', '2020-04-17', '2020-04-18',\n       '2020-04-19', '2020-04-20', '2020-04-21', '2020-04-22', '2020-04-23',\n       '2020-04-24', '2020-04-25', '2020-04-26', '2020-04-27', '2020-04-28',\n       '2020-04-29', '2020-04-30', '2020-05-01', '2020-05-02', '2020-05-03',\n       '2020-05-04', '2020-05-05', '2020-05-06', '2020-05-07', '2020-05-08',\n       '2020-05-09', '2020-05-10', '2020-05-11', '2020-05-12', '2020-05-13',\n       '2020-05-14', '2020-05-15', '2020-05-16', '2020-05-17', '2020-05-18',\n       '2020-05-19', 'Country/Region', 'Province/State', 'County', 'Var'],\n      dtype='object')\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   2020-03-20  2020-03-21  2020-03-22  2020-03-23  2020-03-24  2020-03-25  \\\n0         NaN         0.0         0.0         1.0         0.0         0.0   \n\n   2020-03-26  2020-03-27  2020-03-28  2020-03-29  ...  2020-05-14  \\\n0         0.0         0.0         0.0         0.0  ...         0.0   \n\n   2020-05-15  2020-05-16  2020-05-17  2020-05-18  2020-05-19  Country/Region  \\\n0         0.0         0.0         0.0         0.0         0.0        Zimbabwe   \n\n   Province/State  County            Var  \n0             nan     nan  DeathsPerDate  \n\n[1 rows x 65 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>2020-03-20</th>\n      <th>2020-03-21</th>\n      <th>2020-03-22</th>\n      <th>2020-03-23</th>\n      <th>2020-03-24</th>\n      <th>2020-03-25</th>\n      <th>2020-03-26</th>\n      <th>2020-03-27</th>\n      <th>2020-03-28</th>\n      <th>2020-03-29</th>\n      <th>...</th>\n      <th>2020-05-14</th>\n      <th>2020-05-15</th>\n      <th>2020-05-16</th>\n      <th>2020-05-17</th>\n      <th>2020-05-18</th>\n      <th>2020-05-19</th>\n      <th>Country/Region</th>\n      <th>Province/State</th>\n      <th>County</th>\n      <th>Var</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Zimbabwe</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>DeathsPerDate</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 65 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "print(arr_per_date_df.columns)\n",
        "arr_per_date_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbxIHQwW72Bi",
        "colab_type": "code",
        "outputId": "b2f02af4-8ab0-4b86-ead5-d0b0a36d8664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "all_csc_per_date_df.loc[(all_csc_per_date_df[\"Country/Region\"] == \"France\") & \\\n",
        "                    \n",
        "                    (all_csc_per_date_df.Var == \"ConfirmedPerDate\"), [\"Province/State\", \"2020-03-24\"]].values\n",
        "                    #(all_csc_per_date_df.County == \"nan\")]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([['nan', 2499.0]], dtype=object)"
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array(['Afghanistan', 'Albania', 'Algeria', 'Andorra', 'Angola',\n       'Antigua and Barbuda', 'Argentina', 'Armenia', 'Aruba',\n       'Australia', 'Austria', 'Azerbaijan', 'Bahrain', 'Bangladesh',\n       'Barbados', 'Belarus', 'Belgium', 'Belize', 'Benin', 'Bhutan',\n       'Bolivia', 'Bosnia and Herzegovina', 'Botswana', 'Brazil',\n       'Brunei', 'Bulgaria', 'Burkina Faso', 'Burundi', 'Cambodia',\n       'Cameroon', 'Canada', 'Cape Verde', 'Cayman Islands',\n       'Central African Republic', 'Chad', 'Channel Islands', 'Chile',\n       'China', 'Colombia', 'Comoros', 'Congo (Brazzaville)',\n       'Congo (Kinshasa)', 'Costa Rica', 'Croatia', 'Cruise Ship', 'Cuba',\n       'Cyprus', 'Czech Republic', 'Denmark', 'Djibouti', 'Dominica',\n       'Dominican Republic', 'East Timor', 'Ecuador', 'Egypt',\n       'El Salvador', 'Equatorial Guinea', 'Eritrea', 'Estonia',\n       'Eswatini', 'Ethiopia', 'Faroe Islands', 'Fiji', 'Finland',\n       'France', 'Gabon', 'Gambia', 'Georgia', 'Germany', 'Ghana',\n       'Gibraltar', 'Greece', 'Greenland', 'Grenada', 'Guam', 'Guatemala',\n       'Guernsey', 'Guinea', 'Guinea Bissau', 'Guyana', 'Haiti',\n       'Honduras', 'Hong Kong S.A.R.', 'Hungary', 'Iceland', 'India',\n       'Indonesia', 'Iran', 'Iraq', 'Ireland', 'Israel', 'Italy',\n       'Ivory Coast', 'Jamaica', 'Japan', 'Jersey', 'Jordan',\n       'Kazakhstan', 'Kenya', 'Kosovo', 'Kuwait', 'Kyrgyzstan', 'Laos',\n       'Latvia', 'Lebanon', 'Lesotho', 'Liberia', 'Libya',\n       'Liechtenstein', 'Lithuania', 'Luxembourg', 'Macedonia',\n       'Madagascar', 'Malawi', 'Malaysia', 'Maldives', 'Mali', 'Malta',\n       'Mauritania', 'Mauritius', 'Mexico', 'Moldova', 'Monaco',\n       'Mongolia', 'Montenegro', 'Morocco', 'Mozambique', 'Myanmar',\n       'Namibia', 'Nepal', 'Netherlands', 'New Zealand', 'Nicaragua',\n       'Niger', 'Nigeria', 'Norway', 'Oman', 'Pakistan', 'Palestine',\n       'Panama', 'Papua New Guinea', 'Paraguay', 'Peru', 'Philippines',\n       'Poland', 'Portugal', 'Puerto Rico', 'Qatar', 'Republic of Congo',\n       'Republic of Serbia', 'Reunion', 'Romania', 'Russia', 'Rwanda',\n       'Saint Barthelemy', 'Saint Kitts and Nevis', 'Saint Lucia',\n       'Saint Martin', 'Saint Vincent and the Grenadines', 'San Marino',\n       'Sao Tome and Principe', 'Saudi Arabia', 'Senegal', 'Seychelles',\n       'Sierra Leone', 'Singapore', 'Slovakia', 'Slovenia', 'Somalia',\n       'South Africa', 'South Korea', 'South Sudan', 'Spain', 'Sri Lanka',\n       'Sudan', 'Suriname', 'Sweden', 'Switzerland', 'Syria', 'Taiwan',\n       'Tajikistan', 'Thailand', 'The Bahamas', 'Togo',\n       'Trinidad and Tobago', 'Tunisia', 'Turkey', 'Uganda', 'Ukraine',\n       'United Arab Emirates', 'United Kingdom',\n       'United Republic of Tanzania', 'United States of America',\n       'Uruguay', 'Uzbekistan', 'Vatican', 'Venezuela', 'Vietnam',\n       'Western Sahara', 'Yemen', 'Zambia', 'Zimbabwe'], dtype=object)"
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "all_csc_per_date_df[\"Country/Region\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byk9__8HI5dn",
        "colab_type": "code",
        "outputId": "762b169e-5e5c-4014-e383-4503da160853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "all_csc_conf_per_date_df = all_csc_per_date_df[all_csc_per_date_df.Var == \"ConfirmedPerDate\"].\\\n",
        "                           drop(\"Var\", axis=1).melt(id_vars=[\"Country/Region\", \"Province/State\", \"County\"],\n",
        "                                                    var_name=\"Date\", value_name=\"ConfirmedPerDate\")\n",
        "all_csc_conf_per_date_df.Date = pd.to_datetime(all_csc_conf_per_date_df.Date)\n",
        "\n",
        "all_csc_recv_per_date_df = all_csc_per_date_df[all_csc_per_date_df.Var == \"RecoveredPerDate\"].\\\n",
        "                           drop(\"Var\", axis=1).melt(id_vars=[\"Country/Region\", \"Province/State\", \"County\"],\n",
        "                                                    var_name=\"Date\", value_name=\"RecoveredPerDate\")\n",
        "all_csc_recv_per_date_df.Date = pd.to_datetime(all_csc_recv_per_date_df.Date)\n",
        "\n",
        "all_csc_death_per_date_df = all_csc_per_date_df[all_csc_per_date_df.Var == \"DeathsPerDate\"].\\\n",
        "                            drop(\"Var\", axis=1).melt(id_vars=[\"Country/Region\", \"Province/State\", \"County\"],\n",
        "                                                     var_name=\"Date\", value_name=\"DeathsPerDate\")\n",
        "all_csc_death_per_date_df.Date = pd.to_datetime(all_csc_death_per_date_df.Date)\n",
        "all_csc_conf_per_date_df[\"Country/Region\"].unique()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array(['Afghanistan', 'Albania', 'Algeria', 'Andorra', 'Angola',\n       'Antigua and Barbuda', 'Argentina', 'Armenia', 'Aruba',\n       'Australia', 'Austria', 'Azerbaijan', 'Bahrain', 'Bangladesh',\n       'Barbados', 'Belarus', 'Belgium', 'Belize', 'Benin', 'Bhutan',\n       'Bolivia', 'Bosnia and Herzegovina', 'Botswana', 'Brazil',\n       'Brunei', 'Bulgaria', 'Burkina Faso', 'Burundi', 'Cambodia',\n       'Cameroon', 'Canada', 'Cape Verde', 'Cayman Islands',\n       'Central African Republic', 'Chad', 'Channel Islands', 'Chile',\n       'China', 'Colombia', 'Comoros', 'Congo (Brazzaville)',\n       'Congo (Kinshasa)', 'Costa Rica', 'Croatia', 'Cruise Ship', 'Cuba',\n       'Cyprus', 'Czech Republic', 'Denmark', 'Djibouti', 'Dominica',\n       'Dominican Republic', 'East Timor', 'Ecuador', 'Egypt',\n       'El Salvador', 'Equatorial Guinea', 'Eritrea', 'Estonia',\n       'Eswatini', 'Ethiopia', 'Faroe Islands', 'Fiji', 'Finland',\n       'France', 'Gabon', 'Gambia', 'Georgia', 'Germany', 'Ghana',\n       'Gibraltar', 'Greece', 'Greenland', 'Grenada', 'Guam', 'Guatemala',\n       'Guernsey', 'Guinea', 'Guinea Bissau', 'Guyana', 'Haiti',\n       'Honduras', 'Hong Kong S.A.R.', 'Hungary', 'Iceland', 'India',\n       'Indonesia', 'Iran', 'Iraq', 'Ireland', 'Israel', 'Italy',\n       'Ivory Coast', 'Jamaica', 'Japan', 'Jersey', 'Jordan',\n       'Kazakhstan', 'Kenya', 'Kosovo', 'Kuwait', 'Kyrgyzstan', 'Laos',\n       'Latvia', 'Lebanon', 'Lesotho', 'Liberia', 'Libya',\n       'Liechtenstein', 'Lithuania', 'Luxembourg', 'Macedonia',\n       'Madagascar', 'Malawi', 'Malaysia', 'Maldives', 'Mali', 'Malta',\n       'Mauritania', 'Mauritius', 'Mexico', 'Moldova', 'Monaco',\n       'Mongolia', 'Montenegro', 'Morocco', 'Mozambique', 'Myanmar',\n       'Namibia', 'Nepal', 'Netherlands', 'New Zealand', 'Nicaragua',\n       'Niger', 'Nigeria', 'Norway', 'Oman', 'Pakistan', 'Palestine',\n       'Panama', 'Papua New Guinea', 'Paraguay', 'Peru', 'Philippines',\n       'Poland', 'Portugal', 'Puerto Rico', 'Qatar', 'Republic of Congo',\n       'Republic of Serbia', 'Reunion', 'Romania', 'Russia', 'Rwanda',\n       'Saint Barthelemy', 'Saint Kitts and Nevis', 'Saint Lucia',\n       'Saint Martin', 'Saint Vincent and the Grenadines', 'San Marino',\n       'Sao Tome and Principe', 'Saudi Arabia', 'Senegal', 'Seychelles',\n       'Sierra Leone', 'Singapore', 'Slovakia', 'Slovenia', 'Somalia',\n       'South Africa', 'South Korea', 'South Sudan', 'Spain', 'Sri Lanka',\n       'Sudan', 'Suriname', 'Sweden', 'Switzerland', 'Syria', 'Taiwan',\n       'Tajikistan', 'Thailand', 'The Bahamas', 'Togo',\n       'Trinidad and Tobago', 'Tunisia', 'Turkey', 'Uganda', 'Ukraine',\n       'United Arab Emirates', 'United Kingdom',\n       'United Republic of Tanzania', 'United States of America',\n       'Uruguay', 'Uzbekistan', 'Vatican', 'Venezuela', 'Vietnam',\n       'Western Sahara', 'Yemen', 'Zambia', 'Zimbabwe'], dtype=object)"
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXBpJka-dwQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# outer join the confirmed-per-date data with the clean dataframe\n",
        "df = df.merge(all_csc_conf_per_date_df, how=\"outer\", on=[\"Country/Region\", \"Province/State\", \"County\", \"Date\"])\n",
        "df = df.merge(all_csc_recv_per_date_df, how=\"outer\", on=[\"Country/Region\", \"Province/State\", \"County\", \"Date\"])\n",
        "df = df.merge(all_csc_death_per_date_df, how=\"outer\", on=[\"Country/Region\", \"Province/State\", \"County\", \"Date\"])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "(119, 14)"
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "df[(df[\"Country/Region\"] == \"United States of America\") & (df[\"Province/State\"] == \"nan\")].sort_values([\"Date\"]).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ]
      },
      "outputs": [],
      "source": [
        "# Beginning on March 22 the US county data for Confirmed, Deaths & Recovered \n",
        "# need to be aggregated for state-wide values.  ConfirmedPerDate, DeathsPerDate &\n",
        "# RecoveredPerDate need to be aggregated beginning on March 23.\n",
        "us_cnty_mask = (df[\"Country/Region\"] == \"United States of America\") & (df.County != \"nan\")\n",
        "us_state_mask = (df[\"Country/Region\"] == \"United States of America\") & (df.County == \"nan\")\n",
        "cumul_vars = [\"Confirmed\", \"Recovered\", \"Deaths\"]\n",
        "perday_vars = [\"ConfirmedPerDate\", \"RecoveredPerDate\", \"DeathsPerDate\"]\n",
        "for state in np.sort(df.loc[us_cnty_mask, \"Province/State\"].unique()):\n",
        "    for date in np.sort(df.loc[us_cnty_mask & (df[\"Province/State\"] == state), \"Date\"].unique()):\n",
        "        state_day_mask = us_state_mask & (df[\"Province/State\"] == state) & (df.Date == date)\n",
        "        counties_day_mask = us_cnty_mask & (df[\"Province/State\"] == state) & (df.Date == date)\n",
        "        if pd.to_datetime(date) > pd.datetime(2020, 3, 21):\n",
        "            df.loc[state_day_mask, cumul_vars] = df.loc[counties_day_mask, cumul_vars].sum().values\n",
        "        \n",
        "        if pd.to_datetime(date) > pd.datetime(2020, 3, 22):\n",
        "            df.loc[state_day_mask, perday_vars] = df.loc[counties_day_mask, perday_vars].sum().values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "  Country/Region Province/State County       Date  Confirmed  Deaths  \\\n0    Afghanistan            nan    nan 2020-02-24        1.0     0.0   \n1    Afghanistan            nan    nan 2020-02-25        1.0     0.0   \n2    Afghanistan            nan    nan 2020-02-26        1.0     0.0   \n\n   Recovered  Latitude  Longitude  FIPS  Active ConfirmedPerDate  \\\n0        0.0       0.0        0.0   0.0     0.0              NaN   \n1        0.0       0.0        0.0   0.0     0.0                0   \n2        0.0       0.0        0.0   0.0     0.0                0   \n\n  RecoveredPerDate DeathsPerDate USstateAbbr  \n0              NaN           NaN         nan  \n1                0             0         nan  \n2                0             0         nan  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country/Region</th>\n      <th>Province/State</th>\n      <th>County</th>\n      <th>Date</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>FIPS</th>\n      <th>Active</th>\n      <th>ConfirmedPerDate</th>\n      <th>RecoveredPerDate</th>\n      <th>DeathsPerDate</th>\n      <th>USstateAbbr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-02-24</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-02-25</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Afghanistan</td>\n      <td>nan</td>\n      <td>nan</td>\n      <td>2020-02-26</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>nan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# make a column for US state abbreviations (used by Dash)\n",
        "states_dict = {\n",
        "        'AK': 'Alaska',\n",
        "        'AL': 'Alabama',\n",
        "        'AR': 'Arkansas',\n",
        "        'AS': 'American Samoa',\n",
        "        'AZ': 'Arizona',\n",
        "        'CA': 'California',\n",
        "        'CO': 'Colorado',\n",
        "        'CT': 'Connecticut',\n",
        "        'DC': 'District of Columbia',\n",
        "        'DE': 'Delaware',\n",
        "        'FL': 'Florida',\n",
        "        'GA': 'Georgia',\n",
        "        'GU': 'Guam',\n",
        "        'HI': 'Hawaii',\n",
        "        'IA': 'Iowa',\n",
        "        'ID': 'Idaho',\n",
        "        'IL': 'Illinois',\n",
        "        'IN': 'Indiana',\n",
        "        'KS': 'Kansas',\n",
        "        'KY': 'Kentucky',\n",
        "        'LA': 'Louisiana',\n",
        "        'MA': 'Massachusetts',\n",
        "        'MD': 'Maryland',\n",
        "        'ME': 'Maine',\n",
        "        'MI': 'Michigan',\n",
        "        'MN': 'Minnesota',\n",
        "        'MO': 'Missouri',\n",
        "        'MP': 'Northern Mariana Islands',\n",
        "        'MS': 'Mississippi',\n",
        "        'MT': 'Montana',\n",
        "        'NA': 'National',\n",
        "        'NC': 'North Carolina',\n",
        "        'ND': 'North Dakota',\n",
        "        'NE': 'Nebraska',\n",
        "        'NH': 'New Hampshire',\n",
        "        'NJ': 'New Jersey',\n",
        "        'NM': 'New Mexico',\n",
        "        'NV': 'Nevada',\n",
        "        'NY': 'New York',\n",
        "        'OH': 'Ohio',\n",
        "        'OK': 'Oklahoma',\n",
        "        'OR': 'Oregon',\n",
        "        'PA': 'Pennsylvania',\n",
        "        'PR': 'Puerto Rico',\n",
        "        'RI': 'Rhode Island',\n",
        "        'SC': 'South Carolina',\n",
        "        'SD': 'South Dakota',\n",
        "        'TN': 'Tennessee',\n",
        "        'TX': 'Texas',\n",
        "        'UT': 'Utah',\n",
        "        'VA': 'Virginia',\n",
        "        'VI': 'Virgin Islands',\n",
        "        'VT': 'Vermont',\n",
        "        'WA': 'Washington',\n",
        "        'WI': 'Wisconsin',\n",
        "        'WV': 'West Virginia',\n",
        "        'WY': 'Wyoming',\n",
        "        'nan': 'nan'\n",
        "}\n",
        "\n",
        "inverted_state_dict = {value: key for key, value in states_dict.items()}\n",
        "df[\"USstateAbbr\"] = df[\"Province/State\"].replace(inverted_state_dict)\n",
        "df.loc[df[\"Country/Region\"] != \"United States of America\", \"USstateAbbr\"] = \"nan\"\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "df3 = df\n",
        "#df = df3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "     State          County   FIPS  Population\n0  Alabama         Alabama    NaN     4903185\n1  Alabama  Autauga County  01001       55869\n2  Alabama  Baldwin County  01003      223234",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>State</th>\n      <th>County</th>\n      <th>FIPS</th>\n      <th>Population</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alabama</td>\n      <td>Alabama</td>\n      <td>NaN</td>\n      <td>4903185</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alabama</td>\n      <td>Autauga County</td>\n      <td>01001</td>\n      <td>55869</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Alabama</td>\n      <td>Baldwin County</td>\n      <td>01003</td>\n      <td>223234</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# calculate US county per capita variables\n",
        "us_pop_df = pd.read_pickle(r\"C:\\Users\\adiad\\Anaconda3\\envs\\CovidApp\\covidapp\\data_clean\\us_pop_df.pkl\")\n",
        "us_pop_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "FIPS  Population\n01001 55869\n01003 223234\n01005 24686\n"
        }
      ],
      "source": [
        "# create a dict to trnsform us counties to their population\n",
        "us_cnty_pop_dict = {}\n",
        "us_cnty_pop_df = us_pop_df[us_pop_df.FIPS.notna()]\n",
        "for fips in us_cnty_pop_df.FIPS:\n",
        "    pop = us_cnty_pop_df.loc[us_cnty_pop_df.FIPS == fips, \"Population\"].values[0]\n",
        "    us_cnty_pop_dict.update({fips:pop})\n",
        "\n",
        "print(\"FIPS  Population\")\n",
        "for x in list(us_cnty_pop_dict)[:3]:\n",
        "    print(x, us_cnty_pop_dict[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIPS is supposed to be 5 numeric characters\n",
        "# with 0 padding on the left\n",
        "df.FIPS[df.FIPS.isna() | df.FIPS.isnull()] = 0\n",
        "df.FIPS = df.FIPS.astype(int).astype(str)\n",
        "df.loc[(df.FIPS.str.len() > 1) & (df.FIPS.str.len() < 5), \"FIPS\"] = \\\n",
        "    df.loc[(df.FIPS.str.len() > 1) & \\\n",
        "           (df.FIPS.str.len() < 5), \"FIPS\"].str.pad(width=5, side=\"left\", fillchar=\"0\")\n",
        "df.FIPS[df.FIPS.str.startswith(\"8\") | df.FIPS.str.startswith(\"9\")] = \"0\"\n",
        "df.loc[df.FIPS == \"22002\", \"FIPS\"] = \"11001\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "                 Country/Region Province/State   County       Date  Confirmed  \\\n19338  United States of America        Alabama  Autauga 2020-03-22        0.0   \n19339  United States of America        Alabama  Autauga 2020-03-23        0.0   \n19340  United States of America        Alabama  Autauga 2020-03-24        1.0   \n19341  United States of America        Alabama  Autauga 2020-03-25        4.0   \n19342  United States of America        Alabama  Autauga 2020-03-26        6.0   \n19343  United States of America        Alabama  Autauga 2020-03-27        6.0   \n19344  United States of America        Alabama  Autauga 2020-03-28        6.0   \n19345  United States of America        Alabama  Autauga 2020-03-29        6.0   \n19346  United States of America        Alabama  Autauga 2020-03-30        6.0   \n19347  United States of America        Alabama  Autauga 2020-03-31        7.0   \n\n       Deaths  Recovered   FIPS  Active ConfirmedPerDate RecoveredPerDate  \\\n19338     0.0        0.0  01001     0.0              NaN              NaN   \n19339     0.0        0.0  01001     0.0                0                0   \n19340     0.0        0.0  01001     0.0                1                0   \n19341     0.0        0.0  01001     0.0                3                0   \n19342     0.0        0.0  01001     0.0                2                0   \n19343     0.0        0.0  01001     0.0                0                0   \n19344     0.0        0.0  01001     0.0                0                0   \n19345     0.0        0.0  01001     0.0                0                0   \n19346     0.0        0.0  01001     0.0                0                0   \n19347     0.0        0.0  01001     0.0                1                0   \n\n      DeathsPerDate USstateAbbr  ConfirmedPerCapita  RecoveredPerCapita  \\\n19338           NaN          AL            0.000000                 0.0   \n19339             0          AL            0.000000                 0.0   \n19340             0          AL            0.000018                 0.0   \n19341             0          AL            0.000072                 0.0   \n19342             0          AL            0.000107                 0.0   \n19343             0          AL            0.000107                 0.0   \n19344             0          AL            0.000107                 0.0   \n19345             0          AL            0.000107                 0.0   \n19346             0          AL            0.000107                 0.0   \n19347             0          AL            0.000125                 0.0   \n\n       DeathsPerCapita  ConfirmedPerDatePerCapita  RecoveredPerDatePerCapita  \\\n19338              0.0                        NaN                        NaN   \n19339              0.0                   0.000000                        0.0   \n19340              0.0                   0.000018                        0.0   \n19341              0.0                   0.000054                        0.0   \n19342              0.0                   0.000036                        0.0   \n19343              0.0                   0.000000                        0.0   \n19344              0.0                   0.000000                        0.0   \n19345              0.0                   0.000000                        0.0   \n19346              0.0                   0.000000                        0.0   \n19347              0.0                   0.000018                        0.0   \n\n       DeathsPerDatePerCapita  Population  \n19338                     NaN       55869  \n19339                     0.0       55869  \n19340                     0.0       55869  \n19341                     0.0       55869  \n19342                     0.0       55869  \n19343                     0.0       55869  \n19344                     0.0       55869  \n19345                     0.0       55869  \n19346                     0.0       55869  \n19347                     0.0       55869  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country/Region</th>\n      <th>Province/State</th>\n      <th>County</th>\n      <th>Date</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n      <th>FIPS</th>\n      <th>Active</th>\n      <th>ConfirmedPerDate</th>\n      <th>RecoveredPerDate</th>\n      <th>DeathsPerDate</th>\n      <th>USstateAbbr</th>\n      <th>ConfirmedPerCapita</th>\n      <th>RecoveredPerCapita</th>\n      <th>DeathsPerCapita</th>\n      <th>ConfirmedPerDatePerCapita</th>\n      <th>RecoveredPerDatePerCapita</th>\n      <th>DeathsPerDatePerCapita</th>\n      <th>Population</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19338</th>\n      <td>United States of America</td>\n      <td>Alabama</td>\n      <td>Autauga</td>\n      <td>2020-03-22</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>01001</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>AL</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>55869</td>\n    </tr>\n    <tr>\n      <th>19339</th>\n      <td>United States of America</td>\n      <td>Alabama</td>\n      <td>Autauga</td>\n      <td>2020-03-23</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>01001</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>AL</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>55869</td>\n    </tr>\n    <tr>\n      <th>19340</th>\n      <td>United States of America</td>\n      <td>Alabama</td>\n      <td>Autauga</td>\n      <td>2020-03-24</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>01001</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>AL</td>\n      <td>0.000018</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000018</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>55869</td>\n    </tr>\n    <tr>\n      <th>19341</th>\n      <td>United States of America</td>\n      <td>Alabama</td>\n      <td>Autauga</td>\n      <td>2020-03-25</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>01001</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>AL</td>\n      <td>0.000072</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000054</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>55869</td>\n    </tr>\n    <tr>\n      <th>19342</th>\n      <td>United States of America</td>\n      <td>Alabama</td>\n      <td>Autauga</td>\n      <td>2020-03-26</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>01001</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>AL</td>\n      <td>0.000107</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000036</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>55869</td>\n    </tr>\n    <tr>\n      <th>19343</th>\n      <td>United States of America</td>\n      <td>Alabama</td>\n      <td>Autauga</td>\n      <td>2020-03-27</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>01001</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>AL</td>\n      <td>0.000107</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>55869</td>\n    </tr>\n    <tr>\n      <th>19344</th>\n      <td>United States of America</td>\n      <td>Alabama</td>\n      <td>Autauga</td>\n      <td>2020-03-28</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>01001</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>AL</td>\n      <td>0.000107</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>55869</td>\n    </tr>\n    <tr>\n      <th>19345</th>\n      <td>United States of America</td>\n      <td>Alabama</td>\n      <td>Autauga</td>\n      <td>2020-03-29</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>01001</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>AL</td>\n      <td>0.000107</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>55869</td>\n    </tr>\n    <tr>\n      <th>19346</th>\n      <td>United States of America</td>\n      <td>Alabama</td>\n      <td>Autauga</td>\n      <td>2020-03-30</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>01001</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>AL</td>\n      <td>0.000107</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>55869</td>\n    </tr>\n    <tr>\n      <th>19347</th>\n      <td>United States of America</td>\n      <td>Alabama</td>\n      <td>Autauga</td>\n      <td>2020-03-31</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>01001</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>AL</td>\n      <td>0.000125</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000018</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>55869</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# calculate per capita values for US counties\n",
        "case_vars = [\"Confirmed\", \"Recovered\", \"Deaths\"]\n",
        "cap_vars = [var + \"PerCapita\" for var in case_vars]\n",
        "date_vars = [var + \"PerDate\" for var in case_vars]\n",
        "cap_date_vars = [var + \"PerCapita\" for var in date_vars]\n",
        "per_day_cap_factor = 1\n",
        "\n",
        "# create per capita columns with arbitrary float values\n",
        "for var in cap_vars + cap_date_vars:\n",
        "    df[var] = np.nan\n",
        "\n",
        "# add population data to dataframe\n",
        "df[\"Population\"] = df.FIPS\n",
        "df.Population = df.Population.replace(us_cnty_pop_dict)\n",
        "\n",
        "# calculate per capita values\n",
        "us_cnty_mask = (df[\"Country/Region\"] == \"United States of America\") & \\\n",
        "               (df.Date > pd.datetime(2020, 3, 21)) & (df.FIPS.isin(us_cnty_pop_dict.keys()))\n",
        "pop_arr = df.loc[us_cnty_mask, \"Population\"].values\n",
        "df.loc[us_cnty_mask, cap_vars] = df.loc[us_cnty_mask, case_vars].values / \\\n",
        "                                 np.stack((pop_arr for i in range(3)), axis=1)\n",
        "df.loc[us_cnty_mask, cap_date_vars] = df.loc[us_cnty_mask, date_vars].values * per_day_cap_factor / \\\n",
        "                                      np.stack((pop_arr for i in range(3)), axis=1)\n",
        "\n",
        "df[us_cnty_mask].drop([\"Latitude\", \"Longitude\"], axis=1).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array(['0', '00250', '60000', '66000', '00066', '69000', '00069', '00072',\n       '78000', '00078'], dtype=object)"
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "df.FIPS[(~df.FIPS.isin(us_cnty_pop_dict.keys()))].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "                  Country/Region Province/State County       Date  Confirmed  \\\n417768  United States of America           Ohio    nan 2020-01-22        NaN   \n407251  United States of America           Ohio    nan 2020-01-23        NaN   \n421277  United States of America           Ohio    nan 2020-01-24        NaN   \n410756  United States of America           Ohio    nan 2020-01-25        NaN   \n414258  United States of America           Ohio    nan 2020-01-26        NaN   \n...                          ...            ...    ...        ...        ...   \n134324  United States of America           Ohio    nan 2020-05-15    26954.0   \n134325  United States of America           Ohio    nan 2020-05-16    27474.0   \n134326  United States of America           Ohio    nan 2020-05-17    27923.0   \n134327  United States of America           Ohio    nan 2020-05-18    28454.0   \n134328  United States of America           Ohio    nan 2020-05-19    28952.0   \n\n        Deaths  Recovered  Latitude  Longitude FIPS  ...  RecoveredPerDate  \\\n417768     NaN        NaN       NaN        NaN    0  ...               NaN   \n407251     NaN        NaN       NaN        NaN    0  ...               NaN   \n421277     NaN        NaN       NaN        NaN    0  ...               NaN   \n410756     NaN        NaN       NaN        NaN    0  ...               NaN   \n414258     NaN        NaN       NaN        NaN    0  ...               NaN   \n...        ...        ...       ...        ...  ...  ...               ...   \n134324  1581.0        0.0       0.0        0.0    0  ...                 0   \n134325  1610.0        0.0       0.0        0.0    0  ...                 0   \n134326  1625.0        0.0       0.0        0.0    0  ...                 0   \n134327  1657.0        0.0       0.0        0.0    0  ...                 0   \n134328  1720.0        0.0       0.0        0.0    0  ...                 0   \n\n       DeathsPerDate USstateAbbr ConfirmedPerCapita RecoveredPerCapita  \\\n417768           NaN          OH                NaN                NaN   \n407251           NaN          OH                NaN                NaN   \n421277           NaN          OH                NaN                NaN   \n410756           NaN          OH                NaN                NaN   \n414258           NaN          OH                NaN                NaN   \n...              ...         ...                ...                ...   \n134324            47          OH                NaN                NaN   \n134325            29          OH                NaN                NaN   \n134326            15          OH                NaN                NaN   \n134327            32          OH                NaN                NaN   \n134328            63          OH                NaN                NaN   \n\n        DeathsPerCapita  ConfirmedPerDatePerCapita  RecoveredPerDatePerCapita  \\\n417768              NaN                        NaN                        NaN   \n407251              NaN                        NaN                        NaN   \n421277              NaN                        NaN                        NaN   \n410756              NaN                        NaN                        NaN   \n414258              NaN                        NaN                        NaN   \n...                 ...                        ...                        ...   \n134324              NaN                        NaN                        NaN   \n134325              NaN                        NaN                        NaN   \n134326              NaN                        NaN                        NaN   \n134327              NaN                        NaN                        NaN   \n134328              NaN                        NaN                        NaN   \n\n        DeathsPerDatePerCapita  Population  \n417768                     NaN           0  \n407251                     NaN           0  \n421277                     NaN           0  \n410756                     NaN           0  \n414258                     NaN           0  \n...                        ...         ...  \n134324                     NaN           0  \n134325                     NaN           0  \n134326                     NaN           0  \n134327                     NaN           0  \n134328                     NaN           0  \n\n[119 rows x 22 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country/Region</th>\n      <th>Province/State</th>\n      <th>County</th>\n      <th>Date</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>FIPS</th>\n      <th>...</th>\n      <th>RecoveredPerDate</th>\n      <th>DeathsPerDate</th>\n      <th>USstateAbbr</th>\n      <th>ConfirmedPerCapita</th>\n      <th>RecoveredPerCapita</th>\n      <th>DeathsPerCapita</th>\n      <th>ConfirmedPerDatePerCapita</th>\n      <th>RecoveredPerDatePerCapita</th>\n      <th>DeathsPerDatePerCapita</th>\n      <th>Population</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>417768</th>\n      <td>United States of America</td>\n      <td>Ohio</td>\n      <td>nan</td>\n      <td>2020-01-22</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>OH</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>407251</th>\n      <td>United States of America</td>\n      <td>Ohio</td>\n      <td>nan</td>\n      <td>2020-01-23</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>OH</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>421277</th>\n      <td>United States of America</td>\n      <td>Ohio</td>\n      <td>nan</td>\n      <td>2020-01-24</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>OH</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>410756</th>\n      <td>United States of America</td>\n      <td>Ohio</td>\n      <td>nan</td>\n      <td>2020-01-25</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>OH</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>414258</th>\n      <td>United States of America</td>\n      <td>Ohio</td>\n      <td>nan</td>\n      <td>2020-01-26</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>OH</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>134324</th>\n      <td>United States of America</td>\n      <td>Ohio</td>\n      <td>nan</td>\n      <td>2020-05-15</td>\n      <td>26954.0</td>\n      <td>1581.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>47</td>\n      <td>OH</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>134325</th>\n      <td>United States of America</td>\n      <td>Ohio</td>\n      <td>nan</td>\n      <td>2020-05-16</td>\n      <td>27474.0</td>\n      <td>1610.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>29</td>\n      <td>OH</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>134326</th>\n      <td>United States of America</td>\n      <td>Ohio</td>\n      <td>nan</td>\n      <td>2020-05-17</td>\n      <td>27923.0</td>\n      <td>1625.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>15</td>\n      <td>OH</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>134327</th>\n      <td>United States of America</td>\n      <td>Ohio</td>\n      <td>nan</td>\n      <td>2020-05-18</td>\n      <td>28454.0</td>\n      <td>1657.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>32</td>\n      <td>OH</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>134328</th>\n      <td>United States of America</td>\n      <td>Ohio</td>\n      <td>nan</td>\n      <td>2020-05-19</td>\n      <td>28952.0</td>\n      <td>1720.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>63</td>\n      <td>OH</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>119 rows × 22 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "df4 = df\n",
        "#df = df4\n",
        "df4[(df4[\"Province/State\"] == \"Ohio\") & (df4.County == \"nan\")].sort_values(by=[\"Date\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "State  Population\nAlabama 4903185\nAlaska 731545\nAmerican Samoa nan\n"
        }
      ],
      "source": [
        "# create a dict to trnsform us states to their population\n",
        "us_state_mask = (df[\"Country/Region\"] == \"United States of America\") & (df.County == \"nan\")\n",
        "\n",
        "us_state_pop_dict = {}\n",
        "for state in np.sort(df.loc[us_state_mask, \"Province/State\"].unique().tolist()):\n",
        "    fips_ls = np.sort(df.loc[us_cnty_mask & (df[\"Province/State\"] == state), \"FIPS\"].unique())\n",
        "    pop = us_cnty_pop_df.loc[us_cnty_pop_df.FIPS.isin(fips_ls), \"Population\"].values.sum()\n",
        "    if pop > 0:\n",
        "        us_state_pop_dict.update({state:pop})\n",
        "    else:\n",
        "        us_state_pop_dict.update({state:np.nan})\n",
        "\n",
        "print(\"State  Population\")\n",
        "for x in list(us_state_pop_dict)[:3]:\n",
        "    print(x, us_state_pop_dict[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ]
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "                  Country/Region Province/State County       Date  Confirmed  \\\n23281   United States of America        Alabama    nan 2020-04-20     5079.0   \n24226   United States of America         Alaska    nan 2020-04-20      321.0   \n25233   United States of America        Arizona    nan 2020-04-20     5068.0   \n29481   United States of America       Arkansas    nan 2020-04-20     1928.0   \n32779   United States of America     California    nan 2020-04-20    33686.0   \n36289   United States of America       Colorado    nan 2020-04-20     9616.0   \n36827   United States of America    Connecticut    nan 2020-04-20    19301.0   \n37068   United States of America       Delaware    nan 2020-04-20     2714.0   \n41111   United States of America        Florida    nan 2020-04-20    27056.0   \n50444   United States of America        Georgia    nan 2020-04-20    19111.0   \n50510   United States of America           Guam    nan 2020-04-20      136.0   \n50872   United States of America         Hawaii    nan 2020-04-20      584.0   \n53014   United States of America          Idaho    nan 2020-04-20     1672.0   \n58548   United States of America       Illinois    nan 2020-04-20    31383.0   \n63981   United States of America        Indiana    nan 2020-04-20    11688.0   \n69185   United States of America           Iowa    nan 2020-04-20     3157.0   \n73794   United States of America         Kansas    nan 2020-04-20     2048.0   \n80102   United States of America       Kentucky    nan 2020-04-20     2977.0   \n83923   United States of America      Louisiana    nan 2020-04-20    24464.0   \n84910   United States of America          Maine    nan 2020-04-20      874.0   \n86383   United States of America       Maryland    nan 2020-04-20    13684.0   \n87277   United States of America  Massachusetts    nan 2020-04-20    37262.0   \n92117   United States of America       Michigan    nan 2020-04-20    31972.0   \n96703   United States of America      Minnesota    nan 2020-04-20     2466.0   \n101523  United States of America    Mississippi    nan 2020-04-20     4512.0   \n107336  United States of America       Missouri    nan 2020-04-20     5890.0   \n109337  United States of America        Montana    nan 2020-04-20      433.0   \n113012  United States of America       Nebraska    nan 2020-04-20     1611.0   \n113907  United States of America         Nevada    nan 2020-04-20     3794.0   \n114566  United States of America  New Hampshire    nan 2020-04-20     1443.0   \n\n        Deaths  Recovered  Latitude  Longitude   FIPS  ...  RecoveredPerDate  \\\n23281    163.0        0.0    0.0000     0.0000      0  ...                 0   \n24226      5.0        0.0    0.0000     0.0000      0  ...                 0   \n25233    190.0        0.0    0.0000     0.0000      0  ...                 0   \n29481     41.0        0.0    0.0000     0.0000      0  ...                 0   \n32779   1223.0        0.0    0.0000     0.0000      0  ...                 0   \n36289    419.0        0.0    0.0000     0.0000      0  ...                 0   \n36827   1327.0        0.0    0.0000     0.0000      0  ...                 0   \n37068     72.0        0.0    0.0000     0.0000      0  ...                 0   \n41111    822.0        0.0    0.0000     0.0000      0  ...                 0   \n50444    773.0        0.0    0.0000     0.0000      0  ...                 0   \n50510      5.0        0.0   13.4443   144.7937  00066  ...                 0   \n50872     10.0        0.0    0.0000     0.0000      0  ...                 0   \n53014     45.0        0.0    0.0000     0.0000      0  ...                 0   \n58548   1346.0        0.0    0.0000     0.0000      0  ...                 0   \n63981    577.0        0.0    0.0000     0.0000      0  ...                 0   \n69185     79.0        0.0    0.0000     0.0000      0  ...                 0   \n73794    102.0        0.0    0.0000     0.0000      0  ...                 0   \n80102    154.0        0.0    0.0000     0.0000      0  ...                 0   \n83923   1327.0        0.0    0.0000     0.0000      0  ...                 0   \n84910     35.0        0.0    0.0000     0.0000      0  ...                 0   \n86383    490.0        0.0    0.0000     0.0000      0  ...                 0   \n87277   1686.0        0.0    0.0000     0.0000      0  ...                 0   \n92117   2464.0        0.0    0.0000     0.0000      0  ...                 0   \n96703    143.0        0.0    0.0000     0.0000      0  ...                 0   \n101523   169.0        0.0    0.0000     0.0000      0  ...                 0   \n107336   200.0        0.0    0.0000     0.0000      0  ...                 0   \n109337    10.0        0.0    0.0000     0.0000      0  ...                 0   \n113012    18.0        0.0    0.0000     0.0000      0  ...                 0   \n113907   159.0        0.0    0.0000     0.0000      0  ...                 0   \n114566     3.0        0.0    0.0000     0.0000      0  ...                 0   \n\n       DeathsPerDate USstateAbbr ConfirmedPerCapita RecoveredPerCapita  \\\n23281              6          AL           0.001036                0.0   \n24226              0          AK           0.000439                0.0   \n25233              7          AZ           0.000696                0.0   \n29481              2          AR           0.000639                0.0   \n32779             48          CA           0.000853                0.0   \n36289              0          CO           0.001670                0.0   \n36827            204          CT           0.005414                0.0   \n37068              5          DE           0.002787                0.0   \n41111             48          FL           0.001260                0.0   \n50444             86          GA           0.001800                0.0   \n50510              0          GU                NaN                NaN   \n50872              0          HI           0.000412                0.0   \n53014              1          ID           0.000936                0.0   \n58548             59          IL           0.002477                0.0   \n63981             15          IN           0.001736                0.0   \n69185              4          IA           0.001001                0.0   \n73794              9          KS           0.000703                0.0   \n80102             14          KY           0.000666                0.0   \n83923             32          LA           0.005262                0.0   \n84910              1          ME           0.000650                0.0   \n86383             29          MD           0.002263                0.0   \n87277              0          MA           0.005406                0.0   \n92117             77          MI           0.003201                0.0   \n96703              9          MN           0.000437                0.0   \n101523            10          MS           0.001516                0.0   \n107336             1          MO           0.000960                0.0   \n109337             0          MT           0.000405                0.0   \n113012             0          NE           0.000833                0.0   \n113907             1          NV           0.001232                0.0   \n114566             0          NH           0.001061                0.0   \n\n        DeathsPerCapita  ConfirmedPerDatePerCapita  RecoveredPerDatePerCapita  \\\n23281          0.000033                   0.000039                        0.0   \n24226          0.000007                   0.000003                        0.0   \n25233          0.000026                   0.000019                        0.0   \n29481          0.000014                   0.000064                        0.0   \n32779          0.000031                   0.000057                        0.0   \n36289          0.000073                   0.000000                        0.0   \n36827          0.000372                   0.000524                        0.0   \n37068          0.000074                   0.000212                        0.0   \n41111          0.000038                   0.000035                        0.0   \n50444          0.000073                   0.000100                        0.0   \n50510               NaN                        NaN                        NaN   \n50872          0.000007                   0.000003                        0.0   \n53014          0.000025                   0.000002                        0.0   \n58548          0.000106                   0.000090                        0.0   \n63981          0.000086                   0.000071                        0.0   \n69185          0.000025                   0.000083                        0.0   \n73794          0.000035                   0.000049                        0.0   \n80102          0.000034                   0.000021                        0.0   \n83923          0.000285                   0.000128                        0.0   \n84910          0.000026                   0.000007                        0.0   \n86383          0.000081                   0.000138                        0.0   \n87277          0.000245                   0.000000                        0.0   \n92117          0.000247                   0.000058                        0.0   \n96703          0.000025                   0.000020                        0.0   \n101523         0.000057                   0.000080                        0.0   \n107336         0.000033                   0.000024                        0.0   \n109337         0.000009                   0.000000                        0.0   \n113012         0.000009                   0.000092                        0.0   \n113907         0.000052                   0.000028                        0.0   \n114566         0.000002                   0.000039                        0.0   \n\n        DeathsPerDatePerCapita  Population  \n23281             1.223694e-06   4903185.0  \n24226             0.000000e+00    731545.0  \n25233             9.617079e-07   7278717.0  \n29481             6.627336e-07   3017804.0  \n32779             1.214814e-06  39512223.0  \n36289             0.000000e+00   5758736.0  \n36827             5.721840e-05   3565287.0  \n37068             5.134714e-06    973764.0  \n41111             2.234872e-06  21477737.0  \n50444             8.099894e-06  10617423.0  \n50510                      NaN         NaN  \n50872             0.000000e+00   1415872.0  \n53014             5.595767e-07   1787065.0  \n58548             4.656000e-06  12671821.0  \n63981             2.228092e-06   6732219.0  \n69185             1.267801e-06   3155070.0  \n73794             3.089265e-06   2913314.0  \n80102             3.133622e-06   4467673.0  \n83923             6.883506e-06   4648794.0  \n84910             7.439303e-07   1344212.0  \n86383             4.796814e-06   6045680.0  \n87277             0.000000e+00   6892503.0  \n92117             7.710133e-06   9986857.0  \n96703             1.595849e-06   5639632.0  \n101523            3.360047e-06   2976149.0  \n107336            1.629347e-07   6137428.0  \n109337            0.000000e+00   1068778.0  \n113012            0.000000e+00   1934408.0  \n113907            3.246589e-07   3080156.0  \n114566            0.000000e+00   1359711.0  \n\n[30 rows x 22 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country/Region</th>\n      <th>Province/State</th>\n      <th>County</th>\n      <th>Date</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>FIPS</th>\n      <th>...</th>\n      <th>RecoveredPerDate</th>\n      <th>DeathsPerDate</th>\n      <th>USstateAbbr</th>\n      <th>ConfirmedPerCapita</th>\n      <th>RecoveredPerCapita</th>\n      <th>DeathsPerCapita</th>\n      <th>ConfirmedPerDatePerCapita</th>\n      <th>RecoveredPerDatePerCapita</th>\n      <th>DeathsPerDatePerCapita</th>\n      <th>Population</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23281</th>\n      <td>United States of America</td>\n      <td>Alabama</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>5079.0</td>\n      <td>163.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>6</td>\n      <td>AL</td>\n      <td>0.001036</td>\n      <td>0.0</td>\n      <td>0.000033</td>\n      <td>0.000039</td>\n      <td>0.0</td>\n      <td>1.223694e-06</td>\n      <td>4903185.0</td>\n    </tr>\n    <tr>\n      <th>24226</th>\n      <td>United States of America</td>\n      <td>Alaska</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>321.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>AK</td>\n      <td>0.000439</td>\n      <td>0.0</td>\n      <td>0.000007</td>\n      <td>0.000003</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>731545.0</td>\n    </tr>\n    <tr>\n      <th>25233</th>\n      <td>United States of America</td>\n      <td>Arizona</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>5068.0</td>\n      <td>190.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>7</td>\n      <td>AZ</td>\n      <td>0.000696</td>\n      <td>0.0</td>\n      <td>0.000026</td>\n      <td>0.000019</td>\n      <td>0.0</td>\n      <td>9.617079e-07</td>\n      <td>7278717.0</td>\n    </tr>\n    <tr>\n      <th>29481</th>\n      <td>United States of America</td>\n      <td>Arkansas</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>1928.0</td>\n      <td>41.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>AR</td>\n      <td>0.000639</td>\n      <td>0.0</td>\n      <td>0.000014</td>\n      <td>0.000064</td>\n      <td>0.0</td>\n      <td>6.627336e-07</td>\n      <td>3017804.0</td>\n    </tr>\n    <tr>\n      <th>32779</th>\n      <td>United States of America</td>\n      <td>California</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>33686.0</td>\n      <td>1223.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>48</td>\n      <td>CA</td>\n      <td>0.000853</td>\n      <td>0.0</td>\n      <td>0.000031</td>\n      <td>0.000057</td>\n      <td>0.0</td>\n      <td>1.214814e-06</td>\n      <td>39512223.0</td>\n    </tr>\n    <tr>\n      <th>36289</th>\n      <td>United States of America</td>\n      <td>Colorado</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>9616.0</td>\n      <td>419.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>CO</td>\n      <td>0.001670</td>\n      <td>0.0</td>\n      <td>0.000073</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>5758736.0</td>\n    </tr>\n    <tr>\n      <th>36827</th>\n      <td>United States of America</td>\n      <td>Connecticut</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>19301.0</td>\n      <td>1327.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>204</td>\n      <td>CT</td>\n      <td>0.005414</td>\n      <td>0.0</td>\n      <td>0.000372</td>\n      <td>0.000524</td>\n      <td>0.0</td>\n      <td>5.721840e-05</td>\n      <td>3565287.0</td>\n    </tr>\n    <tr>\n      <th>37068</th>\n      <td>United States of America</td>\n      <td>Delaware</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>2714.0</td>\n      <td>72.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>5</td>\n      <td>DE</td>\n      <td>0.002787</td>\n      <td>0.0</td>\n      <td>0.000074</td>\n      <td>0.000212</td>\n      <td>0.0</td>\n      <td>5.134714e-06</td>\n      <td>973764.0</td>\n    </tr>\n    <tr>\n      <th>41111</th>\n      <td>United States of America</td>\n      <td>Florida</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>27056.0</td>\n      <td>822.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>48</td>\n      <td>FL</td>\n      <td>0.001260</td>\n      <td>0.0</td>\n      <td>0.000038</td>\n      <td>0.000035</td>\n      <td>0.0</td>\n      <td>2.234872e-06</td>\n      <td>21477737.0</td>\n    </tr>\n    <tr>\n      <th>50444</th>\n      <td>United States of America</td>\n      <td>Georgia</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>19111.0</td>\n      <td>773.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>86</td>\n      <td>GA</td>\n      <td>0.001800</td>\n      <td>0.0</td>\n      <td>0.000073</td>\n      <td>0.000100</td>\n      <td>0.0</td>\n      <td>8.099894e-06</td>\n      <td>10617423.0</td>\n    </tr>\n    <tr>\n      <th>50510</th>\n      <td>United States of America</td>\n      <td>Guam</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>136.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>13.4443</td>\n      <td>144.7937</td>\n      <td>00066</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>GU</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50872</th>\n      <td>United States of America</td>\n      <td>Hawaii</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>584.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>HI</td>\n      <td>0.000412</td>\n      <td>0.0</td>\n      <td>0.000007</td>\n      <td>0.000003</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>1415872.0</td>\n    </tr>\n    <tr>\n      <th>53014</th>\n      <td>United States of America</td>\n      <td>Idaho</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>1672.0</td>\n      <td>45.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>ID</td>\n      <td>0.000936</td>\n      <td>0.0</td>\n      <td>0.000025</td>\n      <td>0.000002</td>\n      <td>0.0</td>\n      <td>5.595767e-07</td>\n      <td>1787065.0</td>\n    </tr>\n    <tr>\n      <th>58548</th>\n      <td>United States of America</td>\n      <td>Illinois</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>31383.0</td>\n      <td>1346.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>59</td>\n      <td>IL</td>\n      <td>0.002477</td>\n      <td>0.0</td>\n      <td>0.000106</td>\n      <td>0.000090</td>\n      <td>0.0</td>\n      <td>4.656000e-06</td>\n      <td>12671821.0</td>\n    </tr>\n    <tr>\n      <th>63981</th>\n      <td>United States of America</td>\n      <td>Indiana</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>11688.0</td>\n      <td>577.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>15</td>\n      <td>IN</td>\n      <td>0.001736</td>\n      <td>0.0</td>\n      <td>0.000086</td>\n      <td>0.000071</td>\n      <td>0.0</td>\n      <td>2.228092e-06</td>\n      <td>6732219.0</td>\n    </tr>\n    <tr>\n      <th>69185</th>\n      <td>United States of America</td>\n      <td>Iowa</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>3157.0</td>\n      <td>79.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>IA</td>\n      <td>0.001001</td>\n      <td>0.0</td>\n      <td>0.000025</td>\n      <td>0.000083</td>\n      <td>0.0</td>\n      <td>1.267801e-06</td>\n      <td>3155070.0</td>\n    </tr>\n    <tr>\n      <th>73794</th>\n      <td>United States of America</td>\n      <td>Kansas</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>2048.0</td>\n      <td>102.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>9</td>\n      <td>KS</td>\n      <td>0.000703</td>\n      <td>0.0</td>\n      <td>0.000035</td>\n      <td>0.000049</td>\n      <td>0.0</td>\n      <td>3.089265e-06</td>\n      <td>2913314.0</td>\n    </tr>\n    <tr>\n      <th>80102</th>\n      <td>United States of America</td>\n      <td>Kentucky</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>2977.0</td>\n      <td>154.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>14</td>\n      <td>KY</td>\n      <td>0.000666</td>\n      <td>0.0</td>\n      <td>0.000034</td>\n      <td>0.000021</td>\n      <td>0.0</td>\n      <td>3.133622e-06</td>\n      <td>4467673.0</td>\n    </tr>\n    <tr>\n      <th>83923</th>\n      <td>United States of America</td>\n      <td>Louisiana</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>24464.0</td>\n      <td>1327.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>32</td>\n      <td>LA</td>\n      <td>0.005262</td>\n      <td>0.0</td>\n      <td>0.000285</td>\n      <td>0.000128</td>\n      <td>0.0</td>\n      <td>6.883506e-06</td>\n      <td>4648794.0</td>\n    </tr>\n    <tr>\n      <th>84910</th>\n      <td>United States of America</td>\n      <td>Maine</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>874.0</td>\n      <td>35.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>ME</td>\n      <td>0.000650</td>\n      <td>0.0</td>\n      <td>0.000026</td>\n      <td>0.000007</td>\n      <td>0.0</td>\n      <td>7.439303e-07</td>\n      <td>1344212.0</td>\n    </tr>\n    <tr>\n      <th>86383</th>\n      <td>United States of America</td>\n      <td>Maryland</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>13684.0</td>\n      <td>490.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>29</td>\n      <td>MD</td>\n      <td>0.002263</td>\n      <td>0.0</td>\n      <td>0.000081</td>\n      <td>0.000138</td>\n      <td>0.0</td>\n      <td>4.796814e-06</td>\n      <td>6045680.0</td>\n    </tr>\n    <tr>\n      <th>87277</th>\n      <td>United States of America</td>\n      <td>Massachusetts</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>37262.0</td>\n      <td>1686.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>MA</td>\n      <td>0.005406</td>\n      <td>0.0</td>\n      <td>0.000245</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>6892503.0</td>\n    </tr>\n    <tr>\n      <th>92117</th>\n      <td>United States of America</td>\n      <td>Michigan</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>31972.0</td>\n      <td>2464.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>77</td>\n      <td>MI</td>\n      <td>0.003201</td>\n      <td>0.0</td>\n      <td>0.000247</td>\n      <td>0.000058</td>\n      <td>0.0</td>\n      <td>7.710133e-06</td>\n      <td>9986857.0</td>\n    </tr>\n    <tr>\n      <th>96703</th>\n      <td>United States of America</td>\n      <td>Minnesota</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>2466.0</td>\n      <td>143.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>9</td>\n      <td>MN</td>\n      <td>0.000437</td>\n      <td>0.0</td>\n      <td>0.000025</td>\n      <td>0.000020</td>\n      <td>0.0</td>\n      <td>1.595849e-06</td>\n      <td>5639632.0</td>\n    </tr>\n    <tr>\n      <th>101523</th>\n      <td>United States of America</td>\n      <td>Mississippi</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>4512.0</td>\n      <td>169.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>10</td>\n      <td>MS</td>\n      <td>0.001516</td>\n      <td>0.0</td>\n      <td>0.000057</td>\n      <td>0.000080</td>\n      <td>0.0</td>\n      <td>3.360047e-06</td>\n      <td>2976149.0</td>\n    </tr>\n    <tr>\n      <th>107336</th>\n      <td>United States of America</td>\n      <td>Missouri</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>5890.0</td>\n      <td>200.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>MO</td>\n      <td>0.000960</td>\n      <td>0.0</td>\n      <td>0.000033</td>\n      <td>0.000024</td>\n      <td>0.0</td>\n      <td>1.629347e-07</td>\n      <td>6137428.0</td>\n    </tr>\n    <tr>\n      <th>109337</th>\n      <td>United States of America</td>\n      <td>Montana</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>433.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>MT</td>\n      <td>0.000405</td>\n      <td>0.0</td>\n      <td>0.000009</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>1068778.0</td>\n    </tr>\n    <tr>\n      <th>113012</th>\n      <td>United States of America</td>\n      <td>Nebraska</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>1611.0</td>\n      <td>18.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NE</td>\n      <td>0.000833</td>\n      <td>0.0</td>\n      <td>0.000009</td>\n      <td>0.000092</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>1934408.0</td>\n    </tr>\n    <tr>\n      <th>113907</th>\n      <td>United States of America</td>\n      <td>Nevada</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>3794.0</td>\n      <td>159.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>NV</td>\n      <td>0.001232</td>\n      <td>0.0</td>\n      <td>0.000052</td>\n      <td>0.000028</td>\n      <td>0.0</td>\n      <td>3.246589e-07</td>\n      <td>3080156.0</td>\n    </tr>\n    <tr>\n      <th>114566</th>\n      <td>United States of America</td>\n      <td>New Hampshire</td>\n      <td>nan</td>\n      <td>2020-04-20</td>\n      <td>1443.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NH</td>\n      <td>0.001061</td>\n      <td>0.0</td>\n      <td>0.000002</td>\n      <td>0.000039</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>1359711.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>30 rows × 22 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# calculate per capita values for entire US states\n",
        "us_cnty_mask = (df[\"Country/Region\"] == \"United States of America\") & \\\n",
        "               (df.Date > pd.datetime(2020, 3, 21)) & (df.County != \"nan\")\n",
        "\n",
        "df.loc[us_state_mask, \"Population\"] = df.loc[us_state_mask, \"Province/State\"].replace(us_state_pop_dict)\n",
        "pop_arr = df.loc[us_state_mask, \"Population\"].values\n",
        "df.loc[us_state_mask, cap_vars] = df.loc[us_state_mask, case_vars].values / \\\n",
        "                                         np.stack((pop_arr for i in range(3)), axis=1)\n",
        "df.loc[us_state_mask, cap_date_vars] = df.loc[us_state_mask, date_vars].values * per_day_cap_factor / \\\n",
        "                                              np.stack((pop_arr for i in range(3)), axis=1)\n",
        "\n",
        "df[us_state_mask & (df.Date == pd.datetime(2020, 4, 20))].head(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "df5 = df\n",
        "#df = df5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ]
      },
      "outputs": [],
      "source": [
        "# aggregate US states into whole country rows\n",
        "all_us_mask = (df[\"Country/Region\"] == \"United States of America\") & (df.County == \"nan\")\n",
        "agg_pop = us_cnty_pop_df.Population.sum()\n",
        "pop_ls = [agg_pop for i in range(3)]\n",
        "factor = np.append(np.array([1, 1, 1]), per_day_cap_factor*np.array([1, 1, 1]))\n",
        "row_ls = []\n",
        "\n",
        "for date in np.sort(df.loc[all_us_mask, \"Date\"].unique()):\n",
        "\n",
        "    # start a new row by duplicating an extant row\n",
        "    all_us_agg_row = df[all_us_mask & (df.Date == date)].head(1)\n",
        "\n",
        "    # calculate aggregates and per capita values\n",
        "    agg_vars = df.loc[all_us_mask & (df.Date == date), case_vars].sum().values\n",
        "    all_us_agg_row[case_vars] = agg_vars\n",
        "    all_us_agg_row[cap_vars] = agg_vars / pop_ls\n",
        "\n",
        "    agg_vars = df.loc[all_us_mask & (df.Date == date), date_vars].sum().values\n",
        "    all_us_agg_row[date_vars] = agg_vars\n",
        "    all_us_agg_row[cap_date_vars] = agg_vars * per_day_cap_factor / pop_ls\n",
        "\n",
        "    # tweak row to reflect that its for th whole country\n",
        "    all_us_agg_row.County = \"nan\"\n",
        "    all_us_agg_row.FIPS = \"0\"\n",
        "    all_us_agg_row[\"Province/State\"] = \"nan\"\n",
        "    all_us_agg_row.USstateAbbr = \"nan\"\n",
        "    #print(all_us_agg_row[case_vars + date_vars + cap_vars + cap_date_vars].values)\n",
        "\n",
        "    # add row to dataframe\n",
        "    row_ls.append(all_us_agg_row)\n",
        "\n",
        "# combine new rows into dataframe\n",
        "all_us_df = pd.concat(row_ls, ignore_index=True)\n",
        "\n",
        "# delete extant rows for whole country\n",
        "df = df[~(all_us_mask & (df[\"Province/State\"] == \"nan\"))].reset_index(drop=True)\n",
        "\n",
        "# add each new row to end of dataframe\n",
        "for row in range(all_us_df.shape[0]):\n",
        "    df.loc[len(df.index)] = all_us_df.iloc[row,:].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "                               State   Population    Country\n0                    New South Wales    8089526.0  Australia\n1                         Queensland    5095100.0  Australia\n2                    South Australia    1751693.0  Australia\n3                           Tasmania     534281.0  Australia\n4                           Victoria    6594804.0  Australia\n5                  Western Australia    2621680.0  Australia\n6       Australian Capital Territory     426709.0  Australia\n7               Jervis Bay Territory        405.0  Australia\n8                 Northern Territory     245869.0  Australia\n9                                NaN          NaN  Australia\n10                             Anhui   59500510.0      China\n11                           Beijing   19612368.0      China\n12                         Chongqing   28846170.0      China\n13                            Fujian   36894216.0      China\n14                         Guangdong  104303132.0      China\n15                             Gansu   25575254.0      China\n16  Guangxi Zhuang Autonomous Region   46026629.0      China\n17                           Guizhou   34746468.0      China\n18                             Henan   94023567.0      China\n19                             Hubei   57237740.0      China",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>State</th>\n      <th>Population</th>\n      <th>Country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>New South Wales</td>\n      <td>8089526.0</td>\n      <td>Australia</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Queensland</td>\n      <td>5095100.0</td>\n      <td>Australia</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>South Australia</td>\n      <td>1751693.0</td>\n      <td>Australia</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Tasmania</td>\n      <td>534281.0</td>\n      <td>Australia</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Victoria</td>\n      <td>6594804.0</td>\n      <td>Australia</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Western Australia</td>\n      <td>2621680.0</td>\n      <td>Australia</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Australian Capital Territory</td>\n      <td>426709.0</td>\n      <td>Australia</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Jervis Bay Territory</td>\n      <td>405.0</td>\n      <td>Australia</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Northern Territory</td>\n      <td>245869.0</td>\n      <td>Australia</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Australia</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Anhui</td>\n      <td>59500510.0</td>\n      <td>China</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Beijing</td>\n      <td>19612368.0</td>\n      <td>China</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Chongqing</td>\n      <td>28846170.0</td>\n      <td>China</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Fujian</td>\n      <td>36894216.0</td>\n      <td>China</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Guangdong</td>\n      <td>104303132.0</td>\n      <td>China</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Gansu</td>\n      <td>25575254.0</td>\n      <td>China</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Guangxi Zhuang Autonomous Region</td>\n      <td>46026629.0</td>\n      <td>China</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Guizhou</td>\n      <td>34746468.0</td>\n      <td>China</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Henan</td>\n      <td>94023567.0</td>\n      <td>China</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Hubei</td>\n      <td>57237740.0</td>\n      <td>China</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# calculate Australia & China state/province per capita variables\n",
        "acc_pop_df = pd.read_pickle(r\"C:\\Users\\adiad\\Anaconda3\\envs\\CovidApp\\covidapp\\data_clean\\australia_china_canada_pop_df.pkl\")\n",
        "acc_pop_df.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "['New South Wales',\n 'Queensland',\n 'South Australia',\n 'Tasmania',\n 'Victoria',\n 'Western Australia',\n 'Australian Capital Territory',\n 'Jervis Bay Territory',\n 'Northern Territory',\n nan,\n 'Anhui',\n 'Beijing',\n 'Chongqing',\n 'Fujian',\n 'Guangdong',\n 'Gansu',\n 'Guangxi Zhuang Autonomous Region',\n 'Guizhou',\n 'Henan',\n 'Hubei',\n 'Hebei',\n 'Hainan',\n 'Hong Kong Special Administrative Region',\n 'Heilongjiang',\n 'Hunan',\n 'Jilin',\n 'Jiangsu',\n 'Jiangxi',\n 'Liaoning',\n 'Macau Special Administrative Region',\n 'Inner Mongolia Autonomous Region',\n 'Ningxia Hui Autonomous Region',\n 'Qinghai',\n 'Sichuan',\n 'Shandong',\n 'Shanghai',\n 'Shaanxi',\n 'Shanxi',\n 'Tianjin',\n 'Taiwan',\n 'Xinjiang Uyghur Autonomous Region',\n 'Tibet Autonomous Region',\n 'Yunnan',\n 'Zhejiang',\n 'Ontario',\n 'Quebec',\n 'British Columbia',\n 'Alberta',\n 'Manitoba',\n 'Saskatchewan',\n 'Nova Scotia',\n 'New Brunswick',\n 'Newfoundland and Labrador',\n 'Prince Edward Island',\n 'Northwest Territories',\n 'Nunavut',\n 'Yukon']"
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "acc_pop_df.State.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "['Australian Capital Territory',\n 'External territories',\n 'From Diamond Princess',\n 'Jervis Bay Territory',\n 'New South Wales',\n 'Northern Territory',\n 'Queensland',\n 'South Australia',\n 'Tasmania',\n 'Victoria',\n 'Western Australia',\n 'nan',\n 'Alberta',\n 'British Columbia',\n 'Manitoba',\n 'New Brunswick',\n 'Newfoundland and Labrador',\n 'Northwest Territories',\n 'Nova Scotia',\n 'Ontario',\n 'Prince Edward Island',\n 'Quebec',\n 'Saskatchewan',\n 'Yukon',\n 'Anhui',\n 'Beijing',\n 'Chongqing',\n 'Fujian',\n 'Gansu',\n 'Guangdong',\n 'Guangxi',\n 'Guizhou',\n 'Hainan',\n 'Hebei',\n 'Heilongjiang',\n 'Henan',\n 'Hubei',\n 'Hunan',\n 'Inner Mongolia',\n 'Jiangsu',\n 'Jiangxi',\n 'Jilin',\n 'Liaoning',\n 'Macau',\n 'Ningxia',\n 'Qinghai',\n 'Shaanxi',\n 'Shandong',\n 'Shanghai',\n 'Shanxi',\n 'Sichuan',\n 'Tianjin',\n 'Tibet',\n 'Xinjiang',\n 'Yunnan',\n 'Zhejiang']"
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "states = df.loc[df[\"Country/Region\"].isin([\"Australia\", \"China\", \"Canada\"]), \\\n",
        "                \"Province/State\"].unique().tolist()\n",
        "states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "['External territories',\n 'From Diamond Princess',\n 'nan',\n 'Guangxi',\n 'Inner Mongolia',\n 'Macau',\n 'Ningxia',\n 'Tibet',\n 'Xinjiang']"
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "acc_pop_df = acc_pop_df[acc_pop_df.State.notna()]\n",
        "\n",
        "# print epidemiology states/provinces which aren't matched in the population data\n",
        "[state for state in states if state not in acc_pop_df.State.to_list()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "# correct the unmatched states/provinces in the population data\n",
        "acc_pop_df.loc[acc_pop_df.State == \"Guangxi Zhuang Autonomous Region\", \"State\"] = \"Guangxi\"\n",
        "acc_pop_df.loc[acc_pop_df.State == \"Inner Mongolia Autonomous Region\", \"State\"] = \"Inner Mongolia\"\n",
        "acc_pop_df.loc[acc_pop_df.State == \"Macau Special Administrative Region\", \"State\"] = \"Macau\"\n",
        "acc_pop_df.loc[acc_pop_df.State == \"Ningxia Hui Autonomous Region\", \"State\"] = \"Ningxia\"\n",
        "acc_pop_df.loc[acc_pop_df.State == \"Tibet Autonomous Region\", \"State\"] = \"Tibet\"\n",
        "acc_pop_df.loc[acc_pop_df.State == \"Xinjiang Uyghur Autonomous Region\", \"State\"] = \"Xinjiang\"\n",
        "acc_pop_df.loc[acc_pop_df.State == \"Hong Kong Special Administrative Region\", \"State\"] = \"Hong Kong S.A.R.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "New South Wales\n             State  Population    Country\n0  New South Wales   8089526.0  Australia\n   \nQueensland\n        State  Population    Country\n1  Queensland   5095100.0  Australia\n   \nSouth Australia\n             State  Population    Country\n2  South Australia   1751693.0  Australia\n   \nTasmania\n      State  Population    Country\n3  Tasmania    534281.0  Australia\n   \nVictoria\n      State  Population    Country\n4  Victoria   6594804.0  Australia\n   \nWestern Australia\n               State  Population    Country\n5  Western Australia   2621680.0  Australia\n   \nAustralian Capital Territory\n                          State  Population    Country\n6  Australian Capital Territory    426709.0  Australia\n   \nJervis Bay Territory\n                  State  Population    Country\n7  Jervis Bay Territory       405.0  Australia\n   \nNorthern Territory\n                State  Population    Country\n8  Northern Territory    245869.0  Australia\n   \nAnhui\n    State  Population Country\n10  Anhui  59500510.0   China\n   \nBeijing\n      State  Population Country\n11  Beijing  19612368.0   China\n   \nChongqing\n        State  Population Country\n12  Chongqing  28846170.0   China\n   \nFujian\n     State  Population Country\n13  Fujian  36894216.0   China\n   \nGuangdong\n        State   Population Country\n14  Guangdong  104303132.0   China\n   \nGansu\n    State  Population Country\n15  Gansu  25575254.0   China\n   \nGuangxi\n      State  Population Country\n16  Guangxi  46026629.0   China\n   \nGuizhou\n      State  Population Country\n17  Guizhou  34746468.0   China\n   \nHenan\n    State  Population Country\n18  Henan  94023567.0   China\n   \nHubei\n    State  Population Country\n19  Hubei  57237740.0   China\n   \nHebei\n    State  Population Country\n20  Hebei  71854202.0   China\n   \nHainan\n     State  Population Country\n21  Hainan   9171300.0   China\n   \nHong Kong S.A.R.\n               State  Population Country\n22  Hong Kong S.A.R.   7061200.0   China\n   \nHeilongjiang\n           State  Population Country\n23  Heilongjiang  38312224.0   China\n   \nHunan\n    State  Population Country\n24  Hunan  65683722.0   China\n   \nJilin\n    State  Population Country\n25  Jilin  27462297.0   China\n   \nJiangsu\n      State  Population Country\n26  Jiangsu  78659903.0   China\n   \nJiangxi\n      State  Population Country\n27  Jiangxi  44567475.0   China\n   \nLiaoning\n       State  Population Country\n28  Liaoning  43746323.0   China\n   \nMacau\n    State  Population Country\n29  Macau    552300.0   China\n   \nInner Mongolia\n             State  Population Country\n30  Inner Mongolia  24706321.0   China\n   \nNingxia\n      State  Population Country\n31  Ningxia   6301350.0   China\n   \nQinghai\n      State  Population Country\n32  Qinghai   5626722.0   China\n   \nSichuan\n      State  Population Country\n33  Sichuan  80418200.0   China\n   \nShandong\n       State  Population Country\n34  Shandong  95793065.0   China\n   \nShanghai\n       State  Population Country\n35  Shanghai  23019148.0   China\n   \nShaanxi\n      State  Population Country\n36  Shaanxi  37327378.0   China\n   \nShanxi\n     State  Population Country\n37  Shanxi  35712111.0   China\n   \nTianjin\n      State  Population Country\n38  Tianjin  12938224.0   China\n   \nTaiwan\n     State  Population Country\n39  Taiwan  23162123.0   China\n   \nXinjiang\n       State  Population Country\n40  Xinjiang  21813334.0   China\n   \nTibet\n    State  Population Country\n41  Tibet   3002166.0   China\n   \nYunnan\n     State  Population Country\n42  Yunnan  45966239.0   China\n   \nZhejiang\n       State  Population Country\n43  Zhejiang  54426891.0   China\n   \nOntario\n      State  Population Country\n44  Ontario  13448494.0  Canada\n   \nQuebec\n     State  Population Country\n45  Quebec   8164361.0  Canada\n   \nBritish Columbia\n               State  Population Country\n46  British Columbia   4648055.0  Canada\n   \nAlberta\n      State  Population Country\n47  Alberta   4067175.0  Canada\n   \nManitoba\n       State  Population Country\n48  Manitoba   1278365.0  Canada\n   \nSaskatchewan\n           State  Population Country\n49  Saskatchewan   1098352.0  Canada\n   \nNova Scotia\n          State  Population Country\n50  Nova Scotia    923598.0  Canada\n   \nNew Brunswick\n            State  Population Country\n51  New Brunswick    747101.0  Canada\n   \nNewfoundland and Labrador\n                        State  Population Country\n52  Newfoundland and Labrador    519716.0  Canada\n   \nPrince Edward Island\n                   State  Population Country\n53  Prince Edward Island    142907.0  Canada\n   \nNorthwest Territories\n                    State  Population Country\n54  Northwest Territories     41786.0  Canada\n   \nNunavut\n      State  Population Country\n55  Nunavut     35944.0  Canada\n   \nYukon\n    State  Population Country\n56  Yukon     35874.0  Canada\n   \nState, Population\nNew South Wales , 8089526.0\nQueensland , 5095100.0\nSouth Australia , 1751693.0\n"
        }
      ],
      "source": [
        "# create a dict to transform states/provinces to their population\n",
        "acc_pop_dict = {}\n",
        "for province in acc_pop_df.State.unique():\n",
        "    print(province)\n",
        "    print(acc_pop_df[acc_pop_df.State == province])\n",
        "    print(\"   \")\n",
        "    pop = acc_pop_df.loc[acc_pop_df.State == province, \"Population\"].values[0]\n",
        "    acc_pop_dict.update({province:pop})\n",
        "\n",
        "print(\"State, Population\")\n",
        "for x in list(acc_pop_dict)[:3]:\n",
        "    print(x, \",\", acc_pop_dict[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "df6 = df\n",
        "#df = df6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "    Country/Region                Province/State County       Date  Confirmed  \\\n616      Australia  Australian Capital Territory    nan 2020-03-13        1.0   \n617      Australia  Australian Capital Territory    nan 2020-03-14        1.0   \n618      Australia  Australian Capital Territory    nan 2020-03-15        1.0   \n619      Australia  Australian Capital Territory    nan 2020-03-16        2.0   \n620      Australia  Australian Capital Territory    nan 2020-03-17        2.0   \n\n     Deaths  Recovered  Latitude  Longitude FIPS  ...  RecoveredPerDate  \\\n616     0.0        0.0  -35.4735   149.0124    0  ...               NaN   \n617     0.0        0.0  -35.4735   149.0124    0  ...                 0   \n618     0.0        0.0  -35.4735   149.0124    0  ...                 0   \n619     0.0        0.0  -35.4735   149.0124    0  ...                 0   \n620     0.0        0.0  -35.4735   149.0124    0  ...                 0   \n\n    DeathsPerDate USstateAbbr ConfirmedPerCapita RecoveredPerCapita  \\\n616           NaN         nan           0.000002                0.0   \n617             0         nan           0.000002                0.0   \n618             0         nan           0.000002                0.0   \n619             0         nan           0.000005                0.0   \n620             0         nan           0.000005                0.0   \n\n     DeathsPerCapita  ConfirmedPerDatePerCapita  RecoveredPerDatePerCapita  \\\n616              0.0                        NaN                        NaN   \n617              0.0                   0.000000                        0.0   \n618              0.0                   0.000000                        0.0   \n619              0.0                   0.000002                        0.0   \n620              0.0                   0.000000                        0.0   \n\n     DeathsPerDatePerCapita  Population  \n616                     NaN    426709.0  \n617                     0.0    426709.0  \n618                     0.0    426709.0  \n619                     0.0    426709.0  \n620                     0.0    426709.0  \n\n[5 rows x 22 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country/Region</th>\n      <th>Province/State</th>\n      <th>County</th>\n      <th>Date</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>FIPS</th>\n      <th>...</th>\n      <th>RecoveredPerDate</th>\n      <th>DeathsPerDate</th>\n      <th>USstateAbbr</th>\n      <th>ConfirmedPerCapita</th>\n      <th>RecoveredPerCapita</th>\n      <th>DeathsPerCapita</th>\n      <th>ConfirmedPerDatePerCapita</th>\n      <th>RecoveredPerDatePerCapita</th>\n      <th>DeathsPerDatePerCapita</th>\n      <th>Population</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>616</th>\n      <td>Australia</td>\n      <td>Australian Capital Territory</td>\n      <td>nan</td>\n      <td>2020-03-13</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-35.4735</td>\n      <td>149.0124</td>\n      <td>0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>nan</td>\n      <td>0.000002</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>426709.0</td>\n    </tr>\n    <tr>\n      <th>617</th>\n      <td>Australia</td>\n      <td>Australian Capital Territory</td>\n      <td>nan</td>\n      <td>2020-03-14</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-35.4735</td>\n      <td>149.0124</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>nan</td>\n      <td>0.000002</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>426709.0</td>\n    </tr>\n    <tr>\n      <th>618</th>\n      <td>Australia</td>\n      <td>Australian Capital Territory</td>\n      <td>nan</td>\n      <td>2020-03-15</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-35.4735</td>\n      <td>149.0124</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>nan</td>\n      <td>0.000002</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>426709.0</td>\n    </tr>\n    <tr>\n      <th>619</th>\n      <td>Australia</td>\n      <td>Australian Capital Territory</td>\n      <td>nan</td>\n      <td>2020-03-16</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-35.4735</td>\n      <td>149.0124</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>nan</td>\n      <td>0.000005</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000002</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>426709.0</td>\n    </tr>\n    <tr>\n      <th>620</th>\n      <td>Australia</td>\n      <td>Australian Capital Territory</td>\n      <td>nan</td>\n      <td>2020-03-17</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-35.4735</td>\n      <td>149.0124</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>nan</td>\n      <td>0.000005</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>426709.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# calculating per capita values for australian, chinese & canadian states/provinces\n",
        "acc_mask = df[\"Country/Region\"].isin([\"Australia\", \"China\", \"Canada\"]) & \\\n",
        "           (df[\"Province/State\"].isin(acc_pop_dict.keys()))\n",
        "df.loc[acc_mask, \"Population\"] = df.loc[acc_mask, \"Province/State\"].replace(acc_pop_dict)\n",
        "pop_arr = df.loc[acc_mask, \"Population\"].values\n",
        "df.loc[acc_mask, cap_vars] = df.loc[acc_mask, case_vars].values / \\\n",
        "                             np.stack((pop_arr for i in range(3)), axis=1)\n",
        "df.loc[acc_mask, cap_date_vars] = df.loc[acc_mask, date_vars].values * per_day_cap_factor / \\\n",
        "                                         np.stack((pop_arr for i in range(3)), axis=1)\n",
        "\n",
        "df[acc_mask].head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# aggregate Australian/Chinese/Canadian states/provinces into whole country rows\n",
        "# Australia block\n",
        "aus_mask = (df[\"Country/Region\"] == \"Australia\")\n",
        "aus_pop = acc_pop_df.loc[acc_pop_df.Country == \"Australia\", \"Population\"].sum()\n",
        "aus_pop_ls = [aus_pop for i in range(6)]\n",
        "aus_row_ls = []\n",
        "for date in np.sort(df.loc[aus_mask, \"Date\"].unique()):\n",
        "\n",
        "    # start a new row by duplicating an extant row\n",
        "    all_aus_agg_row = df[aus_mask & (df.Date == date)].head(1)\n",
        "\n",
        "    # calculate vars\n",
        "    agg_vars = df.loc[aus_mask & (df.Date == date), case_vars + date_vars].sum().values\n",
        "    all_aus_agg_row.loc[:, case_vars + date_vars] = agg_vars\n",
        "    all_aus_agg_row.loc[:, cap_vars + cap_date_vars] = agg_vars * factor / aus_pop_ls\n",
        "\n",
        "    # tweak row to reflect that its for th whole country\n",
        "    all_aus_agg_row[\"Province/State\"] = \"nan\"\n",
        "\n",
        "    # add row to list\n",
        "    aus_row_ls.append(all_aus_agg_row)\n",
        "\n",
        "# combine new rows into dataframe\n",
        "all_aus_df = pd.concat(aus_row_ls, ignore_index=True)\n",
        "\n",
        "# delete extant rows for whole country\n",
        "df = df[~(aus_mask & (df[\"Province/State\"] == \"nan\"))].reset_index(drop=True)\n",
        "\n",
        "# add each new row to end of dataframe\n",
        "for row in range(all_aus_df.shape[0]):\n",
        "    df.loc[len(df.index)] = all_aus_df.iloc[row,:].values\n",
        "\n",
        "# China block\n",
        "chn_mask = (df[\"Country/Region\"] == \"China\")\n",
        "chn_pop = acc_pop_df.loc[acc_pop_df.Country == \"China\", \"Population\"].sum()\n",
        "chn_pop_ls = [chn_pop for i in range(6)]\n",
        "chn_row_ls = []\n",
        "#print(df[chn_mask & (df[\"Province/State\"] == \"nan\")])\n",
        "for date in np.sort(df.loc[chn_mask, \"Date\"].unique()):\n",
        "    \n",
        "    # start a new row by duplicating an extant row\n",
        "    all_chn_agg_row = df[chn_mask & (df.Date == date)].head(1)\n",
        "\n",
        "    # calculate vars\n",
        "    agg_vars = df.loc[chn_mask & (df.Date == date), case_vars + date_vars].sum().values\n",
        "    all_chn_agg_row.loc[:, case_vars + date_vars] = agg_vars\n",
        "    all_chn_agg_row.loc[:, cap_vars + cap_date_vars] = agg_vars * factor / chn_pop_ls\n",
        "    \n",
        "    # tweak row to reflect that its for th whole country\n",
        "    all_chn_agg_row[\"Province/State\"] = \"nan\"\n",
        "\n",
        "    # add row to list\n",
        "    chn_row_ls.append(all_chn_agg_row)\n",
        "\n",
        "# combine new rows into dataframe\n",
        "all_chn_df = pd.concat(chn_row_ls, ignore_index=True)\n",
        "\n",
        "# delete extant rows for whole country\n",
        "df = df[~(chn_mask & (df[\"Province/State\"] == \"nan\"))].reset_index(drop=True)\n",
        "\n",
        "# add each new row to end of dataframe\n",
        "for row in range(all_chn_df.shape[0]):\n",
        "    df.loc[len(df.index)] = all_chn_df.iloc[row,:].values\n",
        "\n",
        "# Canada block\n",
        "can_mask = (df[\"Country/Region\"] == \"Canada\")\n",
        "can_pop = acc_pop_df.loc[acc_pop_df.Country == \"Canada\", \"Population\"].sum()\n",
        "can_pop_ls = [can_pop for i in range(6)]\n",
        "can_row_ls = []\n",
        "for date in np.sort(df.loc[can_mask, \"Date\"].unique()):\n",
        "\n",
        "    # start a new row by duplicating an extant row\n",
        "    all_can_agg_row = df[can_mask & (df.Date == date)].head(1)\n",
        "\n",
        "    # calculate vars\n",
        "    agg_vars = df.loc[can_mask & (df.Date == date), case_vars + date_vars].sum().values\n",
        "    all_can_agg_row.loc[:, case_vars + date_vars] = agg_vars\n",
        "    all_can_agg_row.loc[:, cap_vars + cap_date_vars] = agg_vars * factor / can_pop_ls\n",
        "\n",
        "    # tweak row to reflect that its for th whole country\n",
        "    all_can_agg_row[\"Province/State\"] = \"nan\"\n",
        "\n",
        "    # add row to list\n",
        "    can_row_ls.append(all_can_agg_row)\n",
        "\n",
        "# combine new rows into dataframe\n",
        "all_can_df = pd.concat(can_row_ls, ignore_index=True)\n",
        "\n",
        "# delete extant rows for whole country\n",
        "df = df[~(can_mask & (df[\"Province/State\"] == \"nan\"))].reset_index(drop=True)\n",
        "\n",
        "# add each new row to end of dataframe\n",
        "for row in range(all_can_df.shape[0]):\n",
        "    df.loc[len(df.index)] = all_can_df.iloc[row,:].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "         Country  Population\n0          China  1433783686\n1          India  1366417754\n2  United States   329064917",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Population</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>China</td>\n      <td>1433783686</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>India</td>\n      <td>1366417754</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>United States</td>\n      <td>329064917</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# calculate World country per capita variables\n",
        "world_pop_df = pd.read_pickle(r\"C:\\Users\\adiad\\Anaconda3\\envs\\CovidApp\\covidapp\\data_clean\\world_pop_df.pkl\")\n",
        "world_pop_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array(['Afghanistan', 'Albania', 'Algeria', 'American Samoa', 'Andorra',\n       'Angola', 'Anguilla', 'Antigua and Barbuda', 'Argentina',\n       'Armenia', 'Aruba', 'Australia', 'Austria', 'Azerbaijan',\n       'Bahamas', 'Bahrain', 'Bangladesh', 'Barbados', 'Belarus',\n       'Belgium', 'Belize', 'Benin', 'Bermuda', 'Bhutan', 'Bolivia',\n       'Bosnia and Herzegovina', 'Botswana', 'Brazil',\n       'British Virgin Islands', 'Brunei', 'Bulgaria', 'Burkina Faso',\n       'Burundi', 'Cambodia', 'Cameroon', 'Canada', 'Cape Verde',\n       'Caribbean Netherlands', 'Cayman Islands',\n       'Central African Republic', 'Chad', 'Chile', 'China', 'Colombia',\n       'Comoros', 'Congo', 'Cook Islands', 'Costa Rica', 'Croatia',\n       'Cuba', 'Curaçao', 'Cyprus', 'Czech Republic', 'DR Congo',\n       'Denmark', 'Djibouti', 'Dominica', 'Dominican Republic',\n       'East Timor', 'Ecuador', 'Egypt', 'El Salvador',\n       'Equatorial Guinea', 'Eritrea', 'Estonia', 'Eswatini', 'Ethiopia',\n       'F.S. Micronesia', 'Falkland Islands', 'Faroe Islands', 'Fiji',\n       'Finland', 'France', 'French Guiana', 'French Polynesia', 'Gabon',\n       'Gambia', 'Georgia', 'Germany', 'Ghana', 'Gibraltar', 'Greece',\n       'Greenland', 'Grenada', 'Guadeloupe', 'Guam', 'Guatemala',\n       'Guernsey', 'Guinea', 'Guinea-Bissau', 'Guyana', 'Haiti',\n       'Honduras', 'Hong Kong', 'Hungary', 'Iceland', 'India',\n       'Indonesia', 'Iran', 'Iraq', 'Ireland', 'Isle of Man', 'Israel',\n       'Italy', 'Ivory Coast', 'Jamaica', 'Japan', 'Jordan', 'Kazakhstan',\n       'Kenya', 'Kiribati', 'Kuwait', 'Kyrgyzstan', 'Laos', 'Latvia',\n       'Lebanon', 'Lesotho', 'Liberia', 'Libya', 'Liechtenstein',\n       'Lithuania', 'Luxembourg', 'Macau', 'Madagascar', 'Malawi',\n       'Malaysia', 'Maldives', 'Mali', 'Malta', 'Marshall Islands',\n       'Martinique', 'Mauritania', 'Mauritius', 'Mayotte', 'Mexico',\n       'Moldova', 'Monaco', 'Mongolia', 'Montenegro', 'Montserrat',\n       'Morocco', 'Mozambique', 'Myanmar', 'Namibia', 'Nauru', 'Nepal',\n       'Netherlands', 'New Caledonia', 'New Zealand', 'Nicaragua',\n       'Niger', 'Nigeria', 'Niue', 'North Korea', 'North Macedonia',\n       'Northern Mariana Islands', 'Norway', 'Oman', 'Pakistan', 'Palau',\n       'Palestine', 'Panama', 'Papua New Guinea', 'Paraguay', 'Peru',\n       'Philippines', 'Poland', 'Portugal', 'Puerto Rico', 'Qatar',\n       'Romania', 'Russia', 'Rwanda', 'Réunion',\n       'Saint Helena, Ascension and Tristan da Cunha',\n       'Saint Kitts and Nevis', 'Saint Lucia',\n       'Saint Pierre and Miquelon', 'Saint Vincent and the Grenadines',\n       'Samoa', 'San Marino', 'Saudi Arabia', 'Senegal', 'Serbia',\n       'Seychelles', 'Sierra Leone', 'Singapore', 'Sint Maarten',\n       'Slovakia', 'Slovenia', 'Solomon Islands', 'Somalia',\n       'South Africa', 'South Korea', 'South Sudan', 'Spain', 'Sri Lanka',\n       'Sudan', 'Suriname', 'Sweden', 'Switzerland', 'Syria',\n       'São Tomé and Príncipe', 'Taiwan', 'Tajikistan', 'Tanzania',\n       'Thailand', 'Togo', 'Tokelau', 'Tonga', 'Trinidad and Tobago',\n       'Tunisia', 'Turkey', 'Turkmenistan', 'Turks and Caicos Islands',\n       'Tuvalu', 'U.S. Virgin Islands', 'Uganda', 'Ukraine',\n       'United Arab Emirates', 'United Kingdom', 'United States',\n       'Uruguay', 'Uzbekistan', 'Vanuatu', 'Vatican City', 'Venezuela',\n       'Vietnam', 'Wallis and Futuna', 'Western Sahara', 'Yemen',\n       'Zambia', 'Zimbabwe'], dtype='<U44')"
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "np.sort(world_pop_df.Country.unique().tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "['Channel Islands',\n 'Congo (Brazzaville)',\n 'Congo (Kinshasa)',\n 'Cruise Ship',\n 'Guinea Bissau',\n 'Hong Kong S.A.R.',\n 'Jersey',\n 'Kosovo',\n 'Macedonia',\n 'Republic of Congo',\n 'Republic of Serbia',\n 'Reunion',\n 'Saint Barthelemy',\n 'Saint Martin',\n 'Sao Tome and Principe',\n 'The Bahamas',\n 'United Republic of Tanzania',\n 'United States of America',\n 'Vatican']"
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "# print countries in epidemiological data which aren't matched in the population data\n",
        "[country for country in np.sort(df[\"Country/Region\"].unique()) if country not in world_pop_df.Country.to_list()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "world_pop_df.loc[world_pop_df.Country == \"DR Congo\", \"Country\"] = \"Republic of Congo\"\n",
        "world_pop_df.loc[world_pop_df.Country == \"Serbia\", \"Country\"] = \"Republic of Serbia\"\n",
        "world_pop_df.loc[world_pop_df.Country == \"Bahamas\", \"Country\"] = \"The Bahamas\"\n",
        "world_pop_df.loc[world_pop_df.Country == \"Tanzania\", \"Country\"] = \"United Republic of Tanzania\"\n",
        "world_pop_df.loc[world_pop_df.Country == \"Vatican City\", \"Country\"] = \"Vatican\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Country, Population\nChina , 1433783686\nIndia , 1366417754\nUnited States , 329064917\n"
        }
      ],
      "source": [
        "# create a dict to transform states/provinces to their population\n",
        "world_pop_dict = {}\n",
        "for country in world_pop_df.Country.unique():\n",
        "    #print(province)\n",
        "    #print(ac_pop_df[ac_pop_df.State == province])\n",
        "    #print(\"   \")\n",
        "    pop = world_pop_df.loc[world_pop_df.Country == country, \"Population\"].values[0]\n",
        "    world_pop_dict.update({country:pop})\n",
        "\n",
        "print(\"Country, Population\")\n",
        "for x in list(world_pop_dict)[:3]:\n",
        "    print(x, \",\", world_pop_dict[x])\n",
        "\n",
        "# calculate per capita values for countries\n",
        "countries = np.sort(df.loc[df[\"Country/Region\"].isin(world_pop_df.Country), \\\n",
        "                           \"Country/Region\"].unique()).tolist()\n",
        "countries.remove(\"Australia\") # the US doesn't match so it is not in this blacklist\n",
        "countries.remove(\"China\")\n",
        "world_mask = df[\"Country/Region\"].isin(countries)\n",
        "\n",
        "df.loc[world_mask, \"Population\"] = df.loc[world_mask, \"Country/Region\"].replace(world_pop_dict)\n",
        "pop_arr = df.loc[world_mask, \"Population\"].values\n",
        "\n",
        "df.loc[world_mask, cap_vars] = df.loc[world_mask, case_vars].values / \\\n",
        "                                      np.stack((pop_arr for i in range(3)), axis=1)\n",
        "df.loc[world_mask, cap_date_vars] = df.loc[world_mask, date_vars].values * per_day_cap_factor / \\\n",
        "                                           np.stack((pop_arr for i in range(3)), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define categorical variable which indicates the intended map scope of each row\n",
        "df[\"MapScope\"] = \"\"\n",
        "df.loc[(df[\"Country/Region\"] == \"United States of America\") & \\\n",
        "       (df.Date > pd.datetime(2020, 3, 21)) & (df.County != \"nan\"), \"MapScope\"] = \"US Counties\"\n",
        "df.loc[(df[\"Country/Region\"] == \"United States of America\") & \\\n",
        "       (df[\"County\"] == \"nan\") & (df[\"Province/State\"] != \"nan\"), \"MapScope\"] = \"US States\"\n",
        "df.loc[(df[\"Country/Region\"] == \"China\") & (df[\"Province/State\"] != \"nan\") & \\\n",
        "       (df.Date > pd.datetime(2020, 1, 22)), \"MapScope\"] = \"China Provinces\"\n",
        "df.loc[(df[\"Country/Region\"] == \"Australia\") & \\\n",
        "       (df[\"Province/State\"] != \"nan\"), \"MapScope\"] = \"Australia States\"\n",
        "df.loc[(df[\"Country/Region\"] == \"Canada\") & (df[\"Province/State\"] != \"nan\"), \"MapScope\"] = \"Canada Provinces\"\n",
        "df.loc[(df[\"Province/State\"] == \"nan\"), \"MapScope\"] = \"Countries\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Memory used: 277.81 Mb\nCountry/Region                       object\nProvince/State                       object\nCounty                               object\nDate                         datetime64[ns]\nConfirmed                           float64\nDeaths                              float64\nRecovered                           float64\nLatitude                            float64\nLongitude                           float64\nFIPS                                 object\nActive                              float64\nConfirmedPerDate                     object\nRecoveredPerDate                     object\nDeathsPerDate                        object\nUSstateAbbr                          object\nConfirmedPerCapita                  float64\nRecoveredPerCapita                  float64\nDeathsPerCapita                     float64\nConfirmedPerDatePerCapita           float64\nRecoveredPerDatePerCapita           float64\nDeathsPerDatePerCapita              float64\nPopulation                          float64\nMapScope                             object\ndtype: object\n"
        }
      ],
      "source": [
        "def memory_usage(df):\n",
        "    return(round(df.memory_usage(deep=True).sum() / 1024 ** 2, 2))\n",
        "\n",
        "print('Memory used:', memory_usage(df), 'Mb')\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Memory used: 29.92 Mb\nCountry/Region                     category\nProvince/State                     category\nCounty                             category\nDate                         datetime64[ns]\nConfirmed                            uint32\nDeaths                               uint32\nRecovered                            uint32\nFIPS                               category\nConfirmedPerDate                     uint16\nRecoveredPerDate                     uint16\nDeathsPerDate                        uint16\nConfirmedPerCapita                  float16\nRecoveredPerCapita                  float16\nDeathsPerCapita                     float16\nConfirmedPerDatePerCapita           float64\nRecoveredPerDatePerCapita           float64\nDeathsPerDatePerCapita              float64\nMapScope                           category\ndtype: object\n"
        }
      ],
      "source": [
        "# reduce the memory footprint of the dataframe\n",
        "df[\"Country/Region\"] = df[\"Country/Region\"].astype(\"category\")\n",
        "df[\"Province/State\"] = df[\"Province/State\"].astype(\"category\")\n",
        "df[\"County\"] = df[\"County\"].astype(\"category\")\n",
        "df[\"MapScope\"] = df[\"MapScope\"].astype(\"category\")\n",
        "\n",
        "df.Confirmed = df.Confirmed.fillna(0).astype(\"uint32\")\n",
        "df.Recovered = df.Recovered.fillna(0).astype(\"uint32\")\n",
        "df.Deaths = df.Deaths.fillna(0).astype(\"uint32\")\n",
        "\n",
        "# PerDate values were calculated, if the quantity decreased from the\n",
        "# prior day, then the PerDate value will be negative.\n",
        "# Negative values will be clipped/replaced with zeros so unsigned\n",
        "# integers can be used.\n",
        "df.ConfirmedPerDate[df.ConfirmedPerDate < 0] = 0\n",
        "df.ConfirmedPerDate = df.ConfirmedPerDate.fillna(0).round().astype(\"uint16\")\n",
        "df.RecoveredPerDate[df.RecoveredPerDate < 0] = 0\n",
        "df.RecoveredPerDate = df.RecoveredPerDate.fillna(0).round().astype(\"uint16\")\n",
        "df.DeathsPerDate[df.DeathsPerDate < 0] = 0\n",
        "df.DeathsPerDate = df.DeathsPerDate.fillna(0).round().astype(\"uint16\")\n",
        "\n",
        "df.ConfirmedPerCapita[df.ConfirmedPerCapita < 0] = 0\n",
        "df.ConfirmedPerCapita = df.ConfirmedPerCapita.fillna(0).astype(\"float16\")\n",
        "df.RecoveredPerCapita[df.RecoveredPerCapita < 0] = 0\n",
        "df.RecoveredPerCapita = df.RecoveredPerCapita.fillna(0).astype(\"float16\")\n",
        "df.DeathsPerCapita[df.DeathsPerCapita < 0] = 0\n",
        "df.DeathsPerCapita = df.DeathsPerCapita.fillna(0).astype(\"float16\")\n",
        "\n",
        "df.ConfirmedPerDatePerCapita[df.ConfirmedPerDatePerCapita < 0] = 0\n",
        "df.ConfirmedPerDatePerCapita = df.ConfirmedPerDatePerCapita.fillna(0)\n",
        "df.RecoveredPerDatePerCapita[df.RecoveredPerDatePerCapita < 0] = 0\n",
        "df.RecoveredPerDatePerCapita = df.RecoveredPerDatePerCapita.fillna(0)\n",
        "df.DeathsPerDatePerCapita[df.DeathsPerDatePerCapita < 0] = 0\n",
        "df.DeathsPerDatePerCapita = df.DeathsPerDatePerCapita.fillna(0)\n",
        "\n",
        "#df.Latitude = df.Latitude.astype(\"float16\")\n",
        "#df.Longitude = df.Longitude.astype(\"float16\")\n",
        "df.FIPS = df.FIPS.astype(\"category\")\n",
        "\n",
        "df = df.drop([\"Active\", \"Latitude\", \"Longitude\", \"USstateAbbr\", \"Population\"], axis=1)\n",
        "\n",
        "print('Memory used:', memory_usage(df), 'Mb')\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save clean dataframe as a pickle file\n",
        "pkl_file_path = r\"C:\\Users\\adiad\\Anaconda3\\envs\\CovidApp36\\covidapp\\data_clean\\\\\"\n",
        "pkl_file_name = \"Johns_Hopkins_Clean.pkl\"\n",
        "df.to_pickle(pkl_file_path + pkl_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload new pickle file to Google Drive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "gauth = GoogleAuth()\n",
        "gauth.LoadClientConfigFile(\"C:/Users/adiad/Anaconda3/envs/CovidApp36/covidapp/secret_credentials/client_secrets.json\")\n",
        "\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# List all my files and folders on Google Drive with their ID\n",
        "#for file_list in drive.ListFile({'q': 'trashed=false'}):\n",
        "#  print('Received %s files from Files.list()' % len(file_list)) # <= 10\n",
        "#  for file1 in file_list:\n",
        "#      print('title: %s, id: %s' % (file1['title'], file1['id']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Your browser has been opened to visit:\n\n    https://accounts.google.com/o/oauth2/auth?client_id=615556211045-q8k6sbfqtkuiubnnns06sgrm3b7fgob4.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n\nAuthentication successful.\ntitle: Johns_Hopkins_Clean.pkl, mimeType: application/octet-stream\n"
        }
      ],
      "source": [
        "g_file = drive.CreateFile({'id': '1KuubeQzOHAzh_TuNyK2w1XO_L8zXHTRF'})\n",
        "\n",
        "# Read file and set it as a content of this instance.\n",
        "g_file.SetContentFile(pkl_file_path + pkl_file_name)\n",
        "g_file.Upload() # Upload the file.\n",
        "print('title: %s, mimeType: %s' % (g_file['title'], g_file['mimeType']))\n",
        "# title: cat.png, mimeType: image/png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "24.72595646381378"
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "t1 = time.time()\n",
        "(t1 - t0)/60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "422569"
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "df.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pre-render heatmap animation data for US counties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "C:\\Users\\adiad\\Anaconda3\\envs\\CovidApp36\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning:\n\nparsing timezone aware datetimes is deprecated; this will raise an error in the future\n\n"
        }
      ],
      "source": [
        "import pickle, json\n",
        "import datetime as dt\n",
        "from plotly import subplots\n",
        "from plotly import graph_objects as go\n",
        "\n",
        "# converts numpy's datetime64 dtype (used by pandas) to a string\n",
        "def numpy_dt64_to_str(dt64):\n",
        "    day_timestamp_dt = (dt64 - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')\n",
        "    day_dt = dt.datetime.utcfromtimestamp(day_timestamp_dt)\n",
        "    return day_dt.strftime(\"%b %d\")\n",
        "\n",
        "# get mapbox token\n",
        "token = open(\"C:/Users/adiad/Anaconda3/envs/CovidApp36/covidapp/secret_credentials/.mapbox_token\").read()\n",
        "\n",
        "with open(\"C:/Users/adiad/Anaconda3/envs/CovidApp36/covidapp/data_clean/us_county_geo.json\") as f:\n",
        "    us_counties_json = json.load(f)\n",
        "\n",
        "# set app.py function input variables\n",
        "map_scope = \"UScounties\"\n",
        "map_var = \"Confirmed\"\n",
        "map_calc = \"Total\"\n",
        "map_scale = \"Logarithmic\"\n",
        "map_norm_type = \"\"\n",
        "map_norm_val = 100000\n",
        "init_spinner_style = \"this is not None\"\n",
        "\n",
        "#### BEGIN app.py function block\n",
        "# test if this is the initial execution of this callback\n",
        "is_init = (init_spinner_style is None)\n",
        "\n",
        "# only generate a new heatmap if the user initialized this callback\n",
        "if is_init:\n",
        "    fig = init_heatmap\n",
        "\n",
        "else:\n",
        "\n",
        "    # set null values of map parameters\n",
        "    if map_calc == \"Total\":\n",
        "        map_calc = \"\"\n",
        "    if map_norm_type == \"None\":\n",
        "        map_norm_type = \"\"\n",
        "    plot_var = map_var + map_calc + map_norm_type\n",
        "\n",
        "    frame_dur = 1000 # milliseconds, controls animation speed\n",
        "\n",
        "    # set variables conditioned on the map scope\n",
        "    if map_scope == \"UScounties\":\n",
        "        geo_json = us_counties_json\n",
        "        plot_df = df[df[\"MapScope\"] == \"US Counties\"]\n",
        "        plot_df[\"AreaLabel\"] = plot_df.County.astype(str) + \", \" + plot_df[\"Province/State\"].astype(str)\n",
        "        location_var = \"FIPS\"\n",
        "        geo_json_name_field = None\n",
        "        map_center = {\"lat\": 37.0902, \"lon\": -95.7129}\n",
        "        title = \"US counties\"\n",
        "        init_zoom = 3\n",
        "    \n",
        "    elif map_scope == \"USstates\":\n",
        "        geo_json = us_states_json\n",
        "        plot_df = df[df[\"MapScope\"] == \"US States\"]\n",
        "        plot_df[\"AreaLabel\"] = plot_df[\"Province/State\"].astype(str)\n",
        "        location_var = \"Province/State\"\n",
        "        geo_json_name_field = \"properties.NAME\"\n",
        "        map_center = {\"lat\": 37.0902, \"lon\": -95.7129}\n",
        "        title = \"US states\"\n",
        "        init_zoom = 3\n",
        "    \n",
        "    elif map_scope == \"China\":\n",
        "        geo_json = china_json\n",
        "        plot_df = df[df[\"MapScope\"] == \"China Provinces\"]\n",
        "        plot_df[\"AreaLabel\"] = plot_df[\"Province/State\"].astype(str)\n",
        "        location_var = \"Province/State\"\n",
        "        geo_json_name_field = \"properties.NL_NAME_1\"\n",
        "        map_center = {\"lat\": 37.110573, \"lon\": 106.493924}\n",
        "        title = \"Chinese provinces\"\n",
        "        init_zoom = 2\n",
        "    \n",
        "    elif map_scope == \"Australia\":\n",
        "        geo_json = australia_json\n",
        "        plot_df = df[df[\"MapScope\"] == \"Australia States\"]\n",
        "        plot_df[\"AreaLabel\"] = plot_df[\"Province/State\"].astype(str)\n",
        "        location_var = \"Province/State\"\n",
        "        geo_json_name_field = None\n",
        "        map_center = {\"lat\": -26, \"lon\": 133 + 25/60}\n",
        "        title = \"Australian states\"\n",
        "        init_zoom = 3\n",
        "    \n",
        "    elif map_scope == \"Canada\":\n",
        "        geo_json = canada_json\n",
        "        plot_df = df[df[\"MapScope\"] == \"Canada Provinces\"]\n",
        "        plot_df[\"AreaLabel\"] = plot_df[\"Province/State\"].astype(str)\n",
        "        location_var = \"Province/State\"\n",
        "        geo_json_name_field = \"properties.PRENAME\"\n",
        "        map_center = {\"lat\": 58, \"lon\": -96 - 48/60}\n",
        "        title = \"Canadian Provinces\"\n",
        "        init_zoom = 2\n",
        "    \n",
        "    elif map_scope == \"World\":\n",
        "        geo_json = world_json\n",
        "        plot_df = df[df[\"MapScope\"] == \"Countries\"]\n",
        "        plot_df[\"AreaLabel\"] = plot_df[\"Country/Region\"].astype(str)\n",
        "        location_var = \"Country/Region\"\n",
        "        geo_json_name_field = \"properties.ADMIN\"\n",
        "        map_center = {\"lat\": 0, \"lon\": 0}\n",
        "        title = \"Countries\"\n",
        "        init_zoom = 0\n",
        "\n",
        "    # set axis variables conditioned on scale settings\n",
        "    var_finite = plot_df[plot_var].values\n",
        "    var_finite = var_finite[(var_finite != 0) & (var_finite != -np.inf) & (var_finite != np.inf)]\n",
        "    if len(var_finite) > 0:\n",
        "        var_min = min(var_finite)\n",
        "        var_max = max(var_finite)\n",
        "    else:\n",
        "        var_min = 0\n",
        "        var_max = 0\n",
        "    \n",
        "    log_txt = [\"1e-6\", \"1e-5\", \"1e-4\", \".001\", \".01\", \".1\", \\\n",
        "            \"1\", \"10\", \"100\", \"1K\", \"10K\", \"100K\", \"1M\"]\n",
        "    map_log_hvr_txt = \"Cases per \" + log_txt[int(np.log10(map_norm_val)) + 6] + \" Capita: \"\n",
        "    if map_scale == \"Logarithmic\":\n",
        "        bar_scale_type = \"log\"\n",
        "        map_tick_vals = np.arange(-6, 7)\n",
        "        map_tick_txt = log_txt\n",
        "        \n",
        "        if map_norm_type == \"PerCapita\":\n",
        "            plot_df[\"CaseVar\"] = np.log10(plot_df[plot_var]*map_norm_val)\n",
        "            bar_range = np.log10(np.array([var_min, var_max])*map_norm_val)\n",
        "        else:\n",
        "            plot_df[\"CaseVar\"] = np.log10(plot_df[plot_var])\n",
        "            bar_range = np.log10(np.array([var_min, var_max]))\n",
        "    \n",
        "    else:\n",
        "        bar_scale_type = \"linear\"\n",
        "        map_tick_vals = None\n",
        "        map_tick_txt = None\n",
        "\n",
        "        if map_norm_type == \"PerCapita\":\n",
        "            plot_df[\"CaseVar\"] = plot_df[plot_var]*map_norm_val\n",
        "            bar_range = np.array([0, var_max])*map_norm_val\n",
        "        else:\n",
        "            plot_df[\"CaseVar\"] = plot_df[plot_var]\n",
        "            bar_range = np.array([0, var_max])\n",
        "    \n",
        "    if map_var == \"Recovered\":\n",
        "        heat_color_scale = \"ylgn\"\n",
        "        bar_color = \"rgb(69, 161, 69)\"\n",
        "    else:\n",
        "        heat_color_scale = \"ylorrd\"\n",
        "        bar_color = \"rgb(236, 62, 19)\"\n",
        "    \n",
        "    days = np.sort(plot_df.Date.unique())\n",
        "\n",
        "    # when the figure first loads, show the most recent date which has some data to plot\n",
        "    if len(var_finite) > 0:\n",
        "        date_has_data_df = plot_df.groupby([\"Date\"]).sum().reset_index()\n",
        "        init_date = date_has_data_df.loc[date_has_data_df[plot_var] > 0, \"Date\"].max()\n",
        "        init_date_ind = np.where(days == init_date.to_datetime64())[0][0]\n",
        "    else:\n",
        "        init_date = days[-1]\n",
        "        init_date_ind = len(days) - 1\n",
        "    plot_day_df = plot_df[plot_df.Date == init_date]\n",
        "\n",
        "    # define custom hover data\n",
        "    cust_data = np.dstack((plot_day_df.loc[:, map_var + map_calc].values, \\\n",
        "                        plot_day_df.loc[:, map_var + map_calc + \"PerCapita\"]. \\\n",
        "                                    values*map_norm_val))[0]\n",
        "    location_series = plot_day_df[location_var]\n",
        "    if map_norm_type == \"PerCapita\":\n",
        "        bar_txt_format = \"{:.2e}\"\n",
        "    else:\n",
        "        bar_txt_format = \"{:,.0f}\"\n",
        "    \n",
        "    # define the left bar plot\n",
        "    bar_df = plot_day_df.nlargest(10, plot_var, keep=\"all\").reset_index()\n",
        "    bar_df = bar_df.head(10) # nlargest may return more than 10 rows if there are duplicate values\n",
        "    bar_df = bar_df[bar_df.CaseVar > -np.inf]\n",
        "    nrows = bar_df.shape[0]\n",
        "    bar_df = bar_df.iloc[np.arange(nrows - 1, -1, -1),:] # reverse order of top 10 rows\n",
        "\n",
        "    # plotly does not tolerate changing the number of bars in \n",
        "    # a bar graph during animation define a function to pad \n",
        "    # data arrays with blank elements so the bar graph always \n",
        "    # has 10 elements\n",
        "    def pad_10_arr(x, pad_val, unique_fill_bool):\n",
        "        xlen = len(x)\n",
        "        if xlen == 10:\n",
        "            result = x\n",
        "        else:\n",
        "            npad = 10 - xlen\n",
        "            fill_arr = np.array([pad_val for i in range(npad)])\n",
        "\n",
        "            # shorten each string fill element in array to make the elements unique\n",
        "            if unique_fill_bool:\n",
        "                fill_arr = [item[i:] for i, item in enumerate(fill_arr)]\n",
        "            \n",
        "            result = np.append(fill_arr, x)\n",
        "        return result\n",
        "\n",
        "    # only build the bar plot if there is data to plot\n",
        "    if plot_df[plot_var].max() > 0:\n",
        "        no_data = False\n",
        "\n",
        "        max_width_label = 25\n",
        "        if map_scope == \"UScounties\":\n",
        "\n",
        "            # some of the county, state labels are too long, taking up too much space\n",
        "            # in the figure.  Long labels will have the county label trimmed with an ellipsis appended.\n",
        "            labels_to_trim = bar_df[\"AreaLabel\"].astype(str).str.len() > max_width_label\n",
        "            county_len_arr = max_width_label - 5 - bar_df.loc[labels_to_trim, \"Province/State\"].astype(str).str.len().values\n",
        "            county_abbr = [bar_df.loc[labels_to_trim, \"County\"].astype(str).values[i][:county_len_arr[i]] \\\n",
        "                        for i in range(len(county_len_arr))]\n",
        "            state_abbr = bar_df.loc[labels_to_trim, \"Province/State\"].astype(str).values.tolist()\n",
        "            county_state_abbr = [county_abbr[i] + \"..., \" + state_abbr[i] for i in range(len(county_abbr))]\n",
        "            bar_df.loc[labels_to_trim, \"AreaLabel\"] = county_state_abbr\n",
        "        elif map_scope == \"Australia\":\n",
        "            # only one label needs to be trimmed\n",
        "            long_label = \"Australian Capital Territory\"\n",
        "            labels_to_trim = bar_df[\"AreaLabel\"].astype(str) == long_label\n",
        "            bar_df.loc[labels_to_trim, \"AreaLabel\"] = long_label[:(max_width_label - 3)] + \"...\"\n",
        "\n",
        "        # bar labels must be padded so all labels have the same length\n",
        "        # as some labels disappear and others are introduced,\n",
        "        # varied-length label cause bad animation behavior\n",
        "        area_labels = [label.rjust(max_width_label) for label in bar_df.AreaLabel.values]\n",
        "\n",
        "        if map_norm_type == \"PerCapita\":\n",
        "            bar_df[plot_var] = bar_df[plot_var] * map_norm_val\n",
        "        \n",
        "        bar_df[\"ValLabels\"] = bar_df[plot_var].astype(\"float\")\n",
        "        bar_fig_data = go.Bar(x=pad_10_arr(bar_df[plot_var].values, 0, False),\n",
        "                                y=pad_10_arr(area_labels, \" \" * max_width_label, True),\n",
        "                                text=pad_10_arr(bar_df.ValLabels.map(bar_txt_format.format).values, \"\", False),\n",
        "                                textposition=\"auto\",\n",
        "                                hoverinfo=\"none\",\n",
        "                                orientation=\"h\",\n",
        "                                marker_color=bar_color,\n",
        "                                name=\"\")\n",
        "    else:\n",
        "        no_data = True\n",
        "        bar_fig_data = go.Bar(x=[],\n",
        "                                y=[],\n",
        "                                orientation=\"h\",\n",
        "                                name=\"\")\n",
        "    \n",
        "    # build the heatmap\n",
        "    heat_fig_data =go.Choroplethmapbox(geojson=geo_json,\n",
        "                                        locations=location_series,\n",
        "                                        featureidkey=geo_json_name_field,\n",
        "                                        z=plot_day_df.CaseVar,\n",
        "                                        zmin=0,\n",
        "                                        zmax=plot_df.CaseVar.max(),\n",
        "                                        customdata=cust_data,\n",
        "                                        name=\"\",\n",
        "                                        text=plot_day_df.AreaLabel,\n",
        "                                        hovertemplate=\"<b>%{text}</b><br>\" + \\\n",
        "                                                        \"<b>Cases</b>: %{customdata[0]:,}<br>\" + \\\n",
        "                                                        \"<b>\" + map_log_hvr_txt + \"</b>: %{customdata[1]:.2e}\",\n",
        "                                        colorbar=dict(outlinewidth=1,\n",
        "                                                        outlinecolor=\"#333333\",\n",
        "                                                        len=0.9,\n",
        "                                                        lenmode=\"fraction\",\n",
        "                                                        xpad=30,\n",
        "                                                        xanchor=\"right\",\n",
        "                                                        bgcolor=None,\n",
        "                                                        title=dict(text=\"Cases\",\n",
        "                                                                font=dict(size=14)),\n",
        "                                                        tickvals=map_tick_vals,\n",
        "                                                        ticktext=map_tick_txt,\n",
        "                                                        tickcolor=\"#333333\",\n",
        "                                                        tickwidth=2,\n",
        "                                                        tickfont=dict(color=\"#333333\",\n",
        "                                                                    size=12)),\n",
        "                                        colorscale=heat_color_scale,\n",
        "                                        marker_opacity=0.7,\n",
        "                                        marker_line_width=0)\n",
        "\n",
        "    # define animation controls\n",
        "    fig_ctrls = []\n",
        "    sliders_dict = dict()\n",
        "\n",
        "    # only define the animation controls of there is data to plot\n",
        "    if plot_df[plot_var].max() > 0:\n",
        "        fig_ctrls = [dict(type=\"buttons\",\n",
        "                            buttons=[dict(label=\"Play\",\n",
        "                                        method=\"animate\",\n",
        "                                        args=[None,\n",
        "                                            dict(frame=dict(duration=frame_dur,\n",
        "                                                            redraw=True),\n",
        "                                                    fromcurrent=True)]),\n",
        "                                dict(label=\"Pause\",\n",
        "                                        method=\"animate\",\n",
        "                                        args=[[None],\n",
        "                                            dict(frame=dict(duration=0,\n",
        "                                                            redraw=True),\n",
        "                                                mode=\"immediate\")])],\n",
        "                            direction=\"left\",\n",
        "                            pad={\"r\": 10, \"t\": 35},\n",
        "                            showactive=False,\n",
        "                            x=0.1,\n",
        "                            xanchor=\"right\",\n",
        "                            y=0,\n",
        "                            yanchor=\"top\")]\n",
        "\n",
        "        if (not is_init):\n",
        "            sliders_dict = dict(active=init_date_ind,\n",
        "                                visible=True,\n",
        "                                yanchor=\"top\",\n",
        "                                xanchor=\"left\",\n",
        "                                currentvalue=dict(font=dict(size=14),\n",
        "                                                    prefix=\"Plotted Date: \",\n",
        "                                                    visible=True,\n",
        "                                                    xanchor=\"center\"),\n",
        "                                pad=dict(b=10,\n",
        "                                            t=10),\n",
        "                                len=0.875,\n",
        "                                x=0.125,\n",
        "                                y=0,\n",
        "                                steps=[])\n",
        "\n",
        "    # define the animation frames\n",
        "    fig_frames = []\n",
        "    if is_init:\n",
        "        fig_frames = init_fig_frames\n",
        "        sliders_dict = init_slider_steps\n",
        "\n",
        "    # only define the animation frames if there is data to plot\n",
        "    elif plot_df[plot_var].max() > 0:\n",
        "        for day in days:\n",
        "\n",
        "            # this code repeating what was done to build the initial bar plot above\n",
        "            plot_day_df = plot_df[plot_df.Date == day]\n",
        "            bar_df = plot_day_df.nlargest(10, plot_var, keep=\"all\").reset_index()\n",
        "            bar_df = bar_df.head(10) # nlargest may return more than 10 rows if there are duplicate values\n",
        "            bar_df = bar_df[bar_df.CaseVar > -np.inf]\n",
        "            nrows = bar_df.shape[0]\n",
        "            bar_df = bar_df.iloc[np.arange(nrows - 1, -1, -1),:] # reverse order of top 10 rows\n",
        "            if map_scope == \"UScounties\":\n",
        "                labels_to_trim = bar_df[\"AreaLabel\"].astype(str).str.len() > max_width_label\n",
        "                county_len_arr = max_width_label - 5 - bar_df.loc[labels_to_trim, \"Province/State\"].astype(str).str.len().values\n",
        "                county_abbr = [bar_df.loc[labels_to_trim, \"County\"].astype(str).values[i][:county_len_arr[i]] \\\n",
        "                            for i in range(len(county_len_arr))]\n",
        "                state_abbr = bar_df.loc[labels_to_trim, \"Province/State\"].astype(str).values.tolist()\n",
        "                county_state_abbr = [county_abbr[i] + \"..., \" + state_abbr[i] for i in range(len(county_abbr))]\n",
        "                bar_df.loc[labels_to_trim, \"AreaLabel\"] = county_state_abbr\n",
        "            elif map_scope == \"Australia\":\n",
        "                long_label = \"Australian Capital Territory\"\n",
        "                labels_to_trim = bar_df[\"AreaLabel\"].astype(str) == long_label\n",
        "                bar_df.loc[labels_to_trim, \"AreaLabel\"] = long_label[:(max_width_label - 3)] + \"...\"\n",
        "            area_labels = [label.rjust(max_width_label) for label in bar_df.AreaLabel.values]\n",
        "            if map_norm_type == \"PerCapita\":\n",
        "                bar_df[plot_var] = bar_df[plot_var] * map_norm_val\n",
        "            bar_df[\"ValLabels\"] = bar_df[plot_var].astype(\"float\")\n",
        "\n",
        "            # this code repeats what was done to build the initial heatmap above\n",
        "            cust_data = np.dstack((plot_day_df.loc[:, map_var + map_calc].values, \\\n",
        "                                plot_day_df.loc[:, map_var + map_calc + \"PerCapita\"]. \\\n",
        "                                            values*map_norm_val))[0]\n",
        "            location_series = plot_day_df[location_var]\n",
        "            \n",
        "            # define the frame, repeating what was done for the initial plots above\n",
        "            frame = go.Frame(data=[go.Bar(x=pad_10_arr(bar_df[plot_var].values, 0, False),\n",
        "                                            y=pad_10_arr(area_labels, \" \" * max_width_label, True),\n",
        "                                            text=pad_10_arr(bar_df.ValLabels.map(bar_txt_format.format). \\\n",
        "                                                                    values, \"\", False),\n",
        "                                            textposition=\"auto\",\n",
        "                                            hoverinfo=\"none\",\n",
        "                                            name=\"\"),\n",
        "                                    go.Choroplethmapbox(locations=location_series,\n",
        "                                                        featureidkey=geo_json_name_field,\n",
        "                                                        z=plot_day_df.CaseVar,\n",
        "                                                        customdata=cust_data,\n",
        "                                                        name=\"\",\n",
        "                                                        text=plot_day_df.AreaLabel,\n",
        "                                                        hovertemplate=\"<b>%{text}</b><br>\" + \\\n",
        "                                                                        \"<b>Cases</b>: %{customdata[0]:,}<br>\" + \\\n",
        "                                                                        \"<b>\" + map_log_hvr_txt + \"</b>: %{customdata[1]:.2e}\")],\n",
        "                                name=numpy_dt64_to_str(day))\n",
        "            fig_frames.append(frame)\n",
        "\n",
        "            # define the slider step\n",
        "            slider_step = dict(args=[[numpy_dt64_to_str(day)],\n",
        "                                        dict(mode=\"immediate\",\n",
        "                                            frame=dict(duration=300,\n",
        "                                                        redraw=True))],\n",
        "                                method=\"animate\",\n",
        "                                label=numpy_dt64_to_str(day))\n",
        "            sliders_dict[\"steps\"].append(slider_step)\n",
        "\n",
        "    # Assemble the entire figure based on the components defined above\n",
        "    fig = subplots.make_subplots(rows=1, cols=2, column_widths=[0.2, 0.8],\n",
        "                                    subplot_titles=(\"Top 10 \" + title, \"\"),\n",
        "                                    horizontal_spacing=0.05,\n",
        "                                    specs=[[{\"type\": \"bar\"},\n",
        "                                            {\"type\": \"choroplethmapbox\"}]])\n",
        "    fig.add_trace(bar_fig_data, row=1, col=1)\n",
        "    fig.add_trace(heat_fig_data, row=1, col=2)\n",
        "    fig.update_layout(mapbox_style=\"light\",\n",
        "                        mapbox_zoom=init_zoom,\n",
        "                        mapbox_accesstoken=token,\n",
        "                        mapbox_center=map_center,\n",
        "                        margin={\"r\":10,\"t\":30,\"l\":10,\"b\":10},\n",
        "                        plot_bgcolor=\"white\",\n",
        "                        sliders=[sliders_dict],\n",
        "                        updatemenus=fig_ctrls)\n",
        "    fig[\"frames\"] = fig_frames\n",
        "    \n",
        "    # update the bar plot axes\n",
        "    if no_data:\n",
        "        fig.update_xaxes(showticklabels=False)\n",
        "        fig.update_yaxes(showticklabels=False)\n",
        "    else:\n",
        "        fig.update_xaxes(type=bar_scale_type,\n",
        "                            ticks=\"outside\",\n",
        "                            range=bar_range,\n",
        "                            showgrid=True,\n",
        "                            gridwidth=0.5,\n",
        "                            gridcolor=\"#CCCCCC\")\n",
        "        fig.update_yaxes(tickfont=dict(family=\"Courier New, monospace\",\n",
        "                                        size=13))\n",
        "\n",
        "    if no_data:\n",
        "        # add annotation when theres no data explaining as such\n",
        "        fig[\"layout\"][\"annotations\"] = [dict(x=0,\n",
        "                                                y=0,\n",
        "                                                xref=\"x1\", \n",
        "                                                yref=\"y1\",\n",
        "                                                text=\"All<br>\" + title + \"<br>have reported<br>zero \" + \\\n",
        "                                                    map_var + \"<br>cases to date\",\n",
        "                                                showarrow=False,\n",
        "                                                font=dict(size=16))]\n",
        "    else:\n",
        "        # modify the bar plot title font properties\n",
        "        fig[\"layout\"][\"annotations\"][0][\"font\"] = dict(size=16)\n",
        "### END app.py function block\n",
        "\n",
        "# write the finished data structures as pickle files\n",
        "with open(\"C:/Users/adiad/Anaconda3/envs/CovidApp36/covidapp/data_clean/init_heatmap.pkl\", \"wb\") as handle:\n",
        "    pickle.dump(fig, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "#fig.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Covid19 Visualization3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python361064bitcovidapp36conda73f2c0ce62d44d7188e4e41c6a3488db",
      "display_name": "Python 3.6.10 64-bit ('CovidApp36': conda)"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f8740008767f49d5a3c9146b8cb2c43d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b4b1a03310ae47089a663c0b5296ccc0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bea6c47e04704c208f289b75766039eb",
              "IPY_MODEL_c6e0300328094b3a93c1d31a6d045896",
              "IPY_MODEL_43b2669c82354599b66b1cd7cfd082ed"
            ]
          }
        },
        "b4b1a03310ae47089a663c0b5296ccc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bea6c47e04704c208f289b75766039eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SelectMultipleModel",
          "state": {
            "_options_labels": [
              "Alabama",
              "Alaska",
              "Alberta",
              "American Samoa",
              "Anguilla",
              "Anhui",
              "Arizona",
              "Arkansas",
              "Aruba",
              "Australian Capital Territory",
              "Bavaria",
              "Beijing",
              "Bermuda",
              "British Columbia",
              "British Virgin Islands",
              "California",
              "Cayman Islands",
              "Channel Islands",
              "Chicago",
              "Chongqing",
              "Colorado",
              "Connecticut",
              "Cruise Ship",
              "Curacao",
              "D.C.",
              "Delaware",
              "Denmark",
              "Diamond Princess",
              "District of Columbia",
              "External territories",
              "Falkland Islands (Islas Malvinas)",
              "Faroe Islands",
              "Fench Guiana",
              "Florida",
              "France",
              "French Guiana",
              "French Polynesia",
              "From Diamond Princess",
              "Fujian",
              "Gansu",
              "Georgia",
              "Gibraltar",
              "Grand Princess",
              "Greenland",
              "Guadeloupe",
              "Guam",
              "Guangdong",
              "Guangxi",
              "Guizhou",
              "Hainan",
              "Hawaii",
              "Hebei",
              "Heilongjiang",
              "Henan",
              "Hong Kong",
              "Hubei",
              "Hunan",
              "Idaho",
              "Illinois",
              "Indiana",
              "Inner Mongolia",
              "Iowa",
              "Isle of Man",
              "Jervis Bay Territory",
              "Jiangsu",
              "Jiangxi",
              "Jilin",
              "Kansas",
              "Kentucky",
              "Liaoning",
              "Louisiana",
              "Macau",
              "Maine",
              "Manitoba",
              "Martinique",
              "Maryland",
              "Massachusetts",
              "Mayotte",
              "Michigan",
              "Minnesota",
              "Mississippi",
              "Missouri",
              "Montana",
              "Montserrat",
              "Nebraska",
              "Netherlands",
              "Nevada",
              "New Brunswick",
              "New Caledonia",
              "New Hampshire",
              "New Jersey",
              "New Mexico",
              "New South Wales",
              "New York",
              "Newfoundland and Labrador",
              "Ningxia",
              "North Carolina",
              "North Dakota",
              "Northern Mariana Islands",
              "Northern Territory",
              "Northwest Territories",
              "Nova Scotia",
              "ON",
              "Ohio",
              "Oklahoma",
              "Ontario",
              "Oregon",
              "Pennsylvania",
              "Prince Edward Island",
              "Puerto Rico",
              "QC",
              "Qinghai",
              "Quebec",
              "Queensland",
              "Reunion",
              "Rhode Island",
              "Saint Barthelemy",
              "Saskatchewan",
              "Shaanxi",
              "Shandong",
              "Shanghai",
              "Shanxi",
              "Sichuan",
              "Sint Eustatius and Saba",
              "Sint Maarten",
              "South Australia",
              "South Carolina",
              "South Dakota",
              "St Martin",
              "Taiwan",
              "Tasmania",
              "Tennessee",
              "Texas",
              "Tianjin",
              "Tibet",
              "Turks and Caicos Islands",
              "United Kingdom",
              "United States Virgin Islands",
              "Utah",
              "Vermont",
              "Victoria",
              "Virgin Islands",
              "Virginia",
              "Washington",
              "West Virginia",
              "Western Australia",
              "Wisconsin",
              "Wuhan Evacuee",
              "Wyoming",
              "Xinjiang",
              "Yukon",
              "Yunnan",
              "Zhejiang",
              "nan"
            ],
            "_view_name": "SelectMultipleView",
            "style": "IPY_MODEL_a79b51547a0b40fc9d8a36098d2bc9d9",
            "rows": 5,
            "_dom_classes": [],
            "description": "States",
            "_model_name": "SelectMultipleModel",
            "index": [],
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67d63198c41d4435a657983dfbaefab9"
          }
        },
        "c6e0300328094b3a93c1d31a6d045896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SelectMultipleModel",
          "state": {
            "_options_labels": [
              "Afghanistan",
              "Albania",
              "Algeria",
              "Andorra",
              "Angola",
              "Antigua and Barbuda",
              "Argentina",
              "Armenia",
              "Aruba",
              "Australia",
              "Austria",
              "Azerbaijan",
              "Bahamas",
              "Bahrain",
              "Bangladesh",
              "Barbados",
              "Belarus",
              "Belgium",
              "Belize",
              "Benin",
              "Bhutan",
              "Bolivia",
              "Bosnia and Herzegovina",
              "Botswana",
              "Brazil",
              "Brunei",
              "Bulgaria",
              "Burkina Faso",
              "Burma",
              "Burundi",
              "Cabo Verde",
              "Cambodia",
              "Cameroon",
              "Canada",
              "Cape Verde",
              "Cayman Islands",
              "Central African Republic",
              "Chad",
              "Channel Islands",
              "Chile",
              "China",
              "Colombia",
              "Congo (Brazzaville)",
              "Congo (Kinshasa)",
              "Costa Rica",
              "Croatia",
              "Cruise Ship",
              "Cuba",
              "Curacao",
              "Cyprus",
              "Czech Republic",
              "Czechia",
              "Denmark",
              "Djibouti",
              "Dominica",
              "Dominican Republic",
              "East Timor",
              "Ecuador",
              "Egypt",
              "El Salvador",
              "Equatorial Guinea",
              "Eritrea",
              "Estonia",
              "Eswatini",
              "Ethiopia",
              "Faroe Islands",
              "Fiji",
              "Finland",
              "France",
              "French Guiana",
              "Gabon",
              "Gambia",
              "Georgia",
              "Germany",
              "Ghana",
              "Gibraltar",
              "Greece",
              "Greenland",
              "Grenada",
              "Guadeloupe",
              "Guam",
              "Guatemala",
              "Guernsey",
              "Guinea",
              "Guinea-Bissau",
              "Guyana",
              "Haiti",
              "Holy See",
              "Honduras",
              "Hong Kong",
              "Hungary",
              "Iceland",
              "India",
              "Indonesia",
              "Iran",
              "Iraq",
              "Ireland",
              "Israel",
              "Italy",
              "Ivory Coast",
              "Jamaica",
              "Japan",
              "Jersey",
              "Jordan",
              "Kazakhstan",
              "Kenya",
              "Kosovo",
              "Kuwait",
              "Kyrgyzstan",
              "Laos",
              "Latvia",
              "Lebanon",
              "Liberia",
              "Libya",
              "Liechtenstein",
              "Lithuania",
              "Luxembourg",
              "MS Zaandam",
              "Macao SAR",
              "Macau",
              "Madagascar",
              "Malawi",
              "Malaysia",
              "Maldives",
              "Mali",
              "Malta",
              "Martinique",
              "Mauritania",
              "Mauritius",
              "Mayotte",
              "Mexico",
              "Moldova",
              "Monaco",
              "Mongolia",
              "Montenegro",
              "Morocco",
              "Mozambique",
              "Namibia",
              "Nepal",
              "Netherlands",
              "New Zealand",
              "Nicaragua",
              "Niger",
              "Nigeria",
              "North Ireland",
              "North Macedonia",
              "Norway",
              "Oman",
              "Pakistan",
              "Palestine",
              "Panama",
              "Papua New Guinea",
              "Paraguay",
              "Peru",
              "Philippines",
              "Poland",
              "Portugal",
              "Puerto Rico",
              "Qatar",
              "Republic of the Congo",
              "Reunion",
              "Romania",
              "Russia",
              "Rwanda",
              "Saint Barthelemy",
              "Saint Kitts and Nevis",
              "Saint Lucia",
              "Saint Martin",
              "Saint Vincent and the Grenadines",
              "San Marino",
              "Saudi Arabia",
              "Senegal",
              "Serbia",
              "Seychelles",
              "Sierra Leone",
              "Singapore",
              "Slovakia",
              "Slovenia",
              "Somalia",
              "South Africa",
              "South Korea",
              "Spain",
              "Sri Lanka",
              "Sudan",
              "Suriname",
              "Sweden",
              "Switzerland",
              "Syria",
              "Taipei and environs",
              "Taiwan",
              "Tanzania",
              "Thailand",
              "Timor-Leste",
              "Togo",
              "Trinidad and Tobago",
              "Tunisia",
              "Turkey",
              "Uganda",
              "Ukraine",
              "United Arab Emirates",
              "United Kingdom",
              "United States",
              "Uruguay",
              "Uzbekistan",
              "Vatican City",
              "Venezuela",
              "Vietnam",
              "West Bank and Gaza",
              "Zambia",
              "Zimbabwe",
              "occupied Palestinian territory"
            ],
            "_view_name": "SelectMultipleView",
            "style": "IPY_MODEL_5363157eec3b498a8244b9bcc1254c53",
            "rows": 5,
            "_dom_classes": [],
            "description": "Countries",
            "_model_name": "SelectMultipleModel",
            "index": [],
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5fb6651db52c4277bee33a372b699c0f"
          }
        },
        "43b2669c82354599b66b1cd7cfd082ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ToggleButtonModel",
          "state": {
            "_view_name": "ToggleButtonView",
            "style": "IPY_MODEL_1bc9eec8f8af4a769e9df33152d414a8",
            "_dom_classes": [],
            "description": "Update Plot",
            "_model_name": "ToggleButtonModel",
            "button_style": "",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "tooltip": "",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "value": false,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7932063d9fc4c5aaaa930df91c72ce3",
            "icon": ""
          }
        },
        "a79b51547a0b40fc9d8a36098d2bc9d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67d63198c41d4435a657983dfbaefab9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5363157eec3b498a8244b9bcc1254c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5fb6651db52c4277bee33a372b699c0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1bc9eec8f8af4a769e9df33152d414a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7932063d9fc4c5aaaa930df91c72ce3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}